{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "import evaluation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_fix = \"MemoryFix\" # Choose \"Disable\", \"MemoryFix\" or \"None\"\n",
    "\n",
    "if GPU_fix == \"Disable\":\n",
    "    try:\n",
    "        # Disable all GPUS\n",
    "        tf.config.set_visible_devices([], 'GPU')\n",
    "        visible_devices = tf.config.get_visible_devices()\n",
    "        for device in visible_devices:\n",
    "            assert device.device_type != 'GPU'\n",
    "    except:\n",
    "        # Invalid device or cannot modify virtual devices once initialized.\n",
    "        pass\n",
    "elif GPU_fix == \"MemoryFix\":\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'tau_data/'\n",
    "train = pandas.read_csv(folder + 'training.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LifeTime</th>\n",
       "      <th>dira</th>\n",
       "      <th>FlightDistance</th>\n",
       "      <th>FlightDistanceError</th>\n",
       "      <th>IP</th>\n",
       "      <th>IPSig</th>\n",
       "      <th>VertexChi2</th>\n",
       "      <th>pt</th>\n",
       "      <th>DOCAone</th>\n",
       "      <th>DOCAtwo</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_p</th>\n",
       "      <th>p2_p</th>\n",
       "      <th>p0_eta</th>\n",
       "      <th>p1_eta</th>\n",
       "      <th>p2_eta</th>\n",
       "      <th>SPDhits</th>\n",
       "      <th>production</th>\n",
       "      <th>signal</th>\n",
       "      <th>mass</th>\n",
       "      <th>min_ANNmuon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18453471</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>14.033335</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.451886</td>\n",
       "      <td>1.900433</td>\n",
       "      <td>1482.037476</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.060602</td>\n",
       "      <td>...</td>\n",
       "      <td>12290.760742</td>\n",
       "      <td>39264.398438</td>\n",
       "      <td>3.076006</td>\n",
       "      <td>4.003800</td>\n",
       "      <td>4.031514</td>\n",
       "      <td>458</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1866.300049</td>\n",
       "      <td>0.277559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364094</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>5.536157</td>\n",
       "      <td>0.302341</td>\n",
       "      <td>0.142163</td>\n",
       "      <td>9.564503</td>\n",
       "      <td>0.865666</td>\n",
       "      <td>3050.720703</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>...</td>\n",
       "      <td>16562.667969</td>\n",
       "      <td>7341.257812</td>\n",
       "      <td>3.228553</td>\n",
       "      <td>2.786543</td>\n",
       "      <td>2.975564</td>\n",
       "      <td>406</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1727.095947</td>\n",
       "      <td>0.225924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11130990</th>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>6.117302</td>\n",
       "      <td>0.276463</td>\n",
       "      <td>0.034746</td>\n",
       "      <td>1.970751</td>\n",
       "      <td>10.975849</td>\n",
       "      <td>3895.908691</td>\n",
       "      <td>0.055044</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>...</td>\n",
       "      <td>22695.388672</td>\n",
       "      <td>10225.309570</td>\n",
       "      <td>3.536903</td>\n",
       "      <td>2.865686</td>\n",
       "      <td>3.052810</td>\n",
       "      <td>196</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1898.588013</td>\n",
       "      <td>0.368630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173787</th>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>5.228067</td>\n",
       "      <td>0.220739</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>4.271331</td>\n",
       "      <td>3.276358</td>\n",
       "      <td>4010.781738</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.006417</td>\n",
       "      <td>...</td>\n",
       "      <td>16909.515625</td>\n",
       "      <td>9141.426758</td>\n",
       "      <td>3.087461</td>\n",
       "      <td>3.218034</td>\n",
       "      <td>2.375592</td>\n",
       "      <td>137</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1840.410034</td>\n",
       "      <td>0.246045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102544</th>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>39.069534</td>\n",
       "      <td>1.898197</td>\n",
       "      <td>0.120936</td>\n",
       "      <td>4.984982</td>\n",
       "      <td>0.468348</td>\n",
       "      <td>4144.546875</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>...</td>\n",
       "      <td>97612.804688</td>\n",
       "      <td>47118.785156</td>\n",
       "      <td>4.632295</td>\n",
       "      <td>4.711155</td>\n",
       "      <td>4.296878</td>\n",
       "      <td>477</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1899.793945</td>\n",
       "      <td>0.222060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LifeTime      dira  FlightDistance  FlightDistanceError        IP  \\\n",
       "id                                                                            \n",
       "18453471  0.001578  0.999999       14.033335             0.681401  0.016039   \n",
       "5364094   0.000988  0.999705        5.536157             0.302341  0.142163   \n",
       "11130990  0.000877  0.999984        6.117302             0.276463  0.034746   \n",
       "15173787  0.000854  0.999903        5.228067             0.220739  0.076389   \n",
       "1102544   0.001129  0.999995       39.069534             1.898197  0.120936   \n",
       "\n",
       "             IPSig  VertexChi2           pt   DOCAone   DOCAtwo  ...  \\\n",
       "id                                                               ...   \n",
       "18453471  0.451886    1.900433  1482.037476  0.066667  0.060602  ...   \n",
       "5364094   9.564503    0.865666  3050.720703  0.024022  0.019245  ...   \n",
       "11130990  1.970751   10.975849  3895.908691  0.055044  0.047947  ...   \n",
       "15173787  4.271331    3.276358  4010.781738  0.053779  0.006417  ...   \n",
       "1102544   4.984982    0.468348  4144.546875  0.004491  0.037326  ...   \n",
       "\n",
       "                  p1_p          p2_p    p0_eta    p1_eta    p2_eta  SPDhits  \\\n",
       "id                                                                            \n",
       "18453471  12290.760742  39264.398438  3.076006  4.003800  4.031514      458   \n",
       "5364094   16562.667969   7341.257812  3.228553  2.786543  2.975564      406   \n",
       "11130990  22695.388672  10225.309570  3.536903  2.865686  3.052810      196   \n",
       "15173787  16909.515625   9141.426758  3.087461  3.218034  2.375592      137   \n",
       "1102544   97612.804688  47118.785156  4.632295  4.711155  4.296878      477   \n",
       "\n",
       "          production  signal         mass  min_ANNmuon  \n",
       "id                                                      \n",
       "18453471         -99       0  1866.300049     0.277559  \n",
       "5364094          -99       0  1727.095947     0.225924  \n",
       "11130990         -99       0  1898.588013     0.368630  \n",
       "15173787         -99       0  1840.410034     0.246045  \n",
       "1102544          -99       0  1899.793945     0.222060  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add features\n",
      "Eliminate features\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/sionek/ugbc-gs\n",
    "train = pandas.read_csv(folder + 'training.csv', index_col='id')\n",
    "test  = pandas.read_csv(folder + 'test.csv', index_col='id')\n",
    "\n",
    "\n",
    "#--------------- feature engineering -------------- #\n",
    "def add_features(df):\n",
    "    # features used by the others on Kaggle\n",
    "    df['NEW_FD_SUMP']=df['FlightDistance']/(df['p0_p']+df['p1_p']+df['p2_p'])\n",
    "    df['NEW5_lt']=df['LifeTime']*(df['p0_IP']+df['p1_IP']+df['p2_IP'])/3\n",
    "    df['p_track_Chi2Dof_MAX'] = df.loc[:, ['p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof']].max(axis=1)\n",
    "    #df['flight_dist_sig'] = df['FlightDistance']/df['FlightDistanceError'] # modified to:\n",
    "    df['flight_dist_sig2'] = (df['FlightDistance']/df['FlightDistanceError'])**2\n",
    "    # features from phunter\n",
    "    df['flight_dist_sig'] = df['FlightDistance']/df['FlightDistanceError']\n",
    "    df['NEW_IP_dira'] = df['IP']*df['dira']\n",
    "    df['p0p2_ip_ratio']=df['IP']/df['IP_p0p2']\n",
    "    df['p1p2_ip_ratio']=df['IP']/df['IP_p1p2']\n",
    "    df['DCA_MAX'] = df.loc[:, ['DOCAone', 'DOCAtwo', 'DOCAthree']].max(axis=1)\n",
    "    df['iso_bdt_min'] = df.loc[:, ['p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT']].min(axis=1)\n",
    "    df['iso_min'] = df.loc[:, ['isolationa', 'isolationb', 'isolationc','isolationd', 'isolatione', 'isolationf']].min(axis=1)\n",
    "    # My:\n",
    "    # new combined features just to minimize their number;\n",
    "    # their physical sense doesn't matter\n",
    "    df['NEW_iso_abc'] = df['isolationa']*df['isolationb']*df['isolationc']\n",
    "    df['NEW_iso_def'] = df['isolationd']*df['isolatione']*df['isolationf']\n",
    "    df['NEW_pN_IP'] = df['p0_IP']+df['p1_IP']+df['p2_IP']\n",
    "    df['NEW_pN_p']  = df['p0_p']+df['p1_p']+df['p2_p']\n",
    "    df['NEW_IP_pNpN'] = df['IP_p0p2']*df['IP_p1p2']\n",
    "    df['NEW_pN_IPSig'] = df['p0_IPSig']+df['p1_IPSig']+df['p2_IPSig']\n",
    "    #My:\n",
    "    # \"super\" feature changing the result from 0.988641 to 0.991099\n",
    "    df['NEW_FD_LT']=df['FlightDistance']/df['LifeTime']\n",
    "    return df\n",
    "\n",
    "print(\"Add features\")\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "\n",
    "print(\"Eliminate features\")\n",
    "filter_out = ['id', 'min_ANNmuon', 'production', 'mass', 'signal',\n",
    "              'SPDhits','CDF1', 'CDF2', 'CDF3',\n",
    "              'isolationb', 'isolationc','p0_pt', 'p1_pt', 'p2_pt',\n",
    "              'p0_p', 'p1_p', 'p2_p', 'p0_eta', 'p1_eta', 'p2_eta',\n",
    "              'isolationa', 'isolationb', 'isolationc', 'isolationd', 'isolatione', 'isolationf',\n",
    "              'p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT',\n",
    "              'p0_IP', 'p1_IP', 'p2_IP',\n",
    "              'IP_p0p2', 'IP_p1p2',\n",
    "              'p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof',\n",
    "              'p0_IPSig', 'p1_IPSig', 'p2_IPSig',\n",
    "              'DOCAone', 'DOCAtwo', 'DOCAthree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training features\n",
    "Here we use subset of the all features to pass the agreement checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "#default\n",
    "variables = ['LifeTime',\n",
    "             'dira',\n",
    "             'FlightDistance',\n",
    "             'FlightDistanceError',\n",
    "             'IP',\n",
    "             'IPSig',\n",
    "             'VertexChi2',\n",
    "             'pt',\n",
    "             'DOCAone',\n",
    "             'DOCAtwo',\n",
    "             'DOCAthree',\n",
    "             'IP_p0p2',\n",
    "             'IP_p1p2',\n",
    "             'isolationa',\n",
    "             'isolationb',\n",
    "             'isolationc',\n",
    "             'isolationd',\n",
    "             'isolatione',\n",
    "             'isolationf',\n",
    "             'iso',\n",
    "             'CDF1',\n",
    "             'CDF2',\n",
    "             'CDF3',\n",
    "             'ISO_SumBDT',\n",
    "             'p0_IsoBDT',\n",
    "             'p1_IsoBDT',\n",
    "             'p2_IsoBDT',\n",
    "             'p0_track_Chi2Dof',\n",
    "             'p1_track_Chi2Dof',\n",
    "             'p2_track_Chi2Dof',\n",
    "             'p0_IP',\n",
    "             'p1_IP',\n",
    "             'p2_IP',\n",
    "             'p0_IPSig',\n",
    "             'p1_IPSig',\n",
    "             'p2_IPSig',\n",
    "             'p0_pt',\n",
    "             'p1_pt',\n",
    "             'p2_pt',\n",
    "             'p0_p',\n",
    "             'p1_p',\n",
    "             'p2_p',\n",
    "             'p0_eta',\n",
    "             'p1_eta',\n",
    "             'p2_eta',\n",
    "             'SPDhits',\n",
    "             ]\n",
    "print(len(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "#modified\n",
    "variables = list(f for f in train.columns if f not in filter_out)\n",
    "print(len(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing dataset\n",
    "df = train[variables]\n",
    "train_mean = df.mean()\n",
    "train_std = df.std()\n",
    "train_df = (df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative(batch_norm in model)\n",
    "train_df = train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure();\n",
    "df['DOCAone'].diff().hist(color=\"k\", alpha=0.5, bins=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    67552.000000\n",
       "mean         0.001255\n",
       "std          0.000779\n",
       "min          0.000144\n",
       "25%          0.000725\n",
       "50%          0.001061\n",
       "75%          0.001559\n",
       "max          0.022134\n",
       "Name: LifeTime, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['LifeTime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(len(variables)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.05)),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.05)), \n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.05)), \n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(50, activation=tf.keras.layers.LeakyReLU(alpha=0.05)),  \n",
    "  tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = train_df.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_df[\"DOCAone\"].to_numpy()\n",
    "print(a.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"DOCAone\"] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training arrays\n",
    "x_train = train_df.to_numpy()\n",
    "y_train = train['signal'].to_numpy()\n",
    "y_train = np.expand_dims(y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.4005 - accuracy: 0.8278\n",
      "Epoch 2/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3784 - accuracy: 0.8372\n",
      "Epoch 3/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3690 - accuracy: 0.8411\n",
      "Epoch 4/15\n",
      "1056/1056 [==============================] - 4s 4ms/step - loss: 0.3651 - accuracy: 0.8424\n",
      "Epoch 5/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3651 - accuracy: 0.8433\n",
      "Epoch 6/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3639 - accuracy: 0.8438\n",
      "Epoch 7/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3605 - accuracy: 0.8438\n",
      "Epoch 8/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3609 - accuracy: 0.8440\n",
      "Epoch 9/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3647 - accuracy: 0.8431\n",
      "Epoch 10/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3626 - accuracy: 0.8428\n",
      "Epoch 11/15\n",
      "1056/1056 [==============================] - 5s 4ms/step - loss: 0.3665 - accuracy: 0.8444\n",
      "Epoch 12/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3660 - accuracy: 0.8409\n",
      "Epoch 13/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3649 - accuracy: 0.8415\n",
      "Epoch 14/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3605 - accuracy: 0.8457\n",
      "Epoch 15/15\n",
      "1056/1056 [==============================] - 5s 5ms/step - loss: 0.3614 - accuracy: 0.8432\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=15, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agreement test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27458876 0.05568794 0.3891485  ... 0.8917255  0.982622   0.9739213 ]\n",
      "KS metric 0.07655233476343726 True\n"
     ]
    }
   ],
   "source": [
    "check_agreement = pandas.read_csv(folder + 'check_agreement.csv', index_col='id')\n",
    "check_agreement = add_features(check_agreement)\n",
    "agreement_probs = model.predict(check_agreement[variables].to_numpy()).squeeze()\n",
    "print(agreement_probs)\n",
    "ks = evaluation.compute_ks(\n",
    "    agreement_probs[check_agreement['signal'].values == 0],\n",
    "    agreement_probs[check_agreement['signal'].values == 1],\n",
    "    check_agreement[check_agreement['signal'] == 0]['weight'].values,\n",
    "    check_agreement[check_agreement['signal'] == 1]['weight'].values)\n",
    "print('KS metric', ks, ks < 0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01726463 0.19499862 0.48506302 ... 0.78839487 0.37928677 0.02886738]\n",
      "CvM metric 0.0010262050750394684 True\n"
     ]
    }
   ],
   "source": [
    "check_correlation = pandas.read_csv(folder + 'check_correlation.csv', index_col='id')\n",
    "check_correlation = add_features(check_correlation)\n",
    "correlation_probs = model.predict(check_correlation[variables].to_numpy()).squeeze()\n",
    "#pd.DataFrame(correlation_probs,\n",
    "  #                 columns=[variables])\n",
    "print(correlation_probs)\n",
    "cvm = evaluation.compute_cvm(correlation_probs, check_correlation['mass'])\n",
    "print('CvM metric', cvm, cvm < 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute weighted AUC on the training data with min_ANNmuon > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9228560388071492\n"
     ]
    }
   ],
   "source": [
    "train_eval = train[train['min_ANNmuon'] > 0.4]\n",
    "train_probs = model.predict(train_eval[variables].to_numpy()).squeeze()\n",
    "AUC = sklearn.metrics.roc_auc_score(train_eval['signal'], train_probs)\n",
    "print('AUC', AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test, create file for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.DataFrame({'id': test.index})\n",
    "result['prediction'] = model.predict(test[variables].to_numpy()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submission.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
