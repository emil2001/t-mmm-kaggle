{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "import evaluation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "GPU_fix = \"MemoryFix\" # Choose \"Disable\", \"MemoryFix\" or \"None\"\n",
    "\n",
    "if GPU_fix == \"Disable\":\n",
    "    try:\n",
    "        # Disable all GPUS\n",
    "        tf.config.set_visible_devices([], 'GPU')\n",
    "        visible_devices = tf.config.get_visible_devices()\n",
    "        for device in visible_devices:\n",
    "            assert device.device_type != 'GPU'\n",
    "    except:\n",
    "        # Invalid device or cannot modify virtual devices once initialized.\n",
    "        pass\n",
    "elif GPU_fix == \"MemoryFix\":\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/sionek/ugbc-gs\n",
    "folder = 'tau_data/'\n",
    "data = pandas.read_csv(folder + 'training.csv.zip', index_col='id')\n",
    "variables = ['LifeTime',\n",
    "             'dira',\n",
    "             'FlightDistance',\n",
    "             'FlightDistanceError',\n",
    "             'IP',\n",
    "             'IPSig',\n",
    "             'VertexChi2',\n",
    "             'pt',\n",
    "             'DOCAone',\n",
    "             'DOCAtwo',\n",
    "             'DOCAthree',\n",
    "             'IP_p0p2',\n",
    "             'IP_p1p2',\n",
    "             'isolationa',\n",
    "             'isolationb',\n",
    "             'isolationc',\n",
    "             'isolationd',\n",
    "             'isolatione',\n",
    "             'isolationf',\n",
    "             'iso',\n",
    "             'CDF1',\n",
    "             'CDF2',\n",
    "             'CDF3',\n",
    "             'ISO_SumBDT',\n",
    "             'p0_IsoBDT',\n",
    "             'p1_IsoBDT',\n",
    "             'p2_IsoBDT',\n",
    "             'p0_track_Chi2Dof',\n",
    "             'p1_track_Chi2Dof',\n",
    "             'p2_track_Chi2Dof',\n",
    "             'p0_IP',\n",
    "             'p1_IP',\n",
    "             'p2_IP',\n",
    "             'p0_IPSig',\n",
    "             'p1_IPSig',\n",
    "             'p2_IPSig',\n",
    "             'p0_pt',\n",
    "             'p1_pt',\n",
    "             'p2_pt',\n",
    "             'p0_p',\n",
    "             'p1_p',\n",
    "             'p2_p',\n",
    "             'p0_eta',\n",
    "             'p1_eta',\n",
    "             'p2_eta',\n",
    "             'SPDhits',\n",
    "             ]\n",
    "train_df = data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add features\n",
      "Eliminate features\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/sionek/ugbc-gs\n",
    "folder = 'tau_data/'\n",
    "data = pandas.read_csv(folder + 'training.csv.zip', index_col='id')\n",
    "#--------------- feature engineering -------------- #\n",
    "def add_features(df):\n",
    "    # features used by the others on Kaggle\n",
    "    df['NEW_FD_SUMP']=df['FlightDistance']/(df['p0_p']+df['p1_p']+df['p2_p'])\n",
    "    df['NEW5_lt']=df['LifeTime']*(df['p0_IP']+df['p1_IP']+df['p2_IP'])/3\n",
    "    df['p_track_Chi2Dof_MAX'] = df.loc[:, ['p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof']].max(axis=1)\n",
    "    #df['flight_dist_sig'] = df['FlightDistance']/df['FlightDistanceError'] # modified to:\n",
    "    df['flight_dist_sig2'] = (df['FlightDistance']/df['FlightDistanceError'])**2\n",
    "    # features from phunter\n",
    "    df['flight_dist_sig'] = df['FlightDistance']/df['FlightDistanceError']\n",
    "    df['NEW_IP_dira'] = df['IP']*df['dira']\n",
    "    df['p0p2_ip_ratio']=df['IP']/df['IP_p0p2']\n",
    "    df['p1p2_ip_ratio']=df['IP']/df['IP_p1p2']\n",
    "    df['DCA_MAX'] = df.loc[:, ['DOCAone', 'DOCAtwo', 'DOCAthree']].max(axis=1)\n",
    "    df['iso_bdt_min'] = df.loc[:, ['p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT']].min(axis=1)\n",
    "    df['iso_min'] = df.loc[:, ['isolationa', 'isolationb', 'isolationc','isolationd', 'isolatione', 'isolationf']].min(axis=1)\n",
    "    # My:\n",
    "    # new combined features just to minimize their number;\n",
    "    # their physical sense doesn't matter\n",
    "    df['NEW_iso_abc'] = df['isolationa']*df['isolationb']*df['isolationc']\n",
    "    df['NEW_iso_def'] = df['isolationd']*df['isolatione']*df['isolationf']\n",
    "    df['NEW_pN_IP'] = df['p0_IP']+df['p1_IP']+df['p2_IP']\n",
    "    df['NEW_pN_p']  = df['p0_p']+df['p1_p']+df['p2_p']\n",
    "    df['NEW_IP_pNpN'] = df['IP_p0p2']*df['IP_p1p2']\n",
    "    df['NEW_pN_IPSig'] = df['p0_IPSig']+df['p1_IPSig']+df['p2_IPSig']\n",
    "    #My:\n",
    "    # \"super\" feature changing the result from 0.988641 to 0.991099\n",
    "    df['NEW_FD_LT']=df['FlightDistance']/df['LifeTime']\n",
    "    return df\n",
    "\n",
    "print(\"Add features\")\n",
    "train_df = add_features(data)\n",
    "\n",
    "print(\"Eliminate features\")\n",
    "filter_out = ['id', 'min_ANNmuon', 'production', 'mass', 'signal',\n",
    "              'SPDhits','CDF1', 'CDF2', 'CDF3',\n",
    "              'p0_pt', 'p1_pt', 'p2_pt',\n",
    "              'p0_p', 'p1_p', 'p2_p', 'p0_eta', 'p1_eta', 'p2_eta',\n",
    "              'isolationa', 'isolationb', 'isolationc', 'isolationd', 'isolatione', 'isolationf',\n",
    "              'p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT',\n",
    "              'p0_IP', 'p1_IP', 'p2_IP',\n",
    "              'IP_p0p2', 'IP_p1p2',\n",
    "              'p0_track_Chi2Dof', 'p1_track_Chi2Dof', 'p2_track_Chi2Dof',\n",
    "              'p0_IPSig', 'p1_IPSig', 'p2_IPSig',\n",
    "              'DOCAone', 'DOCAtwo', 'DOCAthree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'tau_data/'\n",
    "data = pandas.read_csv(folder + 'training.csv.zip')\n",
    "filter1 = ['production', 'mass', 'signal', 'weight','min_ANNmuon']\n",
    "data1  = data[list(f for f in data.columns if f not in filter1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'LifeTime', 'dira', 'FlightDistance', 'FlightDistanceError', 'IP',\n",
       "       'IPSig', 'VertexChi2', 'pt', 'DOCAone', 'DOCAtwo', 'DOCAthree',\n",
       "       'IP_p0p2', 'IP_p1p2', 'isolationa', 'isolationb', 'isolationc',\n",
       "       'isolationd', 'isolatione', 'isolationf', 'iso', 'CDF1', 'CDF2', 'CDF3',\n",
       "       'ISO_SumBDT', 'p0_IsoBDT', 'p1_IsoBDT', 'p2_IsoBDT', 'p0_track_Chi2Dof',\n",
       "       'p1_track_Chi2Dof', 'p2_track_Chi2Dof', 'p0_IP', 'p1_IP', 'p2_IP',\n",
       "       'p0_IPSig', 'p1_IPSig', 'p2_IPSig', 'p0_pt', 'p1_pt', 'p2_pt', 'p0_p',\n",
       "       'p1_p', 'p2_p', 'p0_eta', 'p1_eta', 'p2_eta', 'SPDhits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entityset: data\n",
      "  Entities:\n",
      "    df [Rows: 67553, Columns: 47]\n",
      "  Relationships:\n",
      "    No relationships\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\featuretools\\__init__.py:60: FutureWarning: The next non-bugfix release of Featuretools will not support Python 3.6\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "es = ft.EntitySet(id='data')\n",
    "es.entity_from_dataframe(entity_id = 'df', dataframe = data1, index = 'id')\n",
    "print(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1081 features\n",
      "EntitySet scattered to 3 workers in 3 seconds                                                                          \n",
      "Elapsed: 00:08 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, \n",
    "target_entity = 'df', \n",
    "max_depth = 1, \n",
    "verbose = 1, \n",
    "n_jobs = 3,\n",
    "trans_primitives = ['add_numeric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54042, 1081), (13511, 1081))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    feature_matrix,\n",
    "    data['signal'],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "sel_.fit(scaler.transform(x_train.fillna(0)), y_train)\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 1081\n",
      "selected features: 461\n",
      "features with coefficients shrank to zero: 596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((54042, 461), (13511, 461))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat =x_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((x_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))\n",
    "removed_feats = x_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats\n",
    "x_train_selected = sel_.transform(x_train.fillna(0))\n",
    "x_val_selected = sel_.transform(x_val.fillna(0))\n",
    "x_train_selected.shape, x_val_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = feature_matrix[list(f for f in feature_matrix.columns if f not in filter1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "#modified\n",
    "variables_mod = list(f for f in data.columns if f not in filter_out)\n",
    "print(len(variables_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = data[variables_mod]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(train_df)) < 0.8\n",
    "train = train_df[msk]\n",
    "val = train_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation samples: 13555\n",
      "train samples: 53998\n"
     ]
    }
   ],
   "source": [
    "print('validation samples:',len(val))\n",
    "print('train samples:',len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training arrays\n",
    "x_train = train\n",
    "y_train = data['signal'][msk].to_numpy()\n",
    "y_train = np.expand_dims(y_train,1)\n",
    "x_val = val\n",
    "y_val = data['signal'][~msk].to_numpy()\n",
    "y_val = np.expand_dims(y_val,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_agreement = pandas.read_csv(folder + 'check_agreement.csv.zip', index_col='id')\n",
    "check_agreement = add_features(check_agreement)\n",
    "check_agreement1 = check_agreement[variables_mod].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_correlation = pandas.read_csv(folder + 'check_correlation.csv.zip', index_col='id')\n",
    "check_correlation = add_features(check_correlation)\n",
    "check_correlation1 = check_correlation[variables_mod].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(check_agreement,check_correlation):\n",
    "    def my_loss_in(y_true, y_pred):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        check_correlation1 = check_correlation[variables_mod].to_numpy()\n",
    "        check_agreement1 = check_agreement[variables_mod].to_numpy()\n",
    "        #agreement_probs = model1m(check_agreement1).numpy()\n",
    "        #ks = evaluation.compute_ks(\n",
    "           # agreement_probs[check_agreement['signal'].values == 0],\n",
    "           # agreement_probs[check_agreement['signal'].values == 1],\n",
    "           # check_agreement[check_agreement['signal'] == 0]['weight'].values,\n",
    "           # check_agreement[check_agreement['signal'] == 1]['weight'].values)\n",
    "        #correlation_probs = model1m(check_correlation1).numpy()\n",
    "        correlation_probs = model1m(check_correlation1).numpy(lambda x: tf.py_function(parse_tfrecord(x, class_table, size), [x], (tf.uint8, tf.float32)))\n",
    "        cvm = evaluation.compute_cvm(correlation_probs, check_correlation['mass'])\n",
    "        return bce(y_true, y_pred) + 10*exp(cvm)\n",
    "    return my_loss_in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    #self.inputs = tf.keras.layers.InputLayer(len(variables_mod))\n",
    "    self.bnorm1 = tf.keras.layers.BatchNormalization()\n",
    "    self.bnorm2 = tf.keras.layers.BatchNormalization()\n",
    "    self.bnorm3 = tf.keras.layers.BatchNormalization()\n",
    "    self.bnorm4 = tf.keras.layers.BatchNormalization()\n",
    "    self.dropout1 = tf.keras.layers.Dropout(0.3)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(0.3)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(0.3)\n",
    "    self.dropout4 = tf.keras.layers.Dropout(0.3)\n",
    "    self.dense1 = tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    self.dense2 = tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    self.dense3 = tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    self.dense4 = tf.keras.layers.Dense(50, activation=tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    self.dense5 = tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    #x = self.inputs(inputs)\n",
    "    x = self.bnorm1(inputs)\n",
    "    x = self.dropout1(x)\n",
    "    x = self.dense1(x)\n",
    "    x = self.bnorm2(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.dense2(x)\n",
    "    x = self.bnorm3(x)\n",
    "    x = self.dropout3(x)\n",
    "    x = self.dense3(x)\n",
    "    x = self.bnorm4(x)\n",
    "    x = self.dropout4(x)\n",
    "    x = self.dense4(x)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    agreement_probs = self.predict(check_agreement1)\n",
    "    ks = evaluation.compute_ks(\n",
    "        agreement_probs[check_agreement['signal'].values == 0],\n",
    "        agreement_probs[check_agreement['signal'].values == 1],\n",
    "        check_agreement[check_agreement['signal'] == 0]['weight'].values,\n",
    "        check_agreement[check_agreement['signal'] == 1]['weight'].values)\n",
    "    correlation_probs = self.predict(check_correlation1)\n",
    "    cvm = evaluation.compute_cvm(correlation_probs, check_correlation['mass'])\n",
    "    loss = bce(y_true, y_pred) + exp(ks) + 10*exp(cvm)\n",
    "    self.add_loss(self)\n",
    "    return self.dense5(x)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "#model.build(input_shape = (len(variables_mod),1))\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch % 300 != 0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание тюнера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=len(variables_mod)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    for i in range(hp.Int('num_layers', 2, 5)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=10,\n",
    "                                            max_value=200,\n",
    "                                            step=10),\n",
    "                               activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='BinaryCrossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='tuner1',\n",
    "    project_name='ttt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train,\n",
    "             epochs=100,\n",
    "             validation_data=(x_val, y_val), batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_tuned = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(len(selected_feat)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2)), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2)), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(50, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),  \n",
    "  tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "])\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1m = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(len(variables_mod)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.2)), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2)), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(50, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),  \n",
    "  tf.keras.layers.Dense(1, activation = tf.keras.activations.sigmoid)\n",
    "])\n",
    "model1m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input\n",
    "from tensorflow.keras.layers import PReLU\n",
    "model = Sequential()\n",
    "model.add(Input(shape=len(variables_mod)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(75))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.13))\n",
    "model.add(Dense(60))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.11))\n",
    "model.add(Dense(45))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.09))\n",
    "model.add(Dense(30))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dropout(0.07))\n",
    "model.add(Dense(15))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='BinaryCrossentropy', optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.4168 - accuracy: 0.8131 - val_loss: 0.3427 - val_accuracy: 0.8537\n",
      "Epoch 2/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3974 - accuracy: 0.8240 - val_loss: 0.3406 - val_accuracy: 0.8526\n",
      "Epoch 3/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3937 - accuracy: 0.8270 - val_loss: 0.3392 - val_accuracy: 0.8568\n",
      "Epoch 4/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3904 - accuracy: 0.8280 - val_loss: 0.3385 - val_accuracy: 0.8565\n",
      "Epoch 5/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3873 - accuracy: 0.8304 - val_loss: 0.3393 - val_accuracy: 0.8589\n",
      "Epoch 6/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3867 - accuracy: 0.8310 - val_loss: 0.3413 - val_accuracy: 0.8576\n",
      "Epoch 7/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3859 - accuracy: 0.8317 - val_loss: 0.3360 - val_accuracy: 0.8600\n",
      "Epoch 8/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3837 - accuracy: 0.8316 - val_loss: 0.3399 - val_accuracy: 0.8581\n",
      "Epoch 9/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3822 - accuracy: 0.8331 - val_loss: 0.3397 - val_accuracy: 0.8598\n",
      "Epoch 10/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3830 - accuracy: 0.8308 - val_loss: 0.3371 - val_accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3816 - accuracy: 0.8332 - val_loss: 0.3328 - val_accuracy: 0.8606\n",
      "Epoch 12/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3803 - accuracy: 0.8337 - val_loss: 0.3391 - val_accuracy: 0.8554\n",
      "Epoch 13/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3802 - accuracy: 0.8330 - val_loss: 0.3399 - val_accuracy: 0.8603\n",
      "Epoch 14/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3791 - accuracy: 0.8336 - val_loss: 0.3342 - val_accuracy: 0.8589\n",
      "Epoch 15/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3822 - accuracy: 0.8319 - val_loss: 0.3370 - val_accuracy: 0.8603\n",
      "Epoch 16/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3792 - accuracy: 0.8342 - val_loss: 0.3353 - val_accuracy: 0.8572\n",
      "Epoch 17/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3774 - accuracy: 0.8363 - val_loss: 0.3326 - val_accuracy: 0.8608\n",
      "Epoch 18/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3787 - accuracy: 0.8332 - val_loss: 0.3349 - val_accuracy: 0.8581\n",
      "Epoch 19/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3782 - accuracy: 0.8332 - val_loss: 0.3345 - val_accuracy: 0.8602\n",
      "Epoch 20/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3785 - accuracy: 0.8339 - val_loss: 0.3403 - val_accuracy: 0.8590\n",
      "Epoch 21/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3781 - accuracy: 0.8348 - val_loss: 0.3347 - val_accuracy: 0.8602\n",
      "Epoch 22/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3770 - accuracy: 0.8355 - val_loss: 0.3350 - val_accuracy: 0.8625\n",
      "Epoch 23/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3742 - accuracy: 0.8363 - val_loss: 0.3342 - val_accuracy: 0.8615\n",
      "Epoch 24/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3767 - accuracy: 0.8346 - val_loss: 0.3294 - val_accuracy: 0.8604\n",
      "Epoch 25/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.3299 - val_accuracy: 0.8605\n",
      "Epoch 26/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3765 - accuracy: 0.8361 - val_loss: 0.3333 - val_accuracy: 0.8585\n",
      "Epoch 27/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3770 - accuracy: 0.8348 - val_loss: 0.3344 - val_accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3779 - accuracy: 0.8356 - val_loss: 0.3294 - val_accuracy: 0.8607\n",
      "Epoch 29/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3748 - accuracy: 0.8340 - val_loss: 0.3355 - val_accuracy: 0.8603\n",
      "Epoch 30/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3750 - accuracy: 0.8361 - val_loss: 0.3320 - val_accuracy: 0.8612\n",
      "Epoch 31/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3738 - accuracy: 0.8360 - val_loss: 0.3343 - val_accuracy: 0.8607\n",
      "Epoch 32/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3769 - accuracy: 0.8361 - val_loss: 0.3305 - val_accuracy: 0.8622\n",
      "Epoch 33/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3747 - accuracy: 0.8358 - val_loss: 0.3307 - val_accuracy: 0.8622\n",
      "Epoch 34/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3734 - accuracy: 0.8372 - val_loss: 0.3326 - val_accuracy: 0.8609\n",
      "Epoch 35/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3742 - accuracy: 0.8374 - val_loss: 0.3341 - val_accuracy: 0.8607\n",
      "Epoch 36/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3761 - accuracy: 0.8377 - val_loss: 0.3291 - val_accuracy: 0.8625\n",
      "Epoch 37/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3748 - accuracy: 0.8355 - val_loss: 0.3333 - val_accuracy: 0.8615\n",
      "Epoch 38/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3721 - accuracy: 0.8364 - val_loss: 0.3334 - val_accuracy: 0.8592\n",
      "Epoch 39/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3727 - accuracy: 0.8376 - val_loss: 0.3292 - val_accuracy: 0.8601\n",
      "Epoch 40/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3749 - accuracy: 0.8370 - val_loss: 0.3315 - val_accuracy: 0.8614\n",
      "Epoch 41/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3731 - accuracy: 0.8353 - val_loss: 0.3376 - val_accuracy: 0.8595\n",
      "Epoch 42/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3760 - accuracy: 0.8360 - val_loss: 0.3302 - val_accuracy: 0.8610\n",
      "Epoch 43/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3710 - accuracy: 0.8383 - val_loss: 0.3349 - val_accuracy: 0.8607\n",
      "Epoch 44/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3735 - accuracy: 0.8376 - val_loss: 0.3317 - val_accuracy: 0.8616\n",
      "Epoch 45/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3720 - accuracy: 0.8365 - val_loss: 0.3312 - val_accuracy: 0.8595\n",
      "Epoch 46/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3743 - accuracy: 0.8360 - val_loss: 0.3359 - val_accuracy: 0.8603\n",
      "Epoch 47/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3732 - accuracy: 0.8374 - val_loss: 0.3301 - val_accuracy: 0.8601\n",
      "Epoch 48/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3748 - accuracy: 0.8369 - val_loss: 0.3329 - val_accuracy: 0.8613\n",
      "Epoch 49/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.3292 - val_accuracy: 0.8617\n",
      "Epoch 50/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3728 - accuracy: 0.8377 - val_loss: 0.3311 - val_accuracy: 0.8611\n",
      "Epoch 51/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3723 - accuracy: 0.8373 - val_loss: 0.3330 - val_accuracy: 0.8628\n",
      "Epoch 52/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3706 - accuracy: 0.8403 - val_loss: 0.3349 - val_accuracy: 0.8583\n",
      "Epoch 53/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3714 - accuracy: 0.8395 - val_loss: 0.3286 - val_accuracy: 0.8637\n",
      "Epoch 54/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3709 - accuracy: 0.8365 - val_loss: 0.3312 - val_accuracy: 0.8580\n",
      "Epoch 55/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3724 - accuracy: 0.8379 - val_loss: 0.3292 - val_accuracy: 0.8607\n",
      "Epoch 56/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3723 - accuracy: 0.8369 - val_loss: 0.3289 - val_accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3698 - accuracy: 0.8385 - val_loss: 0.3295 - val_accuracy: 0.8613\n",
      "Epoch 58/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3691 - accuracy: 0.8409 - val_loss: 0.3284 - val_accuracy: 0.8622\n",
      "Epoch 59/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3694 - accuracy: 0.8377 - val_loss: 0.3329 - val_accuracy: 0.8622\n",
      "Epoch 60/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3709 - accuracy: 0.8371 - val_loss: 0.3306 - val_accuracy: 0.8615\n",
      "Epoch 61/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.3288 - val_accuracy: 0.8614\n",
      "Epoch 62/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3711 - accuracy: 0.8392 - val_loss: 0.3326 - val_accuracy: 0.8592\n",
      "Epoch 63/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3715 - accuracy: 0.8361 - val_loss: 0.3307 - val_accuracy: 0.8601\n",
      "Epoch 64/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3699 - accuracy: 0.8391 - val_loss: 0.3302 - val_accuracy: 0.8595\n",
      "Epoch 65/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3720 - accuracy: 0.8390 - val_loss: 0.3338 - val_accuracy: 0.8598\n",
      "Epoch 66/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3695 - accuracy: 0.8394 - val_loss: 0.3316 - val_accuracy: 0.8556\n",
      "Epoch 67/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3708 - accuracy: 0.8374 - val_loss: 0.3293 - val_accuracy: 0.8595\n",
      "Epoch 68/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3691 - accuracy: 0.8400 - val_loss: 0.3322 - val_accuracy: 0.8625\n",
      "Epoch 69/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3714 - accuracy: 0.8382 - val_loss: 0.3271 - val_accuracy: 0.8608\n",
      "Epoch 70/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3691 - accuracy: 0.8391 - val_loss: 0.3287 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3694 - accuracy: 0.8377 - val_loss: 0.3300 - val_accuracy: 0.8646\n",
      "Epoch 72/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3700 - accuracy: 0.8385 - val_loss: 0.3307 - val_accuracy: 0.8559\n",
      "Epoch 73/100\n",
      "1695/1695 [==============================] - 8s 5ms/step - loss: 0.3684 - accuracy: 0.8396 - val_loss: 0.3309 - val_accuracy: 0.8607\n",
      "Epoch 74/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3704 - accuracy: 0.8379 - val_loss: 0.3340 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3690 - accuracy: 0.8376 - val_loss: 0.3260 - val_accuracy: 0.8625\n",
      "Epoch 76/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3675 - accuracy: 0.8401 - val_loss: 0.3315 - val_accuracy: 0.8622\n",
      "Epoch 77/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3701 - accuracy: 0.8383 - val_loss: 0.3292 - val_accuracy: 0.8615\n",
      "Epoch 78/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3680 - accuracy: 0.8384 - val_loss: 0.3306 - val_accuracy: 0.8621\n",
      "Epoch 79/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3669 - accuracy: 0.8398 - val_loss: 0.3298 - val_accuracy: 0.8608\n",
      "Epoch 80/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3680 - accuracy: 0.8389 - val_loss: 0.3258 - val_accuracy: 0.8614\n",
      "Epoch 81/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3663 - accuracy: 0.8416 - val_loss: 0.3302 - val_accuracy: 0.8588\n",
      "Epoch 82/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3694 - accuracy: 0.8371 - val_loss: 0.3315 - val_accuracy: 0.8625\n",
      "Epoch 83/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3668 - accuracy: 0.8408 - val_loss: 0.3269 - val_accuracy: 0.8604\n",
      "Epoch 84/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3668 - accuracy: 0.8405 - val_loss: 0.3294 - val_accuracy: 0.8602\n",
      "Epoch 85/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3692 - accuracy: 0.8383 - val_loss: 0.3266 - val_accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3683 - accuracy: 0.8404 - val_loss: 0.3300 - val_accuracy: 0.8615\n",
      "Epoch 87/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3672 - accuracy: 0.8399 - val_loss: 0.3278 - val_accuracy: 0.8603\n",
      "Epoch 88/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3687 - accuracy: 0.8401 - val_loss: 0.3314 - val_accuracy: 0.8609\n",
      "Epoch 89/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3687 - accuracy: 0.8401 - val_loss: 0.3271 - val_accuracy: 0.8603\n",
      "Epoch 90/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3672 - accuracy: 0.8383 - val_loss: 0.3317 - val_accuracy: 0.8604\n",
      "Epoch 91/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3663 - accuracy: 0.8390 - val_loss: 0.3329 - val_accuracy: 0.8594\n",
      "Epoch 92/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3690 - accuracy: 0.8393 - val_loss: 0.3325 - val_accuracy: 0.8636\n",
      "Epoch 93/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3680 - accuracy: 0.8394 - val_loss: 0.3300 - val_accuracy: 0.8609\n",
      "Epoch 94/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3681 - accuracy: 0.8386 - val_loss: 0.3303 - val_accuracy: 0.8601\n",
      "Epoch 95/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3668 - accuracy: 0.8405 - val_loss: 0.3287 - val_accuracy: 0.8604\n",
      "Epoch 96/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3692 - accuracy: 0.8379 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 97/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3694 - accuracy: 0.8381 - val_loss: 0.3270 - val_accuracy: 0.8616\n",
      "Epoch 98/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3678 - accuracy: 0.8395 - val_loss: 0.3337 - val_accuracy: 0.8543\n",
      "Epoch 99/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3685 - accuracy: 0.8387 - val_loss: 0.3282 - val_accuracy: 0.8613\n",
      "Epoch 100/100\n",
      "1695/1695 [==============================] - 7s 4ms/step - loss: 0.3681 - accuracy: 0.8389 - val_loss: 0.3277 - val_accuracy: 0.8607\n",
      "Epoch 1/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3606 - accuracy: 0.8434 - val_loss: 0.3252 - val_accuracy: 0.8604\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3611 - accuracy: 0.8438 - val_loss: 0.3279 - val_accuracy: 0.8629\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3592 - accuracy: 0.8440 - val_loss: 0.3293 - val_accuracy: 0.8620\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3604 - accuracy: 0.8430 - val_loss: 0.3315 - val_accuracy: 0.8602\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3592 - accuracy: 0.8434 - val_loss: 0.3318 - val_accuracy: 0.8601\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3599 - accuracy: 0.8446 - val_loss: 0.3291 - val_accuracy: 0.8618\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3607 - accuracy: 0.8437 - val_loss: 0.3288 - val_accuracy: 0.8627\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3607 - accuracy: 0.8429 - val_loss: 0.3278 - val_accuracy: 0.8586\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3608 - accuracy: 0.8410 - val_loss: 0.3260 - val_accuracy: 0.8634\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3611 - accuracy: 0.8426 - val_loss: 0.3282 - val_accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3598 - accuracy: 0.8424 - val_loss: 0.3280 - val_accuracy: 0.8608\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3592 - accuracy: 0.8422 - val_loss: 0.3268 - val_accuracy: 0.8623\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3583 - accuracy: 0.8426 - val_loss: 0.3268 - val_accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3574 - accuracy: 0.8439 - val_loss: 0.3276 - val_accuracy: 0.8604\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3597 - accuracy: 0.8435 - val_loss: 0.3289 - val_accuracy: 0.8602\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3594 - accuracy: 0.8444 - val_loss: 0.3295 - val_accuracy: 0.8613\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3593 - accuracy: 0.8445 - val_loss: 0.3258 - val_accuracy: 0.8613\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3573 - accuracy: 0.8451 - val_loss: 0.3260 - val_accuracy: 0.8629\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3598 - accuracy: 0.8431 - val_loss: 0.3271 - val_accuracy: 0.8622\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3596 - accuracy: 0.8427 - val_loss: 0.3256 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3608 - accuracy: 0.8414 - val_loss: 0.3251 - val_accuracy: 0.8623\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3613 - accuracy: 0.8426 - val_loss: 0.3277 - val_accuracy: 0.8628\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3592 - accuracy: 0.8449 - val_loss: 0.3262 - val_accuracy: 0.8629\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3591 - accuracy: 0.8431 - val_loss: 0.3245 - val_accuracy: 0.8619\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3588 - accuracy: 0.8439 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3592 - accuracy: 0.8435 - val_loss: 0.3283 - val_accuracy: 0.8634\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3590 - accuracy: 0.8438 - val_loss: 0.3267 - val_accuracy: 0.8628\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3586 - accuracy: 0.8443 - val_loss: 0.3263 - val_accuracy: 0.8615\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3574 - accuracy: 0.8448 - val_loss: 0.3264 - val_accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3601 - accuracy: 0.8445 - val_loss: 0.3283 - val_accuracy: 0.8589\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3581 - accuracy: 0.8434 - val_loss: 0.3293 - val_accuracy: 0.8629\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3602 - accuracy: 0.8429 - val_loss: 0.3242 - val_accuracy: 0.8632\n",
      "Epoch 33/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3582 - accuracy: 0.8429 - val_loss: 0.3266 - val_accuracy: 0.8616\n",
      "Epoch 34/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3572 - accuracy: 0.8460 - val_loss: 0.3281 - val_accuracy: 0.8622\n",
      "Epoch 35/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3579 - accuracy: 0.8447 - val_loss: 0.3255 - val_accuracy: 0.8607\n",
      "Epoch 36/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3569 - accuracy: 0.8456 - val_loss: 0.3247 - val_accuracy: 0.8624\n",
      "Epoch 37/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3591 - accuracy: 0.8443 - val_loss: 0.3282 - val_accuracy: 0.8623\n",
      "Epoch 38/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3592 - accuracy: 0.8440 - val_loss: 0.3254 - val_accuracy: 0.8614\n",
      "Epoch 39/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3597 - accuracy: 0.8430 - val_loss: 0.3249 - val_accuracy: 0.8634\n",
      "Epoch 40/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.3608 - accuracy: 0.8446 - val_loss: 0.3253 - val_accuracy: 0.8620\n",
      "Epoch 41/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.3590 - accuracy: 0.8445 - val_loss: 0.3268 - val_accuracy: 0.8619\n",
      "Epoch 42/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3600 - accuracy: 0.8439 - val_loss: 0.3303 - val_accuracy: 0.8616\n",
      "Epoch 43/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3610 - accuracy: 0.8423 - val_loss: 0.3260 - val_accuracy: 0.8640\n",
      "Epoch 44/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3591 - accuracy: 0.8444 - val_loss: 0.3272 - val_accuracy: 0.8616\n",
      "Epoch 45/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3587 - accuracy: 0.8450 - val_loss: 0.3263 - val_accuracy: 0.8607\n",
      "Epoch 46/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3597 - accuracy: 0.8437 - val_loss: 0.3288 - val_accuracy: 0.8585\n",
      "Epoch 47/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3578 - accuracy: 0.8438 - val_loss: 0.3266 - val_accuracy: 0.8594\n",
      "Epoch 48/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3601 - accuracy: 0.8430 - val_loss: 0.3280 - val_accuracy: 0.8619\n",
      "Epoch 49/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3586 - accuracy: 0.8436 - val_loss: 0.3271 - val_accuracy: 0.8619\n",
      "Epoch 50/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3594 - accuracy: 0.8436 - val_loss: 0.3246 - val_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3566 - accuracy: 0.8453 - val_loss: 0.3255 - val_accuracy: 0.8622\n",
      "Epoch 52/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3582 - accuracy: 0.8424 - val_loss: 0.3307 - val_accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3589 - accuracy: 0.8440 - val_loss: 0.3279 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3583 - accuracy: 0.8435 - val_loss: 0.3255 - val_accuracy: 0.8631\n",
      "Epoch 55/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3596 - accuracy: 0.8434 - val_loss: 0.3268 - val_accuracy: 0.8599\n",
      "Epoch 56/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3583 - accuracy: 0.8444 - val_loss: 0.3264 - val_accuracy: 0.8624\n",
      "Epoch 57/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3585 - accuracy: 0.8424 - val_loss: 0.3285 - val_accuracy: 0.8601\n",
      "Epoch 58/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3585 - accuracy: 0.8443 - val_loss: 0.3254 - val_accuracy: 0.8620\n",
      "Epoch 59/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3569 - accuracy: 0.8447 - val_loss: 0.3265 - val_accuracy: 0.8601\n",
      "Epoch 60/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3583 - accuracy: 0.8444 - val_loss: 0.3284 - val_accuracy: 0.8616\n",
      "Epoch 61/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3586 - accuracy: 0.8439 - val_loss: 0.3291 - val_accuracy: 0.8601\n",
      "Epoch 62/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3581 - accuracy: 0.8455 - val_loss: 0.3268 - val_accuracy: 0.8594\n",
      "Epoch 63/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3574 - accuracy: 0.8453 - val_loss: 0.3261 - val_accuracy: 0.8613\n",
      "Epoch 64/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3594 - accuracy: 0.8429 - val_loss: 0.3288 - val_accuracy: 0.8615\n",
      "Epoch 65/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3582 - accuracy: 0.8444 - val_loss: 0.3277 - val_accuracy: 0.8605\n",
      "Epoch 66/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3582 - accuracy: 0.8434 - val_loss: 0.3246 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3592 - accuracy: 0.8441 - val_loss: 0.3276 - val_accuracy: 0.8613\n",
      "Epoch 68/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3592 - accuracy: 0.8438 - val_loss: 0.3278 - val_accuracy: 0.8619\n",
      "Epoch 69/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3581 - accuracy: 0.8451 - val_loss: 0.3266 - val_accuracy: 0.8622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3584 - accuracy: 0.8450 - val_loss: 0.3285 - val_accuracy: 0.8625\n",
      "Epoch 71/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3582 - accuracy: 0.8431 - val_loss: 0.3320 - val_accuracy: 0.8604\n",
      "Epoch 72/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3600 - accuracy: 0.8433 - val_loss: 0.3268 - val_accuracy: 0.8601\n",
      "Epoch 73/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3590 - accuracy: 0.8441 - val_loss: 0.3285 - val_accuracy: 0.8623\n",
      "Epoch 74/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3565 - accuracy: 0.8458 - val_loss: 0.3272 - val_accuracy: 0.8607\n",
      "Epoch 75/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3583 - accuracy: 0.8440 - val_loss: 0.3259 - val_accuracy: 0.8622\n",
      "Epoch 76/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3573 - accuracy: 0.8451 - val_loss: 0.3270 - val_accuracy: 0.8622\n",
      "Epoch 77/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3579 - accuracy: 0.8435 - val_loss: 0.3294 - val_accuracy: 0.8623\n",
      "Epoch 78/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3597 - accuracy: 0.8433 - val_loss: 0.3278 - val_accuracy: 0.8621\n",
      "Epoch 79/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3599 - accuracy: 0.8436 - val_loss: 0.3247 - val_accuracy: 0.8616\n",
      "Epoch 80/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3584 - accuracy: 0.8431 - val_loss: 0.3270 - val_accuracy: 0.8622\n",
      "Epoch 81/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3574 - accuracy: 0.8439 - val_loss: 0.3312 - val_accuracy: 0.8632\n",
      "Epoch 82/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3595 - accuracy: 0.8438 - val_loss: 0.3273 - val_accuracy: 0.8649\n",
      "Epoch 83/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3594 - accuracy: 0.8426 - val_loss: 0.3274 - val_accuracy: 0.8619\n",
      "Epoch 84/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3585 - accuracy: 0.8435 - val_loss: 0.3254 - val_accuracy: 0.8631\n",
      "Epoch 85/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3591 - accuracy: 0.8435 - val_loss: 0.3284 - val_accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3588 - accuracy: 0.8452 - val_loss: 0.3275 - val_accuracy: 0.8613\n",
      "Epoch 87/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3576 - accuracy: 0.8459 - val_loss: 0.3261 - val_accuracy: 0.8611\n",
      "Epoch 88/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3563 - accuracy: 0.8450 - val_loss: 0.3265 - val_accuracy: 0.8604\n",
      "Epoch 89/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3597 - accuracy: 0.8428 - val_loss: 0.3272 - val_accuracy: 0.8617\n",
      "Epoch 90/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3574 - accuracy: 0.8454 - val_loss: 0.3281 - val_accuracy: 0.8606\n",
      "Epoch 91/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3574 - accuracy: 0.8442 - val_loss: 0.3279 - val_accuracy: 0.8631\n",
      "Epoch 92/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3595 - accuracy: 0.8422 - val_loss: 0.3280 - val_accuracy: 0.8578\n",
      "Epoch 93/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3589 - accuracy: 0.8437 - val_loss: 0.3259 - val_accuracy: 0.8625\n",
      "Epoch 94/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3572 - accuracy: 0.8446 - val_loss: 0.3280 - val_accuracy: 0.8602\n",
      "Epoch 95/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3586 - accuracy: 0.8425 - val_loss: 0.3253 - val_accuracy: 0.8621\n",
      "Epoch 96/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3587 - accuracy: 0.8421 - val_loss: 0.3246 - val_accuracy: 0.8633\n",
      "Epoch 97/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3570 - accuracy: 0.8446 - val_loss: 0.3248 - val_accuracy: 0.8631\n",
      "Epoch 98/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3578 - accuracy: 0.8445 - val_loss: 0.3266 - val_accuracy: 0.8626\n",
      "Epoch 99/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3585 - accuracy: 0.8441 - val_loss: 0.3282 - val_accuracy: 0.8625\n",
      "Epoch 100/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3589 - accuracy: 0.8427 - val_loss: 0.3241 - val_accuracy: 0.8621\n",
      "Epoch 1/100\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3553 - accuracy: 0.8446 - val_loss: 0.3245 - val_accuracy: 0.8616\n",
      "Epoch 2/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8477 - val_loss: 0.3247 - val_accuracy: 0.8606\n",
      "Epoch 3/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8451 - val_loss: 0.3248 - val_accuracy: 0.8634\n",
      "Epoch 4/100\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3544 - accuracy: 0.8462 - val_loss: 0.3240 - val_accuracy: 0.8640\n",
      "Epoch 5/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8456 - val_loss: 0.3257 - val_accuracy: 0.8635\n",
      "Epoch 6/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8465 - val_loss: 0.3228 - val_accuracy: 0.8629\n",
      "Epoch 7/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8479 - val_loss: 0.3244 - val_accuracy: 0.8636\n",
      "Epoch 8/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8456 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
      "Epoch 9/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8460 - val_loss: 0.3240 - val_accuracy: 0.8615\n",
      "Epoch 10/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8472 - val_loss: 0.3250 - val_accuracy: 0.8642\n",
      "Epoch 11/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8457 - val_loss: 0.3261 - val_accuracy: 0.8619\n",
      "Epoch 12/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8470 - val_loss: 0.3247 - val_accuracy: 0.8625\n",
      "Epoch 13/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8464 - val_loss: 0.3244 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3231 - val_accuracy: 0.8643\n",
      "Epoch 15/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8444 - val_loss: 0.3253 - val_accuracy: 0.8625\n",
      "Epoch 16/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8455 - val_loss: 0.3221 - val_accuracy: 0.8632\n",
      "Epoch 17/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8460 - val_loss: 0.3243 - val_accuracy: 0.8635\n",
      "Epoch 18/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8460 - val_loss: 0.3254 - val_accuracy: 0.8613\n",
      "Epoch 19/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8471 - val_loss: 0.3228 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 21/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8469 - val_loss: 0.3242 - val_accuracy: 0.8628\n",
      "Epoch 22/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8468 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 23/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8477 - val_loss: 0.3229 - val_accuracy: 0.8636\n",
      "Epoch 24/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8459 - val_loss: 0.3248 - val_accuracy: 0.8632\n",
      "Epoch 25/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8467 - val_loss: 0.3257 - val_accuracy: 0.8634\n",
      "Epoch 26/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8466 - val_loss: 0.3238 - val_accuracy: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8480 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 28/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8454 - val_loss: 0.3264 - val_accuracy: 0.8636\n",
      "Epoch 29/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8468 - val_loss: 0.3246 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8473 - val_loss: 0.3244 - val_accuracy: 0.8638\n",
      "Epoch 31/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8471 - val_loss: 0.3254 - val_accuracy: 0.8632\n",
      "Epoch 32/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8479 - val_loss: 0.3235 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3542 - accuracy: 0.8470 - val_loss: 0.3251 - val_accuracy: 0.8622\n",
      "Epoch 34/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8481 - val_loss: 0.3252 - val_accuracy: 0.8625\n",
      "Epoch 35/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8469 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8457 - val_loss: 0.3269 - val_accuracy: 0.8626\n",
      "Epoch 37/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8468 - val_loss: 0.3237 - val_accuracy: 0.8634\n",
      "Epoch 38/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8452 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 39/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8471 - val_loss: 0.3249 - val_accuracy: 0.8613\n",
      "Epoch 40/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8464 - val_loss: 0.3265 - val_accuracy: 0.8629\n",
      "Epoch 41/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8463 - val_loss: 0.3245 - val_accuracy: 0.8634\n",
      "Epoch 42/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8461 - val_loss: 0.3262 - val_accuracy: 0.8626\n",
      "Epoch 43/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8459 - val_loss: 0.3226 - val_accuracy: 0.8638\n",
      "Epoch 44/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8473 - val_loss: 0.3234 - val_accuracy: 0.8637\n",
      "Epoch 45/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8460 - val_loss: 0.3268 - val_accuracy: 0.8628\n",
      "Epoch 46/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8474 - val_loss: 0.3226 - val_accuracy: 0.8617\n",
      "Epoch 47/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8469 - val_loss: 0.3263 - val_accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8455 - val_loss: 0.3264 - val_accuracy: 0.8628\n",
      "Epoch 49/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8485 - val_loss: 0.3222 - val_accuracy: 0.8638\n",
      "Epoch 50/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8472 - val_loss: 0.3236 - val_accuracy: 0.8623\n",
      "Epoch 51/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8486 - val_loss: 0.3226 - val_accuracy: 0.8627\n",
      "Epoch 52/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8464 - val_loss: 0.3233 - val_accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8467 - val_loss: 0.3255 - val_accuracy: 0.8622\n",
      "Epoch 54/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8464 - val_loss: 0.3272 - val_accuracy: 0.8634\n",
      "Epoch 55/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8466 - val_loss: 0.3251 - val_accuracy: 0.8632\n",
      "Epoch 56/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8455 - val_loss: 0.3237 - val_accuracy: 0.8640\n",
      "Epoch 57/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8467 - val_loss: 0.3228 - val_accuracy: 0.8640\n",
      "Epoch 58/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8469 - val_loss: 0.3258 - val_accuracy: 0.8615\n",
      "Epoch 59/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8472 - val_loss: 0.3262 - val_accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8462 - val_loss: 0.3219 - val_accuracy: 0.8644\n",
      "Epoch 61/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8471 - val_loss: 0.3242 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8450 - val_loss: 0.3236 - val_accuracy: 0.8637\n",
      "Epoch 63/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8473 - val_loss: 0.3238 - val_accuracy: 0.8632\n",
      "Epoch 64/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8472 - val_loss: 0.3257 - val_accuracy: 0.8645\n",
      "Epoch 65/100\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8465 - val_loss: 0.3252 - val_accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8465 - val_loss: 0.3246 - val_accuracy: 0.8616\n",
      "Epoch 67/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8458 - val_loss: 0.3249 - val_accuracy: 0.8625\n",
      "Epoch 68/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8461 - val_loss: 0.3259 - val_accuracy: 0.8616\n",
      "Epoch 69/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8476 - val_loss: 0.3256 - val_accuracy: 0.8626\n",
      "Epoch 70/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8466 - val_loss: 0.3244 - val_accuracy: 0.8634\n",
      "Epoch 71/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8473 - val_loss: 0.3234 - val_accuracy: 0.8632\n",
      "Epoch 72/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8484 - val_loss: 0.3241 - val_accuracy: 0.8643\n",
      "Epoch 73/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8457 - val_loss: 0.3254 - val_accuracy: 0.8628\n",
      "Epoch 74/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8437 - val_loss: 0.3249 - val_accuracy: 0.8616\n",
      "Epoch 75/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8468 - val_loss: 0.3231 - val_accuracy: 0.8624\n",
      "Epoch 76/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8474 - val_loss: 0.3235 - val_accuracy: 0.8611\n",
      "Epoch 77/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8474 - val_loss: 0.3271 - val_accuracy: 0.8625\n",
      "Epoch 78/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8474 - val_loss: 0.3263 - val_accuracy: 0.8610\n",
      "Epoch 79/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8459 - val_loss: 0.3244 - val_accuracy: 0.8628\n",
      "Epoch 80/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8479 - val_loss: 0.3247 - val_accuracy: 0.8618\n",
      "Epoch 81/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8472 - val_loss: 0.3250 - val_accuracy: 0.8607\n",
      "Epoch 82/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8458 - val_loss: 0.3241 - val_accuracy: 0.8619\n",
      "Epoch 83/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8481 - val_loss: 0.3264 - val_accuracy: 0.8631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8467 - val_loss: 0.3233 - val_accuracy: 0.8640\n",
      "Epoch 85/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8466 - val_loss: 0.3254 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8469 - val_loss: 0.3255 - val_accuracy: 0.8604\n",
      "Epoch 87/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8473 - val_loss: 0.3238 - val_accuracy: 0.8623\n",
      "Epoch 88/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8457 - val_loss: 0.3252 - val_accuracy: 0.8626\n",
      "Epoch 89/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8488 - val_loss: 0.3251 - val_accuracy: 0.8620\n",
      "Epoch 90/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8474 - val_loss: 0.3255 - val_accuracy: 0.8626\n",
      "Epoch 91/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8471 - val_loss: 0.3250 - val_accuracy: 0.8627\n",
      "Epoch 92/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8454 - val_loss: 0.3261 - val_accuracy: 0.8636\n",
      "Epoch 93/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8480 - val_loss: 0.3256 - val_accuracy: 0.8635\n",
      "Epoch 94/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8456 - val_loss: 0.3231 - val_accuracy: 0.8652\n",
      "Epoch 95/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8456 - val_loss: 0.3265 - val_accuracy: 0.8632\n",
      "Epoch 96/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8460 - val_loss: 0.3255 - val_accuracy: 0.8625\n",
      "Epoch 97/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8480 - val_loss: 0.3225 - val_accuracy: 0.8634\n",
      "Epoch 98/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8463 - val_loss: 0.3244 - val_accuracy: 0.8638\n",
      "Epoch 99/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8465 - val_loss: 0.3244 - val_accuracy: 0.8621\n",
      "Epoch 100/100\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8468 - val_loss: 0.3248 - val_accuracy: 0.8623\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3504 - accuracy: 0.8486 - val_loss: 0.3221 - val_accuracy: 0.8640\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.8471 - val_loss: 0.3225 - val_accuracy: 0.8640\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8478 - val_loss: 0.3235 - val_accuracy: 0.8638\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3526 - accuracy: 0.8472 - val_loss: 0.3242 - val_accuracy: 0.8615\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8495 - val_loss: 0.3240 - val_accuracy: 0.8636\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8466 - val_loss: 0.3255 - val_accuracy: 0.8623\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8479 - val_loss: 0.3223 - val_accuracy: 0.8641\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8472 - val_loss: 0.3234 - val_accuracy: 0.8624\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8477 - val_loss: 0.3226 - val_accuracy: 0.8640\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8491 - val_loss: 0.3238 - val_accuracy: 0.8631\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3491 - accuracy: 0.8489 - val_loss: 0.3222 - val_accuracy: 0.8635\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8471 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8470 - val_loss: 0.3225 - val_accuracy: 0.8633\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.8482 - val_loss: 0.3234 - val_accuracy: 0.8639\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8484 - val_loss: 0.3244 - val_accuracy: 0.8635\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3509 - accuracy: 0.8487 - val_loss: 0.3247 - val_accuracy: 0.8639\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3509 - accuracy: 0.8481 - val_loss: 0.3244 - val_accuracy: 0.8635\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8485 - val_loss: 0.3227 - val_accuracy: 0.8647\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8481 - val_loss: 0.3237 - val_accuracy: 0.8621\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8484 - val_loss: 0.3223 - val_accuracy: 0.8623\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8489 - val_loss: 0.3227 - val_accuracy: 0.8613\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8478 - val_loss: 0.3225 - val_accuracy: 0.8624\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8480 - val_loss: 0.3246 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8468 - val_loss: 0.3235 - val_accuracy: 0.8625\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3495 - accuracy: 0.8474 - val_loss: 0.3227 - val_accuracy: 0.8642\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8473 - val_loss: 0.3232 - val_accuracy: 0.8640\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8485 - val_loss: 0.3221 - val_accuracy: 0.8649\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8481 - val_loss: 0.3244 - val_accuracy: 0.8634\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8463 - val_loss: 0.3222 - val_accuracy: 0.8641\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8493 - val_loss: 0.3236 - val_accuracy: 0.8645\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8474 - val_loss: 0.3235 - val_accuracy: 0.8640\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8484 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8479 - val_loss: 0.3219 - val_accuracy: 0.8638\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8491 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8482 - val_loss: 0.3252 - val_accuracy: 0.8640\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8481 - val_loss: 0.3235 - val_accuracy: 0.8617\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8466 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8495 - val_loss: 0.3246 - val_accuracy: 0.8634\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8483 - val_loss: 0.3227 - val_accuracy: 0.8637\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3528 - accuracy: 0.8458 - val_loss: 0.3237 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8481 - val_loss: 0.3228 - val_accuracy: 0.8632\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8478 - val_loss: 0.3224 - val_accuracy: 0.8643\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.8470 - val_loss: 0.3236 - val_accuracy: 0.8640\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8469 - val_loss: 0.3249 - val_accuracy: 0.8620\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8483 - val_loss: 0.3227 - val_accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8478 - val_loss: 0.3236 - val_accuracy: 0.8627\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8471 - val_loss: 0.3241 - val_accuracy: 0.8639\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8464 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8459 - val_loss: 0.3241 - val_accuracy: 0.8634\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8489 - val_loss: 0.3228 - val_accuracy: 0.8638\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8480 - val_loss: 0.3241 - val_accuracy: 0.8625\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8465 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.8495 - val_loss: 0.3223 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3507 - accuracy: 0.8484 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8487 - val_loss: 0.3223 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8478 - val_loss: 0.3242 - val_accuracy: 0.8625\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3489 - accuracy: 0.8496 - val_loss: 0.3225 - val_accuracy: 0.8629\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8477 - val_loss: 0.3243 - val_accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8484 - val_loss: 0.3225 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8466 - val_loss: 0.3214 - val_accuracy: 0.8634\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8474 - val_loss: 0.3258 - val_accuracy: 0.8645\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8475 - val_loss: 0.3259 - val_accuracy: 0.8628\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8466 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8493 - val_loss: 0.3224 - val_accuracy: 0.8634\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8496 - val_loss: 0.3240 - val_accuracy: 0.8631\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8483 - val_loss: 0.3249 - val_accuracy: 0.8640\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8481 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8462 - val_loss: 0.3254 - val_accuracy: 0.8623\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8484 - val_loss: 0.3239 - val_accuracy: 0.8624\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8470 - val_loss: 0.3249 - val_accuracy: 0.8631\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8470 - val_loss: 0.3256 - val_accuracy: 0.8626\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8479 - val_loss: 0.3243 - val_accuracy: 0.8637\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.3239 - val_accuracy: 0.8616\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8482 - val_loss: 0.3219 - val_accuracy: 0.8645\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8478 - val_loss: 0.3248 - val_accuracy: 0.8616\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8483 - val_loss: 0.3228 - val_accuracy: 0.8628\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8472 - val_loss: 0.3240 - val_accuracy: 0.8619\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8481 - val_loss: 0.3247 - val_accuracy: 0.8612\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8486 - val_loss: 0.3231 - val_accuracy: 0.8629\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3495 - accuracy: 0.8488 - val_loss: 0.3219 - val_accuracy: 0.8631\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.8482 - val_loss: 0.3232 - val_accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8475 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8470 - val_loss: 0.3242 - val_accuracy: 0.8643\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3495 - accuracy: 0.8481 - val_loss: 0.3234 - val_accuracy: 0.8633\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3513 - accuracy: 0.8471 - val_loss: 0.3225 - val_accuracy: 0.8651\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8489 - val_loss: 0.3246 - val_accuracy: 0.8635\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8483 - val_loss: 0.3226 - val_accuracy: 0.8634\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8480 - val_loss: 0.3235 - val_accuracy: 0.8640\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8482 - val_loss: 0.3261 - val_accuracy: 0.8631\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3489 - accuracy: 0.8484 - val_loss: 0.3233 - val_accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8481 - val_loss: 0.3240 - val_accuracy: 0.8637\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8492 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8472 - val_loss: 0.3235 - val_accuracy: 0.8636\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8485 - val_loss: 0.3220 - val_accuracy: 0.8642\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8460 - val_loss: 0.3242 - val_accuracy: 0.8634\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8463 - val_loss: 0.3226 - val_accuracy: 0.8634\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8479 - val_loss: 0.3220 - val_accuracy: 0.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8484 - val_loss: 0.3234 - val_accuracy: 0.8639\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8477 - val_loss: 0.3239 - val_accuracy: 0.8631\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 1s 4ms/step - loss: 0.3509 - accuracy: 0.8465 - val_loss: 0.3228 - val_accuracy: 0.8626\n"
     ]
    }
   ],
   "source": [
    "history_32 = model1m.fit(x_train, y_train, epochs = 100, batch_size = 32, validation_data = (x_val,y_val))\n",
    "model1m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history_64 = model1m.fit(x_train, y_train, epochs = 100, batch_size = 64, validation_data = (x_val,y_val))\n",
    "model1m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history_128 = model1m.fit(x_train, y_train, epochs = 100, batch_size = 128, validation_data = (x_val,y_val))\n",
    "model1m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history_256 = model1m.fit(x_train, y_train, epochs = 100, batch_size = 256, validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.4110 - accuracy: 0.8166 - val_loss: 0.3482 - val_accuracy: 0.8514\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3888 - accuracy: 0.8292 - val_loss: 0.3429 - val_accuracy: 0.8520\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3844 - accuracy: 0.8310 - val_loss: 0.3518 - val_accuracy: 0.8516\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3823 - accuracy: 0.8329 - val_loss: 0.3416 - val_accuracy: 0.8536\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3813 - accuracy: 0.8336 - val_loss: 0.3374 - val_accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3809 - accuracy: 0.8343 - val_loss: 0.3312 - val_accuracy: 0.8592\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3773 - accuracy: 0.8342 - val_loss: 0.3414 - val_accuracy: 0.8559\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3773 - accuracy: 0.8342 - val_loss: 0.3364 - val_accuracy: 0.8543\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3760 - accuracy: 0.8342 - val_loss: 0.3338 - val_accuracy: 0.8596\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3741 - accuracy: 0.8366 - val_loss: 0.3347 - val_accuracy: 0.8582\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3732 - accuracy: 0.8366 - val_loss: 0.3312 - val_accuracy: 0.8610\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3764 - accuracy: 0.8362 - val_loss: 0.3303 - val_accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3735 - accuracy: 0.8370 - val_loss: 0.3319 - val_accuracy: 0.8592\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3709 - accuracy: 0.8384 - val_loss: 0.3392 - val_accuracy: 0.8616\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3704 - accuracy: 0.8389 - val_loss: 0.3309 - val_accuracy: 0.8618\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3716 - accuracy: 0.8379 - val_loss: 0.3290 - val_accuracy: 0.8616\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3725 - accuracy: 0.8367 - val_loss: 0.3321 - val_accuracy: 0.8609\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3723 - accuracy: 0.8370 - val_loss: 0.3310 - val_accuracy: 0.8611\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3710 - accuracy: 0.8391 - val_loss: 0.3307 - val_accuracy: 0.8619\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3689 - accuracy: 0.8394 - val_loss: 0.3315 - val_accuracy: 0.8611\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3679 - accuracy: 0.8405 - val_loss: 0.3298 - val_accuracy: 0.8613\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3709 - accuracy: 0.8376 - val_loss: 0.3326 - val_accuracy: 0.8631\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3672 - accuracy: 0.8394 - val_loss: 0.3268 - val_accuracy: 0.8648\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3680 - accuracy: 0.8406 - val_loss: 0.3303 - val_accuracy: 0.8606\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3672 - accuracy: 0.8391 - val_loss: 0.3271 - val_accuracy: 0.8612\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3670 - accuracy: 0.8399 - val_loss: 0.3303 - val_accuracy: 0.8619\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3689 - accuracy: 0.8392 - val_loss: 0.3296 - val_accuracy: 0.8614\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3666 - accuracy: 0.8415 - val_loss: 0.3279 - val_accuracy: 0.8585\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3692 - accuracy: 0.8387 - val_loss: 0.3304 - val_accuracy: 0.8591\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3680 - accuracy: 0.8388 - val_loss: 0.3262 - val_accuracy: 0.8599\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3678 - accuracy: 0.8393 - val_loss: 0.3303 - val_accuracy: 0.8607\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3674 - accuracy: 0.8407 - val_loss: 0.3323 - val_accuracy: 0.8590\n",
      "Epoch 33/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3660 - accuracy: 0.8410 - val_loss: 0.3303 - val_accuracy: 0.8617\n",
      "Epoch 34/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3674 - accuracy: 0.8383 - val_loss: 0.3307 - val_accuracy: 0.8619\n",
      "Epoch 35/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3676 - accuracy: 0.8385 - val_loss: 0.3321 - val_accuracy: 0.8605\n",
      "Epoch 36/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3666 - accuracy: 0.8403 - val_loss: 0.3312 - val_accuracy: 0.8616\n",
      "Epoch 37/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3669 - accuracy: 0.8401 - val_loss: 0.3291 - val_accuracy: 0.8619\n",
      "Epoch 38/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3686 - accuracy: 0.8389 - val_loss: 0.3287 - val_accuracy: 0.8614\n",
      "Epoch 39/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3658 - accuracy: 0.8417 - val_loss: 0.3313 - val_accuracy: 0.8597\n",
      "Epoch 40/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3671 - accuracy: 0.8401 - val_loss: 0.3298 - val_accuracy: 0.8611\n",
      "Epoch 41/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3659 - accuracy: 0.8410 - val_loss: 0.3262 - val_accuracy: 0.8619\n",
      "Epoch 42/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3666 - accuracy: 0.8408 - val_loss: 0.3300 - val_accuracy: 0.8621\n",
      "Epoch 43/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3652 - accuracy: 0.8417 - val_loss: 0.3264 - val_accuracy: 0.8613\n",
      "Epoch 44/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3649 - accuracy: 0.8429 - val_loss: 0.3275 - val_accuracy: 0.8628\n",
      "Epoch 45/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3645 - accuracy: 0.8412 - val_loss: 0.3341 - val_accuracy: 0.8602\n",
      "Epoch 46/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3644 - accuracy: 0.8435 - val_loss: 0.3286 - val_accuracy: 0.8622\n",
      "Epoch 47/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3687 - accuracy: 0.8394 - val_loss: 0.3293 - val_accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3665 - accuracy: 0.8393 - val_loss: 0.3281 - val_accuracy: 0.8607\n",
      "Epoch 49/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3627 - accuracy: 0.8427 - val_loss: 0.3292 - val_accuracy: 0.8616\n",
      "Epoch 50/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3657 - accuracy: 0.8414 - val_loss: 0.3320 - val_accuracy: 0.8602\n",
      "Epoch 51/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3634 - accuracy: 0.8403 - val_loss: 0.3247 - val_accuracy: 0.8619\n",
      "Epoch 52/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3644 - accuracy: 0.8401 - val_loss: 0.3305 - val_accuracy: 0.8620\n",
      "Epoch 53/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3659 - accuracy: 0.8412 - val_loss: 0.3271 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3639 - accuracy: 0.8413 - val_loss: 0.3266 - val_accuracy: 0.8601\n",
      "Epoch 55/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3667 - accuracy: 0.8414 - val_loss: 0.3301 - val_accuracy: 0.8602\n",
      "Epoch 56/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3650 - accuracy: 0.8414 - val_loss: 0.3268 - val_accuracy: 0.8622\n",
      "Epoch 57/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3668 - accuracy: 0.8418 - val_loss: 0.3281 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3636 - accuracy: 0.8403 - val_loss: 0.3287 - val_accuracy: 0.8610\n",
      "Epoch 59/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3646 - accuracy: 0.8424 - val_loss: 0.3336 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3635 - accuracy: 0.8420 - val_loss: 0.3315 - val_accuracy: 0.8598\n",
      "Epoch 61/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3639 - accuracy: 0.8409 - val_loss: 0.3284 - val_accuracy: 0.8619\n",
      "Epoch 62/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3641 - accuracy: 0.8417 - val_loss: 0.3288 - val_accuracy: 0.8634\n",
      "Epoch 63/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3651 - accuracy: 0.8408 - val_loss: 0.3277 - val_accuracy: 0.8605\n",
      "Epoch 64/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3630 - accuracy: 0.8411 - val_loss: 0.3274 - val_accuracy: 0.8592\n",
      "Epoch 65/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3638 - accuracy: 0.8415 - val_loss: 0.3262 - val_accuracy: 0.8621\n",
      "Epoch 66/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3637 - accuracy: 0.8420 - val_loss: 0.3273 - val_accuracy: 0.8610\n",
      "Epoch 67/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3637 - accuracy: 0.8419 - val_loss: 0.3301 - val_accuracy: 0.8607\n",
      "Epoch 68/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3653 - accuracy: 0.8404 - val_loss: 0.3332 - val_accuracy: 0.8621\n",
      "Epoch 69/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3626 - accuracy: 0.8410 - val_loss: 0.3284 - val_accuracy: 0.8619\n",
      "Epoch 70/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.8397 - val_loss: 0.3270 - val_accuracy: 0.8622\n",
      "Epoch 71/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3637 - accuracy: 0.8429 - val_loss: 0.3271 - val_accuracy: 0.8610\n",
      "Epoch 72/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3618 - accuracy: 0.8426 - val_loss: 0.3318 - val_accuracy: 0.8612\n",
      "Epoch 73/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3644 - accuracy: 0.8431 - val_loss: 0.3267 - val_accuracy: 0.8610\n",
      "Epoch 74/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3636 - accuracy: 0.8411 - val_loss: 0.3284 - val_accuracy: 0.8629\n",
      "Epoch 75/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3628 - accuracy: 0.8416 - val_loss: 0.3260 - val_accuracy: 0.8632\n",
      "Epoch 76/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3622 - accuracy: 0.8437 - val_loss: 0.3284 - val_accuracy: 0.8592\n",
      "Epoch 77/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3637 - accuracy: 0.8411 - val_loss: 0.3255 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3624 - accuracy: 0.8432 - val_loss: 0.3263 - val_accuracy: 0.8628\n",
      "Epoch 79/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3622 - accuracy: 0.8432 - val_loss: 0.3274 - val_accuracy: 0.8629\n",
      "Epoch 80/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3620 - accuracy: 0.8428 - val_loss: 0.3282 - val_accuracy: 0.8623\n",
      "Epoch 81/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3634 - accuracy: 0.8416 - val_loss: 0.3322 - val_accuracy: 0.8587\n",
      "Epoch 82/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3625 - accuracy: 0.8419 - val_loss: 0.3255 - val_accuracy: 0.8601\n",
      "Epoch 83/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3624 - accuracy: 0.8429 - val_loss: 0.3259 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3632 - accuracy: 0.8410 - val_loss: 0.3262 - val_accuracy: 0.8601\n",
      "Epoch 85/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3628 - accuracy: 0.8439 - val_loss: 0.3281 - val_accuracy: 0.8625\n",
      "Epoch 86/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3635 - accuracy: 0.8416 - val_loss: 0.3345 - val_accuracy: 0.8573\n",
      "Epoch 87/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3631 - accuracy: 0.8418 - val_loss: 0.3277 - val_accuracy: 0.8612\n",
      "Epoch 88/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3632 - accuracy: 0.8440 - val_loss: 0.3270 - val_accuracy: 0.8586\n",
      "Epoch 89/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3614 - accuracy: 0.8426 - val_loss: 0.3270 - val_accuracy: 0.8620\n",
      "Epoch 90/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3633 - accuracy: 0.8423 - val_loss: 0.3310 - val_accuracy: 0.8579\n",
      "Epoch 91/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3626 - accuracy: 0.8418 - val_loss: 0.3270 - val_accuracy: 0.8616\n",
      "Epoch 92/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3610 - accuracy: 0.8411 - val_loss: 0.3328 - val_accuracy: 0.8626\n",
      "Epoch 93/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3640 - accuracy: 0.8419 - val_loss: 0.3289 - val_accuracy: 0.8607\n",
      "Epoch 94/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3631 - accuracy: 0.8422 - val_loss: 0.3315 - val_accuracy: 0.8575\n",
      "Epoch 95/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3631 - accuracy: 0.8431 - val_loss: 0.3295 - val_accuracy: 0.8613\n",
      "Epoch 96/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3635 - accuracy: 0.8411 - val_loss: 0.3361 - val_accuracy: 0.8598\n",
      "Epoch 97/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3616 - accuracy: 0.8420 - val_loss: 0.3259 - val_accuracy: 0.8625\n",
      "Epoch 98/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3617 - accuracy: 0.8420 - val_loss: 0.3260 - val_accuracy: 0.8640\n",
      "Epoch 99/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3622 - accuracy: 0.8408 - val_loss: 0.3253 - val_accuracy: 0.8622\n",
      "Epoch 100/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3647 - accuracy: 0.8415 - val_loss: 0.3312 - val_accuracy: 0.8616\n"
     ]
    }
   ],
   "source": [
    "history_64 = model1m.fit(x_train, y_train, epochs = 100, batch_size = 64, validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.3619 - accuracy: 0.8436 - val_loss: 0.2960 - val_accuracy: 0.8758\n",
      "Epoch 2/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3216 - accuracy: 0.8652 - val_loss: 0.2875 - val_accuracy: 0.8797\n",
      "Epoch 3/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3151 - accuracy: 0.8688 - val_loss: 0.2823 - val_accuracy: 0.8800\n",
      "Epoch 4/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3083 - accuracy: 0.8718 - val_loss: 0.2795 - val_accuracy: 0.8856\n",
      "Epoch 5/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3079 - accuracy: 0.8726 - val_loss: 0.2774 - val_accuracy: 0.8837\n",
      "Epoch 6/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.8734 - val_loss: 0.2753 - val_accuracy: 0.8854\n",
      "Epoch 7/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.3043 - accuracy: 0.8732 - val_loss: 0.2725 - val_accuracy: 0.8883\n",
      "Epoch 8/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2990 - accuracy: 0.8770 - val_loss: 0.2753 - val_accuracy: 0.8870\n",
      "Epoch 9/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2971 - accuracy: 0.8769 - val_loss: 0.2716 - val_accuracy: 0.8868\n",
      "Epoch 10/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2956 - accuracy: 0.8778 - val_loss: 0.2725 - val_accuracy: 0.8870\n",
      "Epoch 11/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2935 - accuracy: 0.8785 - val_loss: 0.2713 - val_accuracy: 0.8879\n",
      "Epoch 12/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2919 - accuracy: 0.8786 - val_loss: 0.2690 - val_accuracy: 0.8876\n",
      "Epoch 13/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2928 - accuracy: 0.8773 - val_loss: 0.2737 - val_accuracy: 0.8860\n",
      "Epoch 14/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2918 - accuracy: 0.8793 - val_loss: 0.2713 - val_accuracy: 0.8869\n",
      "Epoch 15/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2911 - accuracy: 0.8793 - val_loss: 0.2667 - val_accuracy: 0.8887\n",
      "Epoch 16/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2901 - accuracy: 0.8797 - val_loss: 0.2703 - val_accuracy: 0.8875\n",
      "Epoch 17/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2903 - accuracy: 0.8805 - val_loss: 0.2698 - val_accuracy: 0.8876\n",
      "Epoch 18/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2875 - accuracy: 0.8821 - val_loss: 0.2695 - val_accuracy: 0.8887\n",
      "Epoch 19/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.8807 - val_loss: 0.2701 - val_accuracy: 0.8878\n",
      "Epoch 20/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2884 - accuracy: 0.8809 - val_loss: 0.2704 - val_accuracy: 0.8880\n",
      "Epoch 21/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.8804 - val_loss: 0.2684 - val_accuracy: 0.8896\n",
      "Epoch 22/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2845 - accuracy: 0.8822 - val_loss: 0.2668 - val_accuracy: 0.8899\n",
      "Epoch 23/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2872 - accuracy: 0.8813 - val_loss: 0.2655 - val_accuracy: 0.8879\n",
      "Epoch 24/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2846 - accuracy: 0.8822 - val_loss: 0.2687 - val_accuracy: 0.8889\n",
      "Epoch 25/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2853 - accuracy: 0.8816 - val_loss: 0.2660 - val_accuracy: 0.8895\n",
      "Epoch 26/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2863 - accuracy: 0.8809 - val_loss: 0.2663 - val_accuracy: 0.8895\n",
      "Epoch 27/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8819 - val_loss: 0.2644 - val_accuracy: 0.8902\n",
      "Epoch 28/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2815 - accuracy: 0.8841 - val_loss: 0.2650 - val_accuracy: 0.8894\n",
      "Epoch 29/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.8838 - val_loss: 0.2666 - val_accuracy: 0.8885\n",
      "Epoch 30/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.8823 - val_loss: 0.2640 - val_accuracy: 0.8887\n",
      "Epoch 31/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2830 - accuracy: 0.8820 - val_loss: 0.2639 - val_accuracy: 0.8894\n",
      "Epoch 32/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.8835 - val_loss: 0.2648 - val_accuracy: 0.8913\n",
      "Epoch 33/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2805 - accuracy: 0.8836 - val_loss: 0.2621 - val_accuracy: 0.8910\n",
      "Epoch 34/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2791 - accuracy: 0.8846 - val_loss: 0.2617 - val_accuracy: 0.8920\n",
      "Epoch 35/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2785 - accuracy: 0.8846 - val_loss: 0.2648 - val_accuracy: 0.8893\n",
      "Epoch 36/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2799 - accuracy: 0.8832 - val_loss: 0.2614 - val_accuracy: 0.8916\n",
      "Epoch 37/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2788 - accuracy: 0.8852 - val_loss: 0.2621 - val_accuracy: 0.8928\n",
      "Epoch 38/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2797 - accuracy: 0.8840 - val_loss: 0.2634 - val_accuracy: 0.8893\n",
      "Epoch 39/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2795 - accuracy: 0.8849 - val_loss: 0.2610 - val_accuracy: 0.8911\n",
      "Epoch 40/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.8852 - val_loss: 0.2609 - val_accuracy: 0.8913\n",
      "Epoch 41/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2806 - accuracy: 0.8839 - val_loss: 0.2611 - val_accuracy: 0.8914\n",
      "Epoch 42/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2771 - accuracy: 0.8841 - val_loss: 0.2615 - val_accuracy: 0.8909\n",
      "Epoch 43/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2788 - accuracy: 0.8849 - val_loss: 0.2617 - val_accuracy: 0.8920\n",
      "Epoch 44/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.8845 - val_loss: 0.2617 - val_accuracy: 0.8909\n",
      "Epoch 45/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2765 - accuracy: 0.8846 - val_loss: 0.2618 - val_accuracy: 0.8905\n",
      "Epoch 46/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2781 - accuracy: 0.8848 - val_loss: 0.2619 - val_accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2789 - accuracy: 0.8842 - val_loss: 0.2611 - val_accuracy: 0.8913\n",
      "Epoch 48/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2767 - accuracy: 0.8853 - val_loss: 0.2620 - val_accuracy: 0.8900\n",
      "Epoch 49/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2778 - accuracy: 0.8852 - val_loss: 0.2624 - val_accuracy: 0.8909\n",
      "Epoch 50/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2749 - accuracy: 0.8870 - val_loss: 0.2613 - val_accuracy: 0.8913\n",
      "Epoch 51/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2759 - accuracy: 0.8866 - val_loss: 0.2589 - val_accuracy: 0.8923\n",
      "Epoch 52/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.8865 - val_loss: 0.2612 - val_accuracy: 0.8913\n",
      "Epoch 53/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2753 - accuracy: 0.8849 - val_loss: 0.2594 - val_accuracy: 0.8931\n",
      "Epoch 54/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2738 - accuracy: 0.8871 - val_loss: 0.2630 - val_accuracy: 0.8912\n",
      "Epoch 55/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2758 - accuracy: 0.8857 - val_loss: 0.2611 - val_accuracy: 0.8902\n",
      "Epoch 56/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.8870 - val_loss: 0.2624 - val_accuracy: 0.8894\n",
      "Epoch 57/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.8860 - val_loss: 0.2596 - val_accuracy: 0.8922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2751 - accuracy: 0.8870 - val_loss: 0.2609 - val_accuracy: 0.8910\n",
      "Epoch 59/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2754 - accuracy: 0.8865 - val_loss: 0.2602 - val_accuracy: 0.8896\n",
      "Epoch 60/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.8866 - val_loss: 0.2597 - val_accuracy: 0.8918\n",
      "Epoch 61/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2764 - accuracy: 0.8851 - val_loss: 0.2619 - val_accuracy: 0.8901\n",
      "Epoch 62/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2757 - accuracy: 0.8870 - val_loss: 0.2599 - val_accuracy: 0.8902\n",
      "Epoch 63/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2754 - accuracy: 0.8850 - val_loss: 0.2599 - val_accuracy: 0.8927\n",
      "Epoch 64/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2737 - accuracy: 0.8870 - val_loss: 0.2610 - val_accuracy: 0.8917\n",
      "Epoch 65/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.8859 - val_loss: 0.2614 - val_accuracy: 0.8925\n",
      "Epoch 66/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2758 - accuracy: 0.8858 - val_loss: 0.2617 - val_accuracy: 0.8907\n",
      "Epoch 67/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.8876 - val_loss: 0.2606 - val_accuracy: 0.8924\n",
      "Epoch 68/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2749 - accuracy: 0.8863 - val_loss: 0.2607 - val_accuracy: 0.8928\n",
      "Epoch 69/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2722 - accuracy: 0.8870 - val_loss: 0.2605 - val_accuracy: 0.8909\n",
      "Epoch 70/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2727 - accuracy: 0.8868 - val_loss: 0.2588 - val_accuracy: 0.8919\n",
      "Epoch 71/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2731 - accuracy: 0.8878 - val_loss: 0.2612 - val_accuracy: 0.8923\n",
      "Epoch 72/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2733 - accuracy: 0.8884 - val_loss: 0.2616 - val_accuracy: 0.8917\n",
      "Epoch 73/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2730 - accuracy: 0.8871 - val_loss: 0.2593 - val_accuracy: 0.8920\n",
      "Epoch 74/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2742 - accuracy: 0.8872 - val_loss: 0.2586 - val_accuracy: 0.8925\n",
      "Epoch 75/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2715 - accuracy: 0.8879 - val_loss: 0.2577 - val_accuracy: 0.8932\n",
      "Epoch 76/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2712 - accuracy: 0.8879 - val_loss: 0.2599 - val_accuracy: 0.8909\n",
      "Epoch 77/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2718 - accuracy: 0.8886 - val_loss: 0.2598 - val_accuracy: 0.8907\n",
      "Epoch 78/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2734 - accuracy: 0.8880 - val_loss: 0.2596 - val_accuracy: 0.8931\n",
      "Epoch 79/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2747 - accuracy: 0.8861 - val_loss: 0.2611 - val_accuracy: 0.8909\n",
      "Epoch 80/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2725 - accuracy: 0.8871 - val_loss: 0.2593 - val_accuracy: 0.8930\n",
      "Epoch 81/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 0.8878 - val_loss: 0.2595 - val_accuracy: 0.8928\n",
      "Epoch 82/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2729 - accuracy: 0.8873 - val_loss: 0.2584 - val_accuracy: 0.8913\n",
      "Epoch 83/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2699 - accuracy: 0.8883 - val_loss: 0.2592 - val_accuracy: 0.8923\n",
      "Epoch 84/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2712 - accuracy: 0.8881 - val_loss: 0.2601 - val_accuracy: 0.8916\n",
      "Epoch 85/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2699 - accuracy: 0.8888 - val_loss: 0.2585 - val_accuracy: 0.8918\n",
      "Epoch 86/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2705 - accuracy: 0.8885 - val_loss: 0.2589 - val_accuracy: 0.8917\n",
      "Epoch 87/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2713 - accuracy: 0.8884 - val_loss: 0.2584 - val_accuracy: 0.8912\n",
      "Epoch 88/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2687 - accuracy: 0.8895 - val_loss: 0.2600 - val_accuracy: 0.8909\n",
      "Epoch 89/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2709 - accuracy: 0.8898 - val_loss: 0.2611 - val_accuracy: 0.8923\n",
      "Epoch 90/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2720 - accuracy: 0.8876 - val_loss: 0.2586 - val_accuracy: 0.8912\n",
      "Epoch 91/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2709 - accuracy: 0.8884 - val_loss: 0.2617 - val_accuracy: 0.8893\n",
      "Epoch 92/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2714 - accuracy: 0.8876 - val_loss: 0.2602 - val_accuracy: 0.8916\n",
      "Epoch 93/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2704 - accuracy: 0.8886 - val_loss: 0.2616 - val_accuracy: 0.8902\n",
      "Epoch 94/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2696 - accuracy: 0.8895 - val_loss: 0.2593 - val_accuracy: 0.8924\n",
      "Epoch 95/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2705 - accuracy: 0.8880 - val_loss: 0.2577 - val_accuracy: 0.8913\n",
      "Epoch 96/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2707 - accuracy: 0.8892 - val_loss: 0.2586 - val_accuracy: 0.8923\n",
      "Epoch 97/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2687 - accuracy: 0.8893 - val_loss: 0.2606 - val_accuracy: 0.8905\n",
      "Epoch 98/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2692 - accuracy: 0.8878 - val_loss: 0.2587 - val_accuracy: 0.8917\n",
      "Epoch 99/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2702 - accuracy: 0.8895 - val_loss: 0.2584 - val_accuracy: 0.8935\n",
      "Epoch 100/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2710 - accuracy: 0.8892 - val_loss: 0.2568 - val_accuracy: 0.8918\n",
      "Epoch 101/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2719 - accuracy: 0.8882 - val_loss: 0.2576 - val_accuracy: 0.8925\n",
      "Epoch 102/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.8903 - val_loss: 0.2583 - val_accuracy: 0.8925\n",
      "Epoch 103/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2716 - accuracy: 0.8883 - val_loss: 0.2572 - val_accuracy: 0.8928\n",
      "Epoch 104/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2701 - accuracy: 0.8890 - val_loss: 0.2596 - val_accuracy: 0.8912\n",
      "Epoch 105/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2682 - accuracy: 0.8892 - val_loss: 0.2591 - val_accuracy: 0.8915\n",
      "Epoch 106/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2686 - accuracy: 0.8899 - val_loss: 0.2576 - val_accuracy: 0.8915\n",
      "Epoch 107/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2678 - accuracy: 0.8893 - val_loss: 0.2581 - val_accuracy: 0.8920\n",
      "Epoch 108/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2704 - accuracy: 0.8891 - val_loss: 0.2586 - val_accuracy: 0.8908\n",
      "Epoch 109/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2694 - accuracy: 0.8881 - val_loss: 0.2592 - val_accuracy: 0.8909\n",
      "Epoch 110/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2687 - accuracy: 0.8883 - val_loss: 0.2567 - val_accuracy: 0.8936\n",
      "Epoch 111/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2686 - accuracy: 0.8896 - val_loss: 0.2570 - val_accuracy: 0.8923\n",
      "Epoch 112/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2669 - accuracy: 0.8907 - val_loss: 0.2572 - val_accuracy: 0.8926\n",
      "Epoch 113/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.8900 - val_loss: 0.2578 - val_accuracy: 0.8937\n",
      "Epoch 114/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.8902 - val_loss: 0.2572 - val_accuracy: 0.8939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2672 - accuracy: 0.8891 - val_loss: 0.2589 - val_accuracy: 0.8920\n",
      "Epoch 116/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2691 - accuracy: 0.8895 - val_loss: 0.2599 - val_accuracy: 0.8913\n",
      "Epoch 117/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.8891 - val_loss: 0.2574 - val_accuracy: 0.8929\n",
      "Epoch 118/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2673 - accuracy: 0.8905 - val_loss: 0.2579 - val_accuracy: 0.8916\n",
      "Epoch 119/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2708 - accuracy: 0.8861 - val_loss: 0.2567 - val_accuracy: 0.8922\n",
      "Epoch 120/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2694 - accuracy: 0.8878 - val_loss: 0.2559 - val_accuracy: 0.8933\n",
      "Epoch 121/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2670 - accuracy: 0.8905 - val_loss: 0.2578 - val_accuracy: 0.8915\n",
      "Epoch 122/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2699 - accuracy: 0.8887 - val_loss: 0.2578 - val_accuracy: 0.8924\n",
      "Epoch 123/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2674 - accuracy: 0.8896 - val_loss: 0.2591 - val_accuracy: 0.8924\n",
      "Epoch 124/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2685 - accuracy: 0.8891 - val_loss: 0.2563 - val_accuracy: 0.8925\n",
      "Epoch 125/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2690 - accuracy: 0.8896 - val_loss: 0.2559 - val_accuracy: 0.8936\n",
      "Epoch 126/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2671 - accuracy: 0.8896 - val_loss: 0.2575 - val_accuracy: 0.8925\n",
      "Epoch 127/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2690 - accuracy: 0.8866 - val_loss: 0.2564 - val_accuracy: 0.8934\n",
      "Epoch 128/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.8894 - val_loss: 0.2571 - val_accuracy: 0.8916\n",
      "Epoch 129/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2666 - accuracy: 0.8914 - val_loss: 0.2570 - val_accuracy: 0.8933\n",
      "Epoch 130/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.2562 - val_accuracy: 0.8933\n",
      "Epoch 131/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2674 - accuracy: 0.8909 - val_loss: 0.2591 - val_accuracy: 0.8916\n",
      "Epoch 132/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.8894 - val_loss: 0.2565 - val_accuracy: 0.8928\n",
      "Epoch 133/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.8894 - val_loss: 0.2570 - val_accuracy: 0.8919\n",
      "Epoch 134/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2684 - accuracy: 0.8887 - val_loss: 0.2587 - val_accuracy: 0.8924\n",
      "Epoch 135/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2654 - accuracy: 0.8893 - val_loss: 0.2591 - val_accuracy: 0.8916\n",
      "Epoch 136/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2682 - accuracy: 0.8893 - val_loss: 0.2587 - val_accuracy: 0.8931\n",
      "Epoch 137/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2660 - accuracy: 0.8906 - val_loss: 0.2561 - val_accuracy: 0.8924\n",
      "Epoch 138/200\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.2657 - accuracy: 0.8901 - val_loss: 0.2588 - val_accuracy: 0.8922\n",
      "Epoch 139/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2668 - accuracy: 0.8905 - val_loss: 0.2578 - val_accuracy: 0.8918\n",
      "Epoch 140/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2685 - accuracy: 0.8911 - val_loss: 0.2573 - val_accuracy: 0.8930\n",
      "Epoch 141/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2662 - accuracy: 0.8899 - val_loss: 0.2573 - val_accuracy: 0.8931\n",
      "Epoch 142/200\n",
      "423/423 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.89 - 2s 4ms/step - loss: 0.2669 - accuracy: 0.8903 - val_loss: 0.2564 - val_accuracy: 0.8924\n",
      "Epoch 143/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2683 - accuracy: 0.8896 - val_loss: 0.2563 - val_accuracy: 0.8930\n",
      "Epoch 144/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2666 - accuracy: 0.8905 - val_loss: 0.2572 - val_accuracy: 0.8936\n",
      "Epoch 145/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2669 - accuracy: 0.8893 - val_loss: 0.2569 - val_accuracy: 0.8920\n",
      "Epoch 146/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2674 - accuracy: 0.8888 - val_loss: 0.2570 - val_accuracy: 0.8925\n",
      "Epoch 147/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2659 - accuracy: 0.8915 - val_loss: 0.2566 - val_accuracy: 0.8930\n",
      "Epoch 148/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2660 - accuracy: 0.8903 - val_loss: 0.2566 - val_accuracy: 0.8938\n",
      "Epoch 149/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2679 - accuracy: 0.8885 - val_loss: 0.2570 - val_accuracy: 0.8928\n",
      "Epoch 150/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2646 - accuracy: 0.8915 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 151/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2653 - accuracy: 0.8906 - val_loss: 0.2568 - val_accuracy: 0.8937\n",
      "Epoch 152/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2661 - accuracy: 0.8903 - val_loss: 0.2579 - val_accuracy: 0.8916\n",
      "Epoch 153/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2628 - accuracy: 0.8905 - val_loss: 0.2561 - val_accuracy: 0.8941\n",
      "Epoch 154/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2665 - accuracy: 0.8902 - val_loss: 0.2581 - val_accuracy: 0.8942\n",
      "Epoch 155/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2663 - accuracy: 0.8905 - val_loss: 0.2585 - val_accuracy: 0.8931\n",
      "Epoch 156/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2655 - accuracy: 0.8897 - val_loss: 0.2559 - val_accuracy: 0.8925\n",
      "Epoch 157/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2641 - accuracy: 0.8916 - val_loss: 0.2600 - val_accuracy: 0.8924\n",
      "Epoch 158/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2662 - accuracy: 0.8909 - val_loss: 0.2585 - val_accuracy: 0.8926\n",
      "Epoch 159/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2668 - accuracy: 0.8896 - val_loss: 0.2565 - val_accuracy: 0.8933\n",
      "Epoch 160/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2658 - accuracy: 0.8893 - val_loss: 0.2568 - val_accuracy: 0.8928\n",
      "Epoch 161/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.8911 - val_loss: 0.2555 - val_accuracy: 0.8939\n",
      "Epoch 162/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2671 - accuracy: 0.8894 - val_loss: 0.2583 - val_accuracy: 0.8924\n",
      "Epoch 163/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2664 - accuracy: 0.8909 - val_loss: 0.2576 - val_accuracy: 0.8929\n",
      "Epoch 164/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.8907 - val_loss: 0.2558 - val_accuracy: 0.8922\n",
      "Epoch 165/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2659 - accuracy: 0.8902 - val_loss: 0.2556 - val_accuracy: 0.8928\n",
      "Epoch 166/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2646 - accuracy: 0.8912 - val_loss: 0.2564 - val_accuracy: 0.8933\n",
      "Epoch 167/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2652 - accuracy: 0.8903 - val_loss: 0.2561 - val_accuracy: 0.8928\n",
      "Epoch 168/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2662 - accuracy: 0.8913 - val_loss: 0.2575 - val_accuracy: 0.8928\n",
      "Epoch 169/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2660 - accuracy: 0.8903 - val_loss: 0.2582 - val_accuracy: 0.8925\n",
      "Epoch 170/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2644 - accuracy: 0.8903 - val_loss: 0.2557 - val_accuracy: 0.8931\n",
      "Epoch 171/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2650 - accuracy: 0.8902 - val_loss: 0.2566 - val_accuracy: 0.8934\n",
      "Epoch 172/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2646 - accuracy: 0.8906 - val_loss: 0.2578 - val_accuracy: 0.8923\n",
      "Epoch 173/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.8914 - val_loss: 0.2561 - val_accuracy: 0.8930\n",
      "Epoch 174/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2632 - accuracy: 0.8907 - val_loss: 0.2556 - val_accuracy: 0.8931\n",
      "Epoch 175/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2658 - accuracy: 0.8910 - val_loss: 0.2558 - val_accuracy: 0.8925\n",
      "Epoch 176/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.8897 - val_loss: 0.2556 - val_accuracy: 0.8933\n",
      "Epoch 177/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2652 - accuracy: 0.8897 - val_loss: 0.2562 - val_accuracy: 0.8922\n",
      "Epoch 178/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2652 - accuracy: 0.8906 - val_loss: 0.2557 - val_accuracy: 0.8933\n",
      "Epoch 179/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2643 - accuracy: 0.8905 - val_loss: 0.2571 - val_accuracy: 0.8928\n",
      "Epoch 180/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2637 - accuracy: 0.8911 - val_loss: 0.2565 - val_accuracy: 0.8933\n",
      "Epoch 181/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2629 - accuracy: 0.8925 - val_loss: 0.2569 - val_accuracy: 0.8927\n",
      "Epoch 182/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.8913 - val_loss: 0.2564 - val_accuracy: 0.8933\n",
      "Epoch 183/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2610 - accuracy: 0.8936 - val_loss: 0.2555 - val_accuracy: 0.8928\n",
      "Epoch 184/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.8906 - val_loss: 0.2568 - val_accuracy: 0.8933\n",
      "Epoch 185/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.8900 - val_loss: 0.2558 - val_accuracy: 0.8939\n",
      "Epoch 186/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2653 - accuracy: 0.8910 - val_loss: 0.2572 - val_accuracy: 0.8929\n",
      "Epoch 187/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2635 - accuracy: 0.8917 - val_loss: 0.2554 - val_accuracy: 0.8933\n",
      "Epoch 188/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.8920 - val_loss: 0.2572 - val_accuracy: 0.8926\n",
      "Epoch 189/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2632 - accuracy: 0.8925 - val_loss: 0.2575 - val_accuracy: 0.8920\n",
      "Epoch 190/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2665 - accuracy: 0.8900 - val_loss: 0.2577 - val_accuracy: 0.8920\n",
      "Epoch 191/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2634 - accuracy: 0.8913 - val_loss: 0.2565 - val_accuracy: 0.8928\n",
      "Epoch 192/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2654 - accuracy: 0.8899 - val_loss: 0.2592 - val_accuracy: 0.8936\n",
      "Epoch 193/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2645 - accuracy: 0.8915 - val_loss: 0.2560 - val_accuracy: 0.8928\n",
      "Epoch 194/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2641 - accuracy: 0.8906 - val_loss: 0.2580 - val_accuracy: 0.8923\n",
      "Epoch 195/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2639 - accuracy: 0.8929 - val_loss: 0.2582 - val_accuracy: 0.8916\n",
      "Epoch 196/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2641 - accuracy: 0.8906 - val_loss: 0.2579 - val_accuracy: 0.8914\n",
      "Epoch 197/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2644 - accuracy: 0.8915 - val_loss: 0.2575 - val_accuracy: 0.8927\n",
      "Epoch 198/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2624 - accuracy: 0.8911 - val_loss: 0.2598 - val_accuracy: 0.8928\n",
      "Epoch 199/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.8900 - val_loss: 0.2578 - val_accuracy: 0.8922\n",
      "Epoch 200/200\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.2627 - accuracy: 0.8923 - val_loss: 0.2573 - val_accuracy: 0.8944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model1.fit(x_train_selected, y_train, epochs = 200, batch_size = 128, validation_data = (x_val_selected,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.4125 - accuracy: 0.8170 - val_loss: 0.3507 - val_accuracy: 0.8541\n",
      "Epoch 2/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3862 - accuracy: 0.8298 - val_loss: 0.3458 - val_accuracy: 0.8532\n",
      "Epoch 3/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3795 - accuracy: 0.8339 - val_loss: 0.3432 - val_accuracy: 0.8530\n",
      "Epoch 4/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3781 - accuracy: 0.8341 - val_loss: 0.3465 - val_accuracy: 0.8518\n",
      "Epoch 5/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3748 - accuracy: 0.8356 - val_loss: 0.3420 - val_accuracy: 0.8539\n",
      "Epoch 6/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3739 - accuracy: 0.8370 - val_loss: 0.3433 - val_accuracy: 0.8508\n",
      "Epoch 7/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3726 - accuracy: 0.8373 - val_loss: 0.3424 - val_accuracy: 0.8544\n",
      "Epoch 8/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3727 - accuracy: 0.8378 - val_loss: 0.3382 - val_accuracy: 0.8549\n",
      "Epoch 9/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3702 - accuracy: 0.8397 - val_loss: 0.3405 - val_accuracy: 0.8532\n",
      "Epoch 10/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3683 - accuracy: 0.8384 - val_loss: 0.3437 - val_accuracy: 0.8528\n",
      "Epoch 11/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3675 - accuracy: 0.8406 - val_loss: 0.3373 - val_accuracy: 0.8553\n",
      "Epoch 12/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8404 - val_loss: 0.3375 - val_accuracy: 0.8541\n",
      "Epoch 13/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3660 - accuracy: 0.8402 - val_loss: 0.3381 - val_accuracy: 0.8544\n",
      "Epoch 14/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3685 - accuracy: 0.8394 - val_loss: 0.3379 - val_accuracy: 0.8539\n",
      "Epoch 15/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8400 - val_loss: 0.3428 - val_accuracy: 0.8556\n",
      "Epoch 16/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8416 - val_loss: 0.3370 - val_accuracy: 0.8544\n",
      "Epoch 17/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3658 - accuracy: 0.8396 - val_loss: 0.3371 - val_accuracy: 0.8556\n",
      "Epoch 18/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3638 - accuracy: 0.8411 - val_loss: 0.3368 - val_accuracy: 0.8551\n",
      "Epoch 19/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3642 - accuracy: 0.8420 - val_loss: 0.3359 - val_accuracy: 0.8564\n",
      "Epoch 20/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3638 - accuracy: 0.8418 - val_loss: 0.3415 - val_accuracy: 0.8549\n",
      "Epoch 21/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3630 - accuracy: 0.8417 - val_loss: 0.3382 - val_accuracy: 0.8566\n",
      "Epoch 22/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3657 - accuracy: 0.8407 - val_loss: 0.3381 - val_accuracy: 0.8564\n",
      "Epoch 23/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3634 - accuracy: 0.8415 - val_loss: 0.3369 - val_accuracy: 0.8553\n",
      "Epoch 24/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3623 - accuracy: 0.8434 - val_loss: 0.3370 - val_accuracy: 0.8577\n",
      "Epoch 25/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3618 - accuracy: 0.8432 - val_loss: 0.3341 - val_accuracy: 0.8580\n",
      "Epoch 26/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3608 - accuracy: 0.8429 - val_loss: 0.3344 - val_accuracy: 0.8552\n",
      "Epoch 27/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3609 - accuracy: 0.8422 - val_loss: 0.3354 - val_accuracy: 0.8552\n",
      "Epoch 28/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3599 - accuracy: 0.8423 - val_loss: 0.3371 - val_accuracy: 0.8552\n",
      "Epoch 29/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3620 - accuracy: 0.8420 - val_loss: 0.3360 - val_accuracy: 0.8556\n",
      "Epoch 30/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3610 - accuracy: 0.8432 - val_loss: 0.3364 - val_accuracy: 0.8561\n",
      "Epoch 31/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3609 - accuracy: 0.8431 - val_loss: 0.3373 - val_accuracy: 0.8557\n",
      "Epoch 32/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8440 - val_loss: 0.3366 - val_accuracy: 0.8558\n",
      "Epoch 33/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3610 - accuracy: 0.8437 - val_loss: 0.3363 - val_accuracy: 0.8564\n",
      "Epoch 34/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3604 - accuracy: 0.8435 - val_loss: 0.3348 - val_accuracy: 0.8547\n",
      "Epoch 35/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.8439 - val_loss: 0.3360 - val_accuracy: 0.8547\n",
      "Epoch 36/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3600 - accuracy: 0.8442 - val_loss: 0.3354 - val_accuracy: 0.8558\n",
      "Epoch 37/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3601 - accuracy: 0.8443 - val_loss: 0.3338 - val_accuracy: 0.8557\n",
      "Epoch 38/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3593 - accuracy: 0.8436 - val_loss: 0.3351 - val_accuracy: 0.8561\n",
      "Epoch 39/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3603 - accuracy: 0.8433 - val_loss: 0.3343 - val_accuracy: 0.8568\n",
      "Epoch 40/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8438 - val_loss: 0.3340 - val_accuracy: 0.8559\n",
      "Epoch 41/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8444 - val_loss: 0.3341 - val_accuracy: 0.8560\n",
      "Epoch 42/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8431 - val_loss: 0.3340 - val_accuracy: 0.8575\n",
      "Epoch 43/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3595 - accuracy: 0.8446 - val_loss: 0.3342 - val_accuracy: 0.8553\n",
      "Epoch 44/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3614 - accuracy: 0.8440 - val_loss: 0.3368 - val_accuracy: 0.8552\n",
      "Epoch 45/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3585 - accuracy: 0.8440 - val_loss: 0.3345 - val_accuracy: 0.8561\n",
      "Epoch 46/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8440 - val_loss: 0.3325 - val_accuracy: 0.8572\n",
      "Epoch 47/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8445 - val_loss: 0.3363 - val_accuracy: 0.8561\n",
      "Epoch 48/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3587 - accuracy: 0.8435 - val_loss: 0.3382 - val_accuracy: 0.8557\n",
      "Epoch 49/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3621 - accuracy: 0.8413 - val_loss: 0.3333 - val_accuracy: 0.8565\n",
      "Epoch 50/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3585 - accuracy: 0.8445 - val_loss: 0.3353 - val_accuracy: 0.8566\n",
      "Epoch 51/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8437 - val_loss: 0.3325 - val_accuracy: 0.8562\n",
      "Epoch 52/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3589 - accuracy: 0.8433 - val_loss: 0.3328 - val_accuracy: 0.8553\n",
      "Epoch 53/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3595 - accuracy: 0.8433 - val_loss: 0.3362 - val_accuracy: 0.8546\n",
      "Epoch 54/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3603 - accuracy: 0.8432 - val_loss: 0.3352 - val_accuracy: 0.8564\n",
      "Epoch 55/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8456 - val_loss: 0.3402 - val_accuracy: 0.8556\n",
      "Epoch 56/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8451 - val_loss: 0.3367 - val_accuracy: 0.8565\n",
      "Epoch 57/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.8436 - val_loss: 0.3349 - val_accuracy: 0.8581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8453 - val_loss: 0.3350 - val_accuracy: 0.8571\n",
      "Epoch 59/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3576 - accuracy: 0.8438 - val_loss: 0.3347 - val_accuracy: 0.8552\n",
      "Epoch 60/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8448 - val_loss: 0.3348 - val_accuracy: 0.8554\n",
      "Epoch 61/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3573 - accuracy: 0.8449 - val_loss: 0.3377 - val_accuracy: 0.8575\n",
      "Epoch 62/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8442 - val_loss: 0.3348 - val_accuracy: 0.8571\n",
      "Epoch 63/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8451 - val_loss: 0.3364 - val_accuracy: 0.8547\n",
      "Epoch 64/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8451 - val_loss: 0.3347 - val_accuracy: 0.8564\n",
      "Epoch 65/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8432 - val_loss: 0.3337 - val_accuracy: 0.8577\n",
      "Epoch 66/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8449 - val_loss: 0.3321 - val_accuracy: 0.8582\n",
      "Epoch 67/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8447 - val_loss: 0.3315 - val_accuracy: 0.8572\n",
      "Epoch 68/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8460 - val_loss: 0.3348 - val_accuracy: 0.8555\n",
      "Epoch 69/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3577 - accuracy: 0.8458 - val_loss: 0.3352 - val_accuracy: 0.8553\n",
      "Epoch 70/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8433 - val_loss: 0.3335 - val_accuracy: 0.8569\n",
      "Epoch 71/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8447 - val_loss: 0.3392 - val_accuracy: 0.8567\n",
      "Epoch 72/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8456 - val_loss: 0.3342 - val_accuracy: 0.8552\n",
      "Epoch 73/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.8443 - val_loss: 0.3331 - val_accuracy: 0.8592\n",
      "Epoch 74/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8446 - val_loss: 0.3360 - val_accuracy: 0.8569\n",
      "Epoch 75/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8450 - val_loss: 0.3349 - val_accuracy: 0.8556\n",
      "Epoch 76/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8460 - val_loss: 0.3329 - val_accuracy: 0.8582\n",
      "Epoch 77/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8459 - val_loss: 0.3341 - val_accuracy: 0.8556\n",
      "Epoch 78/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8462 - val_loss: 0.3314 - val_accuracy: 0.8575\n",
      "Epoch 79/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8467 - val_loss: 0.3321 - val_accuracy: 0.8583\n",
      "Epoch 80/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8454 - val_loss: 0.3326 - val_accuracy: 0.8559\n",
      "Epoch 81/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8437 - val_loss: 0.3362 - val_accuracy: 0.8564\n",
      "Epoch 82/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8452 - val_loss: 0.3363 - val_accuracy: 0.8558\n",
      "Epoch 83/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.8442 - val_loss: 0.3341 - val_accuracy: 0.8563\n",
      "Epoch 84/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.8442 - val_loss: 0.3345 - val_accuracy: 0.8567\n",
      "Epoch 85/200\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.84 - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8469 - val_loss: 0.3388 - val_accuracy: 0.8561\n",
      "Epoch 86/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8474 - val_loss: 0.3346 - val_accuracy: 0.8558\n",
      "Epoch 87/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8455 - val_loss: 0.3353 - val_accuracy: 0.8570\n",
      "Epoch 88/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8467 - val_loss: 0.3361 - val_accuracy: 0.8553\n",
      "Epoch 89/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8449 - val_loss: 0.3355 - val_accuracy: 0.8543\n",
      "Epoch 90/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8462 - val_loss: 0.3324 - val_accuracy: 0.8570\n",
      "Epoch 91/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3566 - accuracy: 0.8445 - val_loss: 0.3338 - val_accuracy: 0.8580\n",
      "Epoch 92/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8443 - val_loss: 0.3353 - val_accuracy: 0.8554\n",
      "Epoch 93/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8447 - val_loss: 0.3339 - val_accuracy: 0.8574\n",
      "Epoch 94/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8468 - val_loss: 0.3335 - val_accuracy: 0.8553\n",
      "Epoch 95/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3583 - accuracy: 0.8447 - val_loss: 0.3346 - val_accuracy: 0.8559\n",
      "Epoch 96/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8453 - val_loss: 0.3348 - val_accuracy: 0.8547\n",
      "Epoch 97/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3561 - accuracy: 0.8478 - val_loss: 0.3319 - val_accuracy: 0.8570\n",
      "Epoch 98/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3565 - accuracy: 0.8443 - val_loss: 0.3366 - val_accuracy: 0.8546\n",
      "Epoch 99/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8454 - val_loss: 0.3328 - val_accuracy: 0.8564\n",
      "Epoch 100/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8467 - val_loss: 0.3329 - val_accuracy: 0.8553\n",
      "Epoch 101/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8464 - val_loss: 0.3350 - val_accuracy: 0.8570\n",
      "Epoch 102/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3566 - accuracy: 0.8455 - val_loss: 0.3377 - val_accuracy: 0.8542\n",
      "Epoch 103/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8483 - val_loss: 0.3364 - val_accuracy: 0.8558\n",
      "Epoch 104/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8447 - val_loss: 0.3353 - val_accuracy: 0.8540\n",
      "Epoch 105/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8452 - val_loss: 0.3353 - val_accuracy: 0.8549\n",
      "Epoch 106/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8443 - val_loss: 0.3366 - val_accuracy: 0.8538\n",
      "Epoch 107/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8466 - val_loss: 0.3348 - val_accuracy: 0.8553\n",
      "Epoch 108/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8456 - val_loss: 0.3342 - val_accuracy: 0.8565\n",
      "Epoch 109/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8465 - val_loss: 0.3329 - val_accuracy: 0.8577\n",
      "Epoch 110/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3558 - accuracy: 0.8465 - val_loss: 0.3365 - val_accuracy: 0.8556\n",
      "Epoch 111/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8454 - val_loss: 0.3334 - val_accuracy: 0.8565\n",
      "Epoch 112/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8460 - val_loss: 0.3325 - val_accuracy: 0.8572\n",
      "Epoch 113/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3558 - accuracy: 0.8453 - val_loss: 0.3335 - val_accuracy: 0.8561\n",
      "Epoch 114/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8457 - val_loss: 0.3361 - val_accuracy: 0.8552\n",
      "Epoch 115/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3559 - accuracy: 0.8467 - val_loss: 0.3333 - val_accuracy: 0.8558\n",
      "Epoch 116/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8462 - val_loss: 0.3311 - val_accuracy: 0.8581\n",
      "Epoch 117/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8455 - val_loss: 0.3325 - val_accuracy: 0.8574\n",
      "Epoch 118/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8442 - val_loss: 0.3323 - val_accuracy: 0.8567\n",
      "Epoch 119/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8464 - val_loss: 0.3325 - val_accuracy: 0.8573\n",
      "Epoch 120/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8477 - val_loss: 0.3326 - val_accuracy: 0.8575\n",
      "Epoch 121/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8464 - val_loss: 0.3315 - val_accuracy: 0.8562\n",
      "Epoch 122/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3562 - accuracy: 0.8441 - val_loss: 0.3330 - val_accuracy: 0.8566\n",
      "Epoch 123/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8465 - val_loss: 0.3315 - val_accuracy: 0.8583\n",
      "Epoch 124/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8457 - val_loss: 0.3338 - val_accuracy: 0.8562\n",
      "Epoch 125/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8476 - val_loss: 0.3310 - val_accuracy: 0.8578\n",
      "Epoch 126/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8464 - val_loss: 0.3353 - val_accuracy: 0.8561\n",
      "Epoch 127/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8450 - val_loss: 0.3336 - val_accuracy: 0.8576\n",
      "Epoch 128/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3573 - accuracy: 0.8442 - val_loss: 0.3323 - val_accuracy: 0.8573\n",
      "Epoch 129/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8462 - val_loss: 0.3342 - val_accuracy: 0.8564\n",
      "Epoch 130/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8456 - val_loss: 0.3333 - val_accuracy: 0.8561\n",
      "Epoch 131/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8466 - val_loss: 0.3336 - val_accuracy: 0.8559\n",
      "Epoch 132/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8468 - val_loss: 0.3357 - val_accuracy: 0.8550\n",
      "Epoch 133/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8469 - val_loss: 0.3314 - val_accuracy: 0.8562\n",
      "Epoch 134/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8473 - val_loss: 0.3339 - val_accuracy: 0.8565\n",
      "Epoch 135/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.3360 - val_accuracy: 0.8555\n",
      "Epoch 136/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8485 - val_loss: 0.3353 - val_accuracy: 0.8569\n",
      "Epoch 137/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8468 - val_loss: 0.3337 - val_accuracy: 0.8562\n",
      "Epoch 138/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8466 - val_loss: 0.3337 - val_accuracy: 0.8561\n",
      "Epoch 139/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8442 - val_loss: 0.3361 - val_accuracy: 0.8547\n",
      "Epoch 140/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8461 - val_loss: 0.3326 - val_accuracy: 0.8575\n",
      "Epoch 141/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8475 - val_loss: 0.3344 - val_accuracy: 0.8573\n",
      "Epoch 142/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8464 - val_loss: 0.3347 - val_accuracy: 0.8555\n",
      "Epoch 143/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8467 - val_loss: 0.3333 - val_accuracy: 0.8567\n",
      "Epoch 144/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8473 - val_loss: 0.3333 - val_accuracy: 0.8568\n",
      "Epoch 145/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8452 - val_loss: 0.3354 - val_accuracy: 0.8565\n",
      "Epoch 146/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8457 - val_loss: 0.3341 - val_accuracy: 0.8550\n",
      "Epoch 147/200\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.3537 - accuracy: 0.8456 - val_loss: 0.3376 - val_accuracy: 0.8549\n",
      "Epoch 148/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8454 - val_loss: 0.3327 - val_accuracy: 0.8558\n",
      "Epoch 149/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8453 - val_loss: 0.3322 - val_accuracy: 0.8558\n",
      "Epoch 150/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8460 - val_loss: 0.3320 - val_accuracy: 0.8570\n",
      "Epoch 151/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8468 - val_loss: 0.3330 - val_accuracy: 0.8563\n",
      "Epoch 152/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8475 - val_loss: 0.3346 - val_accuracy: 0.8551\n",
      "Epoch 153/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8460 - val_loss: 0.3343 - val_accuracy: 0.8575\n",
      "Epoch 154/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8481 - val_loss: 0.3336 - val_accuracy: 0.8559\n",
      "Epoch 155/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8465 - val_loss: 0.3330 - val_accuracy: 0.8556\n",
      "Epoch 156/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8468 - val_loss: 0.3348 - val_accuracy: 0.8569\n",
      "Epoch 157/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8485 - val_loss: 0.3353 - val_accuracy: 0.8553\n",
      "Epoch 158/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.3323 - val_accuracy: 0.8570\n",
      "Epoch 159/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8468 - val_loss: 0.3344 - val_accuracy: 0.8563\n",
      "Epoch 160/200\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8469 - val_loss: 0.3344 - val_accuracy: 0.8569\n",
      "Epoch 161/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8468 - val_loss: 0.3348 - val_accuracy: 0.8567\n",
      "Epoch 162/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8470 - val_loss: 0.3333 - val_accuracy: 0.8556\n",
      "Epoch 163/200\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8467 - val_loss: 0.3349 - val_accuracy: 0.8571\n",
      "Epoch 164/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.3345 - val_accuracy: 0.8564\n",
      "Epoch 165/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8443 - val_loss: 0.3335 - val_accuracy: 0.8581\n",
      "Epoch 166/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8478 - val_loss: 0.3328 - val_accuracy: 0.8562\n",
      "Epoch 167/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8483 - val_loss: 0.3329 - val_accuracy: 0.8564\n",
      "Epoch 168/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3549 - accuracy: 0.8451 - val_loss: 0.3331 - val_accuracy: 0.8572\n",
      "Epoch 169/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8460 - val_loss: 0.3350 - val_accuracy: 0.8556\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8453 - val_loss: 0.3335 - val_accuracy: 0.8567\n",
      "Epoch 171/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8465 - val_loss: 0.3345 - val_accuracy: 0.8550\n",
      "Epoch 172/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8462 - val_loss: 0.3335 - val_accuracy: 0.8560\n",
      "Epoch 173/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8468 - val_loss: 0.3310 - val_accuracy: 0.8581\n",
      "Epoch 174/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8467 - val_loss: 0.3357 - val_accuracy: 0.8558\n",
      "Epoch 175/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8456 - val_loss: 0.3350 - val_accuracy: 0.8561\n",
      "Epoch 176/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8460 - val_loss: 0.3341 - val_accuracy: 0.8558\n",
      "Epoch 177/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8468 - val_loss: 0.3330 - val_accuracy: 0.8549\n",
      "Epoch 178/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8476 - val_loss: 0.3333 - val_accuracy: 0.8565\n",
      "Epoch 179/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8463 - val_loss: 0.3334 - val_accuracy: 0.8570\n",
      "Epoch 180/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8471 - val_loss: 0.3337 - val_accuracy: 0.8567\n",
      "Epoch 181/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3549 - accuracy: 0.8453 - val_loss: 0.3351 - val_accuracy: 0.8554\n",
      "Epoch 182/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3332 - val_accuracy: 0.8561\n",
      "Epoch 183/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8462 - val_loss: 0.3355 - val_accuracy: 0.8563\n",
      "Epoch 184/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8459 - val_loss: 0.3330 - val_accuracy: 0.8550\n",
      "Epoch 185/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8458 - val_loss: 0.3353 - val_accuracy: 0.8559\n",
      "Epoch 186/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8462 - val_loss: 0.3355 - val_accuracy: 0.8567\n",
      "Epoch 187/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8448 - val_loss: 0.3329 - val_accuracy: 0.8555\n",
      "Epoch 188/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8476 - val_loss: 0.3321 - val_accuracy: 0.8582\n",
      "Epoch 189/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8467 - val_loss: 0.3340 - val_accuracy: 0.8566\n",
      "Epoch 190/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8467 - val_loss: 0.3328 - val_accuracy: 0.8570\n",
      "Epoch 191/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8477 - val_loss: 0.3336 - val_accuracy: 0.8565\n",
      "Epoch 192/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8460 - val_loss: 0.3328 - val_accuracy: 0.8577\n",
      "Epoch 193/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8463 - val_loss: 0.3322 - val_accuracy: 0.8560\n",
      "Epoch 194/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8473 - val_loss: 0.3337 - val_accuracy: 0.8566\n",
      "Epoch 195/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8476 - val_loss: 0.3345 - val_accuracy: 0.8565\n",
      "Epoch 196/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8481 - val_loss: 0.3335 - val_accuracy: 0.8565\n",
      "Epoch 197/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8483 - val_loss: 0.3311 - val_accuracy: 0.8572\n",
      "Epoch 198/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8458 - val_loss: 0.3346 - val_accuracy: 0.8560\n",
      "Epoch 199/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8450 - val_loss: 0.3336 - val_accuracy: 0.8565\n",
      "Epoch 200/200\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8447 - val_loss: 0.3327 - val_accuracy: 0.8570\n"
     ]
    }
   ],
   "source": [
    "historym = model1m.fit(x_train, y_train, epochs = 200, batch_size = 128, validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.4500 - accuracy: 0.7963 - val_loss: 0.3528 - val_accuracy: 0.8464\n",
      "Epoch 2/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.4074 - accuracy: 0.8174 - val_loss: 0.3468 - val_accuracy: 0.8483\n",
      "Epoch 3/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3959 - accuracy: 0.8229 - val_loss: 0.3450 - val_accuracy: 0.8485\n",
      "Epoch 4/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3964 - accuracy: 0.8242 - val_loss: 0.3428 - val_accuracy: 0.8511\n",
      "Epoch 5/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3865 - accuracy: 0.8319 - val_loss: 0.3408 - val_accuracy: 0.8528\n",
      "Epoch 6/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.3423 - val_accuracy: 0.8512\n",
      "Epoch 7/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3876 - accuracy: 0.8288 - val_loss: 0.3403 - val_accuracy: 0.8536\n",
      "Epoch 8/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3807 - accuracy: 0.8332 - val_loss: 0.3395 - val_accuracy: 0.8524\n",
      "Epoch 9/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3817 - accuracy: 0.8315 - val_loss: 0.3406 - val_accuracy: 0.8526\n",
      "Epoch 10/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3816 - accuracy: 0.8322 - val_loss: 0.3365 - val_accuracy: 0.8579\n",
      "Epoch 11/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3789 - accuracy: 0.8354 - val_loss: 0.3373 - val_accuracy: 0.8562\n",
      "Epoch 12/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3779 - accuracy: 0.8347 - val_loss: 0.3363 - val_accuracy: 0.8565\n",
      "Epoch 13/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3772 - accuracy: 0.8346 - val_loss: 0.3354 - val_accuracy: 0.8579\n",
      "Epoch 14/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3755 - accuracy: 0.8359 - val_loss: 0.3363 - val_accuracy: 0.8562\n",
      "Epoch 15/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3748 - accuracy: 0.8349 - val_loss: 0.3372 - val_accuracy: 0.8550\n",
      "Epoch 16/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3759 - accuracy: 0.8347 - val_loss: 0.3360 - val_accuracy: 0.8588\n",
      "Epoch 17/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3713 - accuracy: 0.8388 - val_loss: 0.3363 - val_accuracy: 0.8571\n",
      "Epoch 18/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3737 - accuracy: 0.8365 - val_loss: 0.3345 - val_accuracy: 0.8595\n",
      "Epoch 19/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3741 - accuracy: 0.8369 - val_loss: 0.3359 - val_accuracy: 0.8573\n",
      "Epoch 20/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3754 - accuracy: 0.8340 - val_loss: 0.3316 - val_accuracy: 0.8581\n",
      "Epoch 21/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3729 - accuracy: 0.8363 - val_loss: 0.3333 - val_accuracy: 0.8587\n",
      "Epoch 22/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3732 - accuracy: 0.8377 - val_loss: 0.3325 - val_accuracy: 0.8606\n",
      "Epoch 23/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3709 - accuracy: 0.8381 - val_loss: 0.3330 - val_accuracy: 0.8588\n",
      "Epoch 24/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3722 - accuracy: 0.8382 - val_loss: 0.3316 - val_accuracy: 0.8588\n",
      "Epoch 25/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3727 - accuracy: 0.8382 - val_loss: 0.3360 - val_accuracy: 0.8583\n",
      "Epoch 26/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3711 - accuracy: 0.8381 - val_loss: 0.3314 - val_accuracy: 0.8598\n",
      "Epoch 27/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3714 - accuracy: 0.8380 - val_loss: 0.3328 - val_accuracy: 0.8595\n",
      "Epoch 28/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3708 - accuracy: 0.8383 - val_loss: 0.3328 - val_accuracy: 0.8598\n",
      "Epoch 29/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3676 - accuracy: 0.8390 - val_loss: 0.3314 - val_accuracy: 0.8601\n",
      "Epoch 30/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3691 - accuracy: 0.8397 - val_loss: 0.3321 - val_accuracy: 0.8604\n",
      "Epoch 31/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3685 - accuracy: 0.8376 - val_loss: 0.3294 - val_accuracy: 0.8607\n",
      "Epoch 32/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3680 - accuracy: 0.8401 - val_loss: 0.3295 - val_accuracy: 0.8618\n",
      "Epoch 33/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3691 - accuracy: 0.8396 - val_loss: 0.3287 - val_accuracy: 0.8604\n",
      "Epoch 34/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3700 - accuracy: 0.8379 - val_loss: 0.3282 - val_accuracy: 0.8613\n",
      "Epoch 35/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3677 - accuracy: 0.8403 - val_loss: 0.3299 - val_accuracy: 0.8613\n",
      "Epoch 36/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8402 - val_loss: 0.3304 - val_accuracy: 0.8611\n",
      "Epoch 37/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3670 - accuracy: 0.8399 - val_loss: 0.3293 - val_accuracy: 0.8611\n",
      "Epoch 38/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3676 - accuracy: 0.8394 - val_loss: 0.3274 - val_accuracy: 0.8617\n",
      "Epoch 39/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3702 - accuracy: 0.8378 - val_loss: 0.3309 - val_accuracy: 0.8610\n",
      "Epoch 40/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3660 - accuracy: 0.8409 - val_loss: 0.3295 - val_accuracy: 0.8607\n",
      "Epoch 41/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3664 - accuracy: 0.8408 - val_loss: 0.3300 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3654 - accuracy: 0.8414 - val_loss: 0.3286 - val_accuracy: 0.8607\n",
      "Epoch 43/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3654 - accuracy: 0.8396 - val_loss: 0.3300 - val_accuracy: 0.8613\n",
      "Epoch 44/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3654 - accuracy: 0.8390 - val_loss: 0.3270 - val_accuracy: 0.8615\n",
      "Epoch 45/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3638 - accuracy: 0.8417 - val_loss: 0.3262 - val_accuracy: 0.8608\n",
      "Epoch 46/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3656 - accuracy: 0.8414 - val_loss: 0.3266 - val_accuracy: 0.8600\n",
      "Epoch 47/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3675 - accuracy: 0.8379 - val_loss: 0.3270 - val_accuracy: 0.8601\n",
      "Epoch 48/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3665 - accuracy: 0.8401 - val_loss: 0.3273 - val_accuracy: 0.8626\n",
      "Epoch 49/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3639 - accuracy: 0.8411 - val_loss: 0.3271 - val_accuracy: 0.8613\n",
      "Epoch 50/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3655 - accuracy: 0.8399 - val_loss: 0.3272 - val_accuracy: 0.8613\n",
      "Epoch 51/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3672 - accuracy: 0.8404 - val_loss: 0.3268 - val_accuracy: 0.8605\n",
      "Epoch 52/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3641 - accuracy: 0.8427 - val_loss: 0.3282 - val_accuracy: 0.8612\n",
      "Epoch 53/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3647 - accuracy: 0.8409 - val_loss: 0.3268 - val_accuracy: 0.8619\n",
      "Epoch 54/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3635 - accuracy: 0.8417 - val_loss: 0.3259 - val_accuracy: 0.8631\n",
      "Epoch 55/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3650 - accuracy: 0.8402 - val_loss: 0.3268 - val_accuracy: 0.8627\n",
      "Epoch 56/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3646 - accuracy: 0.8421 - val_loss: 0.3273 - val_accuracy: 0.8604\n",
      "Epoch 57/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3635 - accuracy: 0.8405 - val_loss: 0.3260 - val_accuracy: 0.8609\n",
      "Epoch 58/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3650 - accuracy: 0.8421 - val_loss: 0.3257 - val_accuracy: 0.8629\n",
      "Epoch 59/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3640 - accuracy: 0.8434 - val_loss: 0.3256 - val_accuracy: 0.8632\n",
      "Epoch 60/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3637 - accuracy: 0.8434 - val_loss: 0.3252 - val_accuracy: 0.8603\n",
      "Epoch 61/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3635 - accuracy: 0.8419 - val_loss: 0.3264 - val_accuracy: 0.8631\n",
      "Epoch 62/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3656 - accuracy: 0.8404 - val_loss: 0.3262 - val_accuracy: 0.8621\n",
      "Epoch 63/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3620 - accuracy: 0.8426 - val_loss: 0.3249 - val_accuracy: 0.8628\n",
      "Epoch 64/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3623 - accuracy: 0.8431 - val_loss: 0.3275 - val_accuracy: 0.8622\n",
      "Epoch 65/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3629 - accuracy: 0.8415 - val_loss: 0.3253 - val_accuracy: 0.8616\n",
      "Epoch 66/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3630 - accuracy: 0.8422 - val_loss: 0.3262 - val_accuracy: 0.8622\n",
      "Epoch 67/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3651 - accuracy: 0.8400 - val_loss: 0.3281 - val_accuracy: 0.8622\n",
      "Epoch 68/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3600 - accuracy: 0.8432 - val_loss: 0.3278 - val_accuracy: 0.8628\n",
      "Epoch 69/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3619 - accuracy: 0.8432 - val_loss: 0.3252 - val_accuracy: 0.8630\n",
      "Epoch 70/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3592 - accuracy: 0.8447 - val_loss: 0.3256 - val_accuracy: 0.8628\n",
      "Epoch 71/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3627 - accuracy: 0.8438 - val_loss: 0.3254 - val_accuracy: 0.8626\n",
      "Epoch 72/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3605 - accuracy: 0.8435 - val_loss: 0.3274 - val_accuracy: 0.8614\n",
      "Epoch 73/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3635 - accuracy: 0.8410 - val_loss: 0.3260 - val_accuracy: 0.8631\n",
      "Epoch 74/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3634 - accuracy: 0.8413 - val_loss: 0.3267 - val_accuracy: 0.8615\n",
      "Epoch 75/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3626 - accuracy: 0.8426 - val_loss: 0.3256 - val_accuracy: 0.8615\n",
      "Epoch 76/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3618 - accuracy: 0.8424 - val_loss: 0.3264 - val_accuracy: 0.8626\n",
      "Epoch 77/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3643 - accuracy: 0.8420 - val_loss: 0.3250 - val_accuracy: 0.8619\n",
      "Epoch 78/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3619 - accuracy: 0.8426 - val_loss: 0.3250 - val_accuracy: 0.8620\n",
      "Epoch 79/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3626 - accuracy: 0.8413 - val_loss: 0.3255 - val_accuracy: 0.8631\n",
      "Epoch 80/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3645 - accuracy: 0.8414 - val_loss: 0.3252 - val_accuracy: 0.8636\n",
      "Epoch 81/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3606 - accuracy: 0.8427 - val_loss: 0.3247 - val_accuracy: 0.8624\n",
      "Epoch 82/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3615 - accuracy: 0.8418 - val_loss: 0.3245 - val_accuracy: 0.8628\n",
      "Epoch 83/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3613 - accuracy: 0.8443 - val_loss: 0.3251 - val_accuracy: 0.8627\n",
      "Epoch 84/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3611 - accuracy: 0.8422 - val_loss: 0.3260 - val_accuracy: 0.8634\n",
      "Epoch 85/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3600 - accuracy: 0.8433 - val_loss: 0.3247 - val_accuracy: 0.8629\n",
      "Epoch 86/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3618 - accuracy: 0.8424 - val_loss: 0.3251 - val_accuracy: 0.8619\n",
      "Epoch 87/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3597 - accuracy: 0.8444 - val_loss: 0.3253 - val_accuracy: 0.8635\n",
      "Epoch 88/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3608 - accuracy: 0.8439 - val_loss: 0.3240 - val_accuracy: 0.8643\n",
      "Epoch 89/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3625 - accuracy: 0.8417 - val_loss: 0.3249 - val_accuracy: 0.8626\n",
      "Epoch 90/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3613 - accuracy: 0.8423 - val_loss: 0.3269 - val_accuracy: 0.8631\n",
      "Epoch 91/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8441 - val_loss: 0.3247 - val_accuracy: 0.8621\n",
      "Epoch 92/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3610 - accuracy: 0.8439 - val_loss: 0.3254 - val_accuracy: 0.8636\n",
      "Epoch 93/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3620 - accuracy: 0.8410 - val_loss: 0.3246 - val_accuracy: 0.8623\n",
      "Epoch 94/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3614 - accuracy: 0.8443 - val_loss: 0.3246 - val_accuracy: 0.8626\n",
      "Epoch 95/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3611 - accuracy: 0.8423 - val_loss: 0.3250 - val_accuracy: 0.8628\n",
      "Epoch 96/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3611 - accuracy: 0.8429 - val_loss: 0.3246 - val_accuracy: 0.8627\n",
      "Epoch 97/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3623 - accuracy: 0.8399 - val_loss: 0.3266 - val_accuracy: 0.8622\n",
      "Epoch 98/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8441 - val_loss: 0.3238 - val_accuracy: 0.8633\n",
      "Epoch 99/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8429 - val_loss: 0.3262 - val_accuracy: 0.8613\n",
      "Epoch 100/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3597 - accuracy: 0.8434 - val_loss: 0.3268 - val_accuracy: 0.8621\n",
      "Epoch 101/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8442 - val_loss: 0.3246 - val_accuracy: 0.8622\n",
      "Epoch 102/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8442 - val_loss: 0.3242 - val_accuracy: 0.8628\n",
      "Epoch 103/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3614 - accuracy: 0.8435 - val_loss: 0.3241 - val_accuracy: 0.8634\n",
      "Epoch 104/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8441 - val_loss: 0.3233 - val_accuracy: 0.8637\n",
      "Epoch 105/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3616 - accuracy: 0.8430 - val_loss: 0.3243 - val_accuracy: 0.8637\n",
      "Epoch 106/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8444 - val_loss: 0.3235 - val_accuracy: 0.8630\n",
      "Epoch 107/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3614 - accuracy: 0.8420 - val_loss: 0.3259 - val_accuracy: 0.8619\n",
      "Epoch 108/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3590 - accuracy: 0.8446 - val_loss: 0.3226 - val_accuracy: 0.8632\n",
      "Epoch 109/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3588 - accuracy: 0.8449 - val_loss: 0.3227 - val_accuracy: 0.8634\n",
      "Epoch 110/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8432 - val_loss: 0.3247 - val_accuracy: 0.8621\n",
      "Epoch 111/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8429 - val_loss: 0.3234 - val_accuracy: 0.8640\n",
      "Epoch 112/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3595 - accuracy: 0.8453 - val_loss: 0.3229 - val_accuracy: 0.8626\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3586 - accuracy: 0.8436 - val_loss: 0.3222 - val_accuracy: 0.8619\n",
      "Epoch 114/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3605 - accuracy: 0.8432 - val_loss: 0.3248 - val_accuracy: 0.8629\n",
      "Epoch 115/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3582 - accuracy: 0.8442 - val_loss: 0.3240 - val_accuracy: 0.8628\n",
      "Epoch 116/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8433 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 117/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3601 - accuracy: 0.8435 - val_loss: 0.3243 - val_accuracy: 0.8624\n",
      "Epoch 118/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3590 - accuracy: 0.8439 - val_loss: 0.3235 - val_accuracy: 0.8641\n",
      "Epoch 119/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3595 - accuracy: 0.8432 - val_loss: 0.3236 - val_accuracy: 0.8650\n",
      "Epoch 120/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3597 - accuracy: 0.8436 - val_loss: 0.3254 - val_accuracy: 0.8632\n",
      "Epoch 121/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3605 - accuracy: 0.8441 - val_loss: 0.3232 - val_accuracy: 0.8612\n",
      "Epoch 122/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3597 - accuracy: 0.8436 - val_loss: 0.3235 - val_accuracy: 0.8636\n",
      "Epoch 123/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8447 - val_loss: 0.3240 - val_accuracy: 0.8618\n",
      "Epoch 124/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3588 - accuracy: 0.8454 - val_loss: 0.3245 - val_accuracy: 0.8630\n",
      "Epoch 125/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3607 - accuracy: 0.8417 - val_loss: 0.3247 - val_accuracy: 0.8639\n",
      "Epoch 126/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8442 - val_loss: 0.3248 - val_accuracy: 0.8631\n",
      "Epoch 127/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.8436 - val_loss: 0.3255 - val_accuracy: 0.8632\n",
      "Epoch 128/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3588 - accuracy: 0.8449 - val_loss: 0.3268 - val_accuracy: 0.8608\n",
      "Epoch 129/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3598 - accuracy: 0.8430 - val_loss: 0.3259 - val_accuracy: 0.8622\n",
      "Epoch 130/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3583 - accuracy: 0.8452 - val_loss: 0.3226 - val_accuracy: 0.8637\n",
      "Epoch 131/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3589 - accuracy: 0.8426 - val_loss: 0.3240 - val_accuracy: 0.8628\n",
      "Epoch 132/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8442 - val_loss: 0.3247 - val_accuracy: 0.8625\n",
      "Epoch 133/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3585 - accuracy: 0.8445 - val_loss: 0.3242 - val_accuracy: 0.8632\n",
      "Epoch 134/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3589 - accuracy: 0.8444 - val_loss: 0.3263 - val_accuracy: 0.8628\n",
      "Epoch 135/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3582 - accuracy: 0.8451 - val_loss: 0.3238 - val_accuracy: 0.8629\n",
      "Epoch 136/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3565 - accuracy: 0.8453 - val_loss: 0.3240 - val_accuracy: 0.8636\n",
      "Epoch 137/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3581 - accuracy: 0.8449 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 138/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8444 - val_loss: 0.3242 - val_accuracy: 0.8629\n",
      "Epoch 139/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3595 - accuracy: 0.8450 - val_loss: 0.3237 - val_accuracy: 0.8622\n",
      "Epoch 140/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3566 - accuracy: 0.8451 - val_loss: 0.3240 - val_accuracy: 0.8628\n",
      "Epoch 141/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3559 - accuracy: 0.8449 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 142/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3604 - accuracy: 0.8442 - val_loss: 0.3244 - val_accuracy: 0.8629\n",
      "Epoch 143/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8436 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 144/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8462 - val_loss: 0.3239 - val_accuracy: 0.8634\n",
      "Epoch 145/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8432 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
      "Epoch 146/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3601 - accuracy: 0.8425 - val_loss: 0.3225 - val_accuracy: 0.8630\n",
      "Epoch 147/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3581 - accuracy: 0.8440 - val_loss: 0.3239 - val_accuracy: 0.8630\n",
      "Epoch 148/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3591 - accuracy: 0.8441 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 149/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3586 - accuracy: 0.8434 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 150/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3566 - accuracy: 0.8440 - val_loss: 0.3232 - val_accuracy: 0.8617\n",
      "Epoch 151/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3586 - accuracy: 0.8441 - val_loss: 0.3232 - val_accuracy: 0.8619\n",
      "Epoch 152/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3577 - accuracy: 0.8455 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 153/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3588 - accuracy: 0.8429 - val_loss: 0.3228 - val_accuracy: 0.8631\n",
      "Epoch 154/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3583 - accuracy: 0.8453 - val_loss: 0.3242 - val_accuracy: 0.8625\n",
      "Epoch 155/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8446 - val_loss: 0.3238 - val_accuracy: 0.8632\n",
      "Epoch 156/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8450 - val_loss: 0.3248 - val_accuracy: 0.8629\n",
      "Epoch 157/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.8461 - val_loss: 0.3233 - val_accuracy: 0.8623\n",
      "Epoch 158/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3579 - accuracy: 0.8444 - val_loss: 0.3238 - val_accuracy: 0.8628\n",
      "Epoch 159/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8448 - val_loss: 0.3237 - val_accuracy: 0.8622\n",
      "Epoch 160/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.8458 - val_loss: 0.3239 - val_accuracy: 0.8613\n",
      "Epoch 161/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3591 - accuracy: 0.8408 - val_loss: 0.3231 - val_accuracy: 0.8638\n",
      "Epoch 162/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8453 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 163/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3579 - accuracy: 0.8452 - val_loss: 0.3221 - val_accuracy: 0.8631\n",
      "Epoch 164/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8435 - val_loss: 0.3238 - val_accuracy: 0.8632\n",
      "Epoch 165/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3583 - accuracy: 0.8454 - val_loss: 0.3239 - val_accuracy: 0.8627\n",
      "Epoch 166/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8450 - val_loss: 0.3241 - val_accuracy: 0.8632\n",
      "Epoch 167/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.8440 - val_loss: 0.3230 - val_accuracy: 0.8640\n",
      "Epoch 168/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3587 - accuracy: 0.8434 - val_loss: 0.3241 - val_accuracy: 0.8641\n",
      "Epoch 169/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8450 - val_loss: 0.3240 - val_accuracy: 0.8631\n",
      "Epoch 170/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8439 - val_loss: 0.3223 - val_accuracy: 0.8628\n",
      "Epoch 171/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8431 - val_loss: 0.3227 - val_accuracy: 0.8620\n",
      "Epoch 172/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8455 - val_loss: 0.3226 - val_accuracy: 0.8607\n",
      "Epoch 173/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8465 - val_loss: 0.3245 - val_accuracy: 0.8628\n",
      "Epoch 174/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8454 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 175/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8454 - val_loss: 0.3250 - val_accuracy: 0.8619\n",
      "Epoch 176/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8451 - val_loss: 0.3242 - val_accuracy: 0.8631\n",
      "Epoch 177/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8443 - val_loss: 0.3235 - val_accuracy: 0.8633\n",
      "Epoch 178/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8448 - val_loss: 0.3246 - val_accuracy: 0.8622\n",
      "Epoch 179/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8446 - val_loss: 0.3233 - val_accuracy: 0.8627\n",
      "Epoch 180/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8458 - val_loss: 0.3250 - val_accuracy: 0.8625\n",
      "Epoch 181/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3596 - accuracy: 0.8417 - val_loss: 0.3236 - val_accuracy: 0.8618\n",
      "Epoch 182/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3564 - accuracy: 0.8462 - val_loss: 0.3247 - val_accuracy: 0.8619\n",
      "Epoch 183/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3575 - accuracy: 0.8443 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 184/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3587 - accuracy: 0.8435 - val_loss: 0.3227 - val_accuracy: 0.8630\n",
      "Epoch 185/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3580 - accuracy: 0.8451 - val_loss: 0.3241 - val_accuracy: 0.8616\n",
      "Epoch 186/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3554 - accuracy: 0.8461 - val_loss: 0.3232 - val_accuracy: 0.8629\n",
      "Epoch 187/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.8460 - val_loss: 0.3223 - val_accuracy: 0.8642\n",
      "Epoch 188/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3553 - accuracy: 0.8440 - val_loss: 0.3242 - val_accuracy: 0.8640\n",
      "Epoch 189/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3572 - accuracy: 0.8442 - val_loss: 0.3236 - val_accuracy: 0.8638\n",
      "Epoch 190/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3564 - accuracy: 0.8457 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 191/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3553 - accuracy: 0.8447 - val_loss: 0.3244 - val_accuracy: 0.8623\n",
      "Epoch 192/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8462 - val_loss: 0.3244 - val_accuracy: 0.8619\n",
      "Epoch 193/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3592 - accuracy: 0.8439 - val_loss: 0.3245 - val_accuracy: 0.8619\n",
      "Epoch 194/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3561 - accuracy: 0.8453 - val_loss: 0.3245 - val_accuracy: 0.8639\n",
      "Epoch 195/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8449 - val_loss: 0.3231 - val_accuracy: 0.8638\n",
      "Epoch 196/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8448 - val_loss: 0.3252 - val_accuracy: 0.8622\n",
      "Epoch 197/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3557 - accuracy: 0.8452 - val_loss: 0.3246 - val_accuracy: 0.8631\n",
      "Epoch 198/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3574 - accuracy: 0.8455 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 199/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3571 - accuracy: 0.8452 - val_loss: 0.3258 - val_accuracy: 0.8628\n",
      "Epoch 200/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3559 - accuracy: 0.8462 - val_loss: 0.3234 - val_accuracy: 0.8636\n",
      "Epoch 201/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8454 - val_loss: 0.3221 - val_accuracy: 0.8634\n",
      "Epoch 202/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3580 - accuracy: 0.8450 - val_loss: 0.3246 - val_accuracy: 0.8622\n",
      "Epoch 203/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3574 - accuracy: 0.8459 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
      "Epoch 204/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3571 - accuracy: 0.8442 - val_loss: 0.3242 - val_accuracy: 0.8631\n",
      "Epoch 205/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3552 - accuracy: 0.8447 - val_loss: 0.3233 - val_accuracy: 0.8630\n",
      "Epoch 206/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3559 - accuracy: 0.8463 - val_loss: 0.3226 - val_accuracy: 0.8650\n",
      "Epoch 207/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3565 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 208/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8452 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 209/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3565 - accuracy: 0.8451 - val_loss: 0.3243 - val_accuracy: 0.8628\n",
      "Epoch 210/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3570 - accuracy: 0.8449 - val_loss: 0.3225 - val_accuracy: 0.8619\n",
      "Epoch 211/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3579 - accuracy: 0.8448 - val_loss: 0.3236 - val_accuracy: 0.8623\n",
      "Epoch 212/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.8438 - val_loss: 0.3253 - val_accuracy: 0.8626\n",
      "Epoch 213/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3555 - accuracy: 0.8458 - val_loss: 0.3242 - val_accuracy: 0.8632\n",
      "Epoch 214/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3562 - accuracy: 0.8451 - val_loss: 0.3255 - val_accuracy: 0.8614\n",
      "Epoch 215/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3568 - accuracy: 0.8458 - val_loss: 0.3224 - val_accuracy: 0.8626\n",
      "Epoch 216/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8453 - val_loss: 0.3227 - val_accuracy: 0.8631\n",
      "Epoch 217/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3566 - accuracy: 0.8452 - val_loss: 0.3243 - val_accuracy: 0.8629\n",
      "Epoch 218/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3561 - accuracy: 0.8447 - val_loss: 0.3240 - val_accuracy: 0.8631\n",
      "Epoch 219/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8458 - val_loss: 0.3233 - val_accuracy: 0.8625\n",
      "Epoch 220/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3557 - accuracy: 0.8461 - val_loss: 0.3229 - val_accuracy: 0.8639\n",
      "Epoch 221/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3569 - accuracy: 0.8446 - val_loss: 0.3225 - val_accuracy: 0.8640\n",
      "Epoch 222/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8461 - val_loss: 0.3250 - val_accuracy: 0.8615\n",
      "Epoch 223/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8442 - val_loss: 0.3240 - val_accuracy: 0.8619\n",
      "Epoch 224/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3565 - accuracy: 0.8448 - val_loss: 0.3221 - val_accuracy: 0.8620\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8479 - val_loss: 0.3234 - val_accuracy: 0.8626\n",
      "Epoch 226/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3555 - accuracy: 0.8454 - val_loss: 0.3238 - val_accuracy: 0.8616\n",
      "Epoch 227/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3556 - accuracy: 0.8450 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 228/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3551 - accuracy: 0.8463 - val_loss: 0.3244 - val_accuracy: 0.8621\n",
      "Epoch 229/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8444 - val_loss: 0.3243 - val_accuracy: 0.8615\n",
      "Epoch 230/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3556 - accuracy: 0.8459 - val_loss: 0.3246 - val_accuracy: 0.8634\n",
      "Epoch 231/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3561 - accuracy: 0.8457 - val_loss: 0.3237 - val_accuracy: 0.8615\n",
      "Epoch 232/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3550 - accuracy: 0.8474 - val_loss: 0.3251 - val_accuracy: 0.8606\n",
      "Epoch 233/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8453 - val_loss: 0.3249 - val_accuracy: 0.8614\n",
      "Epoch 234/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8455 - val_loss: 0.3230 - val_accuracy: 0.8622\n",
      "Epoch 235/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8447 - val_loss: 0.3241 - val_accuracy: 0.8616\n",
      "Epoch 236/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8458 - val_loss: 0.3217 - val_accuracy: 0.8634\n",
      "Epoch 237/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.8462 - val_loss: 0.3240 - val_accuracy: 0.8617\n",
      "Epoch 238/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3578 - accuracy: 0.8448 - val_loss: 0.3252 - val_accuracy: 0.8615\n",
      "Epoch 239/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3565 - accuracy: 0.8439 - val_loss: 0.3242 - val_accuracy: 0.8616\n",
      "Epoch 240/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3554 - accuracy: 0.8479 - val_loss: 0.3238 - val_accuracy: 0.8616\n",
      "Epoch 241/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3572 - accuracy: 0.8453 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 242/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8461 - val_loss: 0.3238 - val_accuracy: 0.8617\n",
      "Epoch 243/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3563 - accuracy: 0.8449 - val_loss: 0.3244 - val_accuracy: 0.8627\n",
      "Epoch 244/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3562 - accuracy: 0.8449 - val_loss: 0.3250 - val_accuracy: 0.8631\n",
      "Epoch 245/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8460 - val_loss: 0.3242 - val_accuracy: 0.8607\n",
      "Epoch 246/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8457 - val_loss: 0.3236 - val_accuracy: 0.8616\n",
      "Epoch 247/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3549 - accuracy: 0.8465 - val_loss: 0.3253 - val_accuracy: 0.8616\n",
      "Epoch 248/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8449 - val_loss: 0.3225 - val_accuracy: 0.8628\n",
      "Epoch 249/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8452 - val_loss: 0.3241 - val_accuracy: 0.8610\n",
      "Epoch 250/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8466 - val_loss: 0.3235 - val_accuracy: 0.8625\n",
      "Epoch 251/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8443 - val_loss: 0.3235 - val_accuracy: 0.8610\n",
      "Epoch 252/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8449 - val_loss: 0.3242 - val_accuracy: 0.8610\n",
      "Epoch 253/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8472 - val_loss: 0.3239 - val_accuracy: 0.8634\n",
      "Epoch 254/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8453 - val_loss: 0.3227 - val_accuracy: 0.8622\n",
      "Epoch 255/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3564 - accuracy: 0.8468 - val_loss: 0.3247 - val_accuracy: 0.8618\n",
      "Epoch 256/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8439 - val_loss: 0.3235 - val_accuracy: 0.8620\n",
      "Epoch 257/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3559 - accuracy: 0.8459 - val_loss: 0.3227 - val_accuracy: 0.8612\n",
      "Epoch 258/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8474 - val_loss: 0.3223 - val_accuracy: 0.8619\n",
      "Epoch 259/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8471 - val_loss: 0.3232 - val_accuracy: 0.8622\n",
      "Epoch 260/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8450 - val_loss: 0.3225 - val_accuracy: 0.8626\n",
      "Epoch 261/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3558 - accuracy: 0.8448 - val_loss: 0.3235 - val_accuracy: 0.8622\n",
      "Epoch 262/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3576 - accuracy: 0.8441 - val_loss: 0.3237 - val_accuracy: 0.8638\n",
      "Epoch 263/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8462 - val_loss: 0.3226 - val_accuracy: 0.8636\n",
      "Epoch 264/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3564 - accuracy: 0.8448 - val_loss: 0.3243 - val_accuracy: 0.8640\n",
      "Epoch 265/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8458 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 266/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3572 - accuracy: 0.8446 - val_loss: 0.3254 - val_accuracy: 0.8620\n",
      "Epoch 267/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8458 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 268/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3557 - accuracy: 0.8438 - val_loss: 0.3232 - val_accuracy: 0.8624\n",
      "Epoch 269/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8455 - val_loss: 0.3242 - val_accuracy: 0.8627\n",
      "Epoch 270/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3569 - accuracy: 0.8457 - val_loss: 0.3243 - val_accuracy: 0.8625\n",
      "Epoch 271/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3547 - accuracy: 0.8457 - val_loss: 0.3241 - val_accuracy: 0.8618\n",
      "Epoch 272/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3572 - accuracy: 0.8453 - val_loss: 0.3253 - val_accuracy: 0.8628\n",
      "Epoch 273/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3566 - accuracy: 0.8442 - val_loss: 0.3225 - val_accuracy: 0.8637\n",
      "Epoch 274/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3552 - accuracy: 0.8454 - val_loss: 0.3244 - val_accuracy: 0.8610\n",
      "Epoch 275/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3554 - accuracy: 0.8448 - val_loss: 0.3251 - val_accuracy: 0.8623\n",
      "Epoch 276/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3560 - accuracy: 0.8451 - val_loss: 0.3235 - val_accuracy: 0.8618\n",
      "Epoch 277/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8460 - val_loss: 0.3253 - val_accuracy: 0.8628\n",
      "Epoch 278/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3555 - accuracy: 0.8446 - val_loss: 0.3250 - val_accuracy: 0.8624\n",
      "Epoch 279/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8462 - val_loss: 0.3230 - val_accuracy: 0.8618\n",
      "Epoch 280/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3549 - accuracy: 0.8452 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 281/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8473 - val_loss: 0.3223 - val_accuracy: 0.8628\n",
      "Epoch 282/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3553 - accuracy: 0.8449 - val_loss: 0.3248 - val_accuracy: 0.8625\n",
      "Epoch 283/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3540 - accuracy: 0.8453 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 284/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8625\n",
      "Epoch 285/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3557 - accuracy: 0.8461 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 286/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3559 - accuracy: 0.8452 - val_loss: 0.3243 - val_accuracy: 0.8632\n",
      "Epoch 287/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8470 - val_loss: 0.3243 - val_accuracy: 0.8620\n",
      "Epoch 288/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8455 - val_loss: 0.3231 - val_accuracy: 0.8618\n",
      "Epoch 289/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8472 - val_loss: 0.3261 - val_accuracy: 0.8618\n",
      "Epoch 290/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8480 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 291/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8469 - val_loss: 0.3244 - val_accuracy: 0.8619\n",
      "Epoch 292/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3550 - accuracy: 0.8452 - val_loss: 0.3224 - val_accuracy: 0.8625\n",
      "Epoch 293/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8458 - val_loss: 0.3230 - val_accuracy: 0.8625\n",
      "Epoch 294/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8495 - val_loss: 0.3264 - val_accuracy: 0.8617\n",
      "Epoch 295/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8458 - val_loss: 0.3250 - val_accuracy: 0.8617\n",
      "Epoch 296/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3561 - accuracy: 0.8450 - val_loss: 0.3232 - val_accuracy: 0.8627\n",
      "Epoch 297/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3553 - accuracy: 0.8453 - val_loss: 0.3241 - val_accuracy: 0.8628\n",
      "Epoch 298/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8487 - val_loss: 0.3237 - val_accuracy: 0.8613\n",
      "Epoch 299/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8481 - val_loss: 0.3235 - val_accuracy: 0.8610\n",
      "Epoch 300/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8469 - val_loss: 0.3222 - val_accuracy: 0.8628\n",
      "Epoch 301/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8470 - val_loss: 0.3233 - val_accuracy: 0.8618\n",
      "Epoch 302/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8460 - val_loss: 0.3234 - val_accuracy: 0.8620\n",
      "Epoch 303/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8481 - val_loss: 0.3232 - val_accuracy: 0.8622\n",
      "Epoch 304/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8459 - val_loss: 0.3228 - val_accuracy: 0.8620\n",
      "Epoch 305/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8464 - val_loss: 0.3235 - val_accuracy: 0.8622\n",
      "Epoch 306/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8487 - val_loss: 0.3228 - val_accuracy: 0.8622\n",
      "Epoch 307/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8462 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 308/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3542 - accuracy: 0.8472 - val_loss: 0.3233 - val_accuracy: 0.8628\n",
      "Epoch 309/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.8455 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 310/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3547 - accuracy: 0.8464 - val_loss: 0.3230 - val_accuracy: 0.8624\n",
      "Epoch 311/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8470 - val_loss: 0.3226 - val_accuracy: 0.8622\n",
      "Epoch 312/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8458 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 313/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8466 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 314/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3558 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8625\n",
      "Epoch 315/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8441 - val_loss: 0.3237 - val_accuracy: 0.8619\n",
      "Epoch 316/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8480 - val_loss: 0.3224 - val_accuracy: 0.8625\n",
      "Epoch 317/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3532 - accuracy: 0.8464 - val_loss: 0.3227 - val_accuracy: 0.8627\n",
      "Epoch 318/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3548 - accuracy: 0.8461 - val_loss: 0.3227 - val_accuracy: 0.8628\n",
      "Epoch 319/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3547 - accuracy: 0.8460 - val_loss: 0.3237 - val_accuracy: 0.8623\n",
      "Epoch 320/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3531 - accuracy: 0.8458 - val_loss: 0.3230 - val_accuracy: 0.8618\n",
      "Epoch 321/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3546 - accuracy: 0.8463 - val_loss: 0.3234 - val_accuracy: 0.8617\n",
      "Epoch 322/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8445 - val_loss: 0.3236 - val_accuracy: 0.8619\n",
      "Epoch 323/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3540 - accuracy: 0.8451 - val_loss: 0.3227 - val_accuracy: 0.8621\n",
      "Epoch 324/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3565 - accuracy: 0.8449 - val_loss: 0.3239 - val_accuracy: 0.8613\n",
      "Epoch 325/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3530 - accuracy: 0.8466 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 326/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8475 - val_loss: 0.3233 - val_accuracy: 0.8618\n",
      "Epoch 327/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3534 - accuracy: 0.8466 - val_loss: 0.3239 - val_accuracy: 0.8621\n",
      "Epoch 328/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3532 - accuracy: 0.8464 - val_loss: 0.3233 - val_accuracy: 0.8622\n",
      "Epoch 329/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3533 - accuracy: 0.8470 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 330/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8464 - val_loss: 0.3235 - val_accuracy: 0.8615\n",
      "Epoch 331/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3533 - accuracy: 0.8465 - val_loss: 0.3225 - val_accuracy: 0.8625\n",
      "Epoch 332/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3544 - accuracy: 0.8464 - val_loss: 0.3233 - val_accuracy: 0.8616\n",
      "Epoch 333/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3546 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8622\n",
      "Epoch 334/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3555 - accuracy: 0.8457 - val_loss: 0.3239 - val_accuracy: 0.8619\n",
      "Epoch 335/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3538 - accuracy: 0.8465 - val_loss: 0.3238 - val_accuracy: 0.8620\n",
      "Epoch 336/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3526 - accuracy: 0.8467 - val_loss: 0.3229 - val_accuracy: 0.8620\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3543 - accuracy: 0.8464 - val_loss: 0.3228 - val_accuracy: 0.8622\n",
      "Epoch 338/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8465 - val_loss: 0.3234 - val_accuracy: 0.8613\n",
      "Epoch 339/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8471 - val_loss: 0.3225 - val_accuracy: 0.8616\n",
      "Epoch 340/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3536 - accuracy: 0.8464 - val_loss: 0.3228 - val_accuracy: 0.8622\n",
      "Epoch 341/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8630\n",
      "Epoch 342/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8472 - val_loss: 0.3231 - val_accuracy: 0.8619\n",
      "Epoch 343/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8458 - val_loss: 0.3237 - val_accuracy: 0.8613\n",
      "Epoch 344/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8467 - val_loss: 0.3239 - val_accuracy: 0.8619\n",
      "Epoch 345/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8477 - val_loss: 0.3228 - val_accuracy: 0.8620\n",
      "Epoch 346/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8468 - val_loss: 0.3235 - val_accuracy: 0.8625\n",
      "Epoch 347/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3539 - accuracy: 0.8462 - val_loss: 0.3231 - val_accuracy: 0.8620\n",
      "Epoch 348/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3535 - accuracy: 0.8481 - val_loss: 0.3234 - val_accuracy: 0.8625\n",
      "Epoch 349/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3522 - accuracy: 0.8477 - val_loss: 0.3235 - val_accuracy: 0.8625\n",
      "Epoch 350/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8470 - val_loss: 0.3228 - val_accuracy: 0.8628\n",
      "Epoch 351/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8471 - val_loss: 0.3240 - val_accuracy: 0.8624\n",
      "Epoch 352/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3545 - accuracy: 0.8458 - val_loss: 0.3236 - val_accuracy: 0.8620\n",
      "Epoch 353/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8466 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 354/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8485 - val_loss: 0.3232 - val_accuracy: 0.8624\n",
      "Epoch 355/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8621\n",
      "Epoch 356/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8464 - val_loss: 0.3230 - val_accuracy: 0.8625\n",
      "Epoch 357/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8476 - val_loss: 0.3226 - val_accuracy: 0.8624\n",
      "Epoch 358/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8466 - val_loss: 0.3231 - val_accuracy: 0.8621\n",
      "Epoch 359/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8464 - val_loss: 0.3228 - val_accuracy: 0.8625\n",
      "Epoch 360/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8471 - val_loss: 0.3233 - val_accuracy: 0.8618\n",
      "Epoch 361/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8466 - val_loss: 0.3242 - val_accuracy: 0.8625\n",
      "Epoch 362/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8470 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 363/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8475 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 364/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3538 - accuracy: 0.8467 - val_loss: 0.3228 - val_accuracy: 0.8629\n",
      "Epoch 365/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3507 - accuracy: 0.8476 - val_loss: 0.3233 - val_accuracy: 0.8622\n",
      "Epoch 366/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3521 - accuracy: 0.8486 - val_loss: 0.3233 - val_accuracy: 0.8622\n",
      "Epoch 367/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8483 - val_loss: 0.3222 - val_accuracy: 0.8634\n",
      "Epoch 368/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3553 - accuracy: 0.8464 - val_loss: 0.3227 - val_accuracy: 0.8623\n",
      "Epoch 369/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3543 - accuracy: 0.8467 - val_loss: 0.3234 - val_accuracy: 0.8621\n",
      "Epoch 370/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8452 - val_loss: 0.3228 - val_accuracy: 0.8626\n",
      "Epoch 371/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.8474 - val_loss: 0.3234 - val_accuracy: 0.8625\n",
      "Epoch 372/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3538 - accuracy: 0.8457 - val_loss: 0.3232 - val_accuracy: 0.8622\n",
      "Epoch 373/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8460 - val_loss: 0.3233 - val_accuracy: 0.8623\n",
      "Epoch 374/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3536 - accuracy: 0.8463 - val_loss: 0.3234 - val_accuracy: 0.8620\n",
      "Epoch 375/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8469 - val_loss: 0.3227 - val_accuracy: 0.8619\n",
      "Epoch 376/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8460 - val_loss: 0.3221 - val_accuracy: 0.8622\n",
      "Epoch 377/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8464 - val_loss: 0.3224 - val_accuracy: 0.8626\n",
      "Epoch 378/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8464 - val_loss: 0.3237 - val_accuracy: 0.8620\n",
      "Epoch 379/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8460 - val_loss: 0.3236 - val_accuracy: 0.8619\n",
      "Epoch 380/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8476 - val_loss: 0.3225 - val_accuracy: 0.8619\n",
      "Epoch 381/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8469 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 382/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8461 - val_loss: 0.3227 - val_accuracy: 0.8613\n",
      "Epoch 383/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3533 - accuracy: 0.8463 - val_loss: 0.3236 - val_accuracy: 0.8621\n",
      "Epoch 384/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8475 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 385/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 386/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8465 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 387/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8482 - val_loss: 0.3232 - val_accuracy: 0.8619\n",
      "Epoch 388/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8458 - val_loss: 0.3234 - val_accuracy: 0.8621\n",
      "Epoch 389/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8482 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 390/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8477 - val_loss: 0.3236 - val_accuracy: 0.8614\n",
      "Epoch 391/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3547 - accuracy: 0.8447 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 392/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8460 - val_loss: 0.3223 - val_accuracy: 0.8629\n",
      "Epoch 393/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8475 - val_loss: 0.3225 - val_accuracy: 0.8625\n",
      "Epoch 394/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3516 - accuracy: 0.8477 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 395/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8470 - val_loss: 0.3225 - val_accuracy: 0.8626\n",
      "Epoch 396/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8464 - val_loss: 0.3227 - val_accuracy: 0.8622\n",
      "Epoch 397/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8463 - val_loss: 0.3229 - val_accuracy: 0.8624\n",
      "Epoch 398/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8479 - val_loss: 0.3225 - val_accuracy: 0.8625\n",
      "Epoch 399/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8468 - val_loss: 0.3226 - val_accuracy: 0.8629\n",
      "Epoch 400/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8481 - val_loss: 0.3232 - val_accuracy: 0.8614\n",
      "Epoch 401/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8465 - val_loss: 0.3225 - val_accuracy: 0.8618\n",
      "Epoch 402/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.3231 - val_accuracy: 0.8623\n",
      "Epoch 403/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8475 - val_loss: 0.3235 - val_accuracy: 0.8622\n",
      "Epoch 404/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8482 - val_loss: 0.3233 - val_accuracy: 0.8623\n",
      "Epoch 405/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8623\n",
      "Epoch 406/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8468 - val_loss: 0.3229 - val_accuracy: 0.8624\n",
      "Epoch 407/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8467 - val_loss: 0.3229 - val_accuracy: 0.8622\n",
      "Epoch 408/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8461 - val_loss: 0.3227 - val_accuracy: 0.8619\n",
      "Epoch 409/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8471 - val_loss: 0.3232 - val_accuracy: 0.8627\n",
      "Epoch 410/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8470 - val_loss: 0.3227 - val_accuracy: 0.8623\n",
      "Epoch 411/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.3231 - val_accuracy: 0.8623\n",
      "Epoch 412/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8624\n",
      "Epoch 413/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8460 - val_loss: 0.3227 - val_accuracy: 0.8632\n",
      "Epoch 414/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8464 - val_loss: 0.3243 - val_accuracy: 0.8618\n",
      "Epoch 415/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8464 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 416/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8467 - val_loss: 0.3229 - val_accuracy: 0.8627\n",
      "Epoch 417/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3507 - accuracy: 0.8493 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 418/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8467 - val_loss: 0.3234 - val_accuracy: 0.8623\n",
      "Epoch 419/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8479 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 420/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8469 - val_loss: 0.3238 - val_accuracy: 0.8628\n",
      "Epoch 421/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8453 - val_loss: 0.3236 - val_accuracy: 0.8616\n",
      "Epoch 422/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8465 - val_loss: 0.3226 - val_accuracy: 0.8619\n",
      "Epoch 423/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8467 - val_loss: 0.3230 - val_accuracy: 0.8629\n",
      "Epoch 424/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3551 - accuracy: 0.8459 - val_loss: 0.3231 - val_accuracy: 0.8619\n",
      "Epoch 425/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8477 - val_loss: 0.3233 - val_accuracy: 0.8627\n",
      "Epoch 426/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8483 - val_loss: 0.3239 - val_accuracy: 0.8624\n",
      "Epoch 427/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8484 - val_loss: 0.3226 - val_accuracy: 0.8625\n",
      "Epoch 428/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8460 - val_loss: 0.3233 - val_accuracy: 0.8620\n",
      "Epoch 429/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8463 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 430/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 431/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8447 - val_loss: 0.3227 - val_accuracy: 0.8627\n",
      "Epoch 432/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8480 - val_loss: 0.3226 - val_accuracy: 0.8623\n",
      "Epoch 433/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3515 - accuracy: 0.8478 - val_loss: 0.3228 - val_accuracy: 0.8631\n",
      "Epoch 434/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8476 - val_loss: 0.3228 - val_accuracy: 0.8622\n",
      "Epoch 435/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8470 - val_loss: 0.3225 - val_accuracy: 0.8623\n",
      "Epoch 436/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.8468 - val_loss: 0.3222 - val_accuracy: 0.8625\n",
      "Epoch 437/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3529 - accuracy: 0.8463 - val_loss: 0.3224 - val_accuracy: 0.8623\n",
      "Epoch 438/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3536 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 439/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3527 - accuracy: 0.8459 - val_loss: 0.3227 - val_accuracy: 0.8623\n",
      "Epoch 440/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3544 - accuracy: 0.8467 - val_loss: 0.3237 - val_accuracy: 0.8622\n",
      "Epoch 441/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3525 - accuracy: 0.8463 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 442/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3535 - accuracy: 0.8471 - val_loss: 0.3238 - val_accuracy: 0.8622\n",
      "Epoch 443/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8482 - val_loss: 0.3235 - val_accuracy: 0.8623\n",
      "Epoch 444/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3535 - accuracy: 0.8469 - val_loss: 0.3235 - val_accuracy: 0.8622\n",
      "Epoch 445/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8477 - val_loss: 0.3237 - val_accuracy: 0.8621\n",
      "Epoch 446/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8467 - val_loss: 0.3236 - val_accuracy: 0.8623\n",
      "Epoch 447/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8472 - val_loss: 0.3231 - val_accuracy: 0.8622\n",
      "Epoch 448/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8467 - val_loss: 0.3230 - val_accuracy: 0.8627\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8479 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 450/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8458 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 451/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3547 - accuracy: 0.8460 - val_loss: 0.3239 - val_accuracy: 0.8627\n",
      "Epoch 452/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8482 - val_loss: 0.3230 - val_accuracy: 0.8627\n",
      "Epoch 453/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8626\n",
      "Epoch 454/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8478 - val_loss: 0.3230 - val_accuracy: 0.8629\n",
      "Epoch 455/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8464 - val_loss: 0.3229 - val_accuracy: 0.8625\n",
      "Epoch 456/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8467 - val_loss: 0.3232 - val_accuracy: 0.8625\n",
      "Epoch 457/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 458/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8494 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 459/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3496 - accuracy: 0.8482 - val_loss: 0.3230 - val_accuracy: 0.8623\n",
      "Epoch 460/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8482 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 461/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3522 - accuracy: 0.8453 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 462/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3529 - accuracy: 0.8462 - val_loss: 0.3226 - val_accuracy: 0.8636\n",
      "Epoch 463/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8485 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 464/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3538 - accuracy: 0.8460 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 465/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8485 - val_loss: 0.3236 - val_accuracy: 0.8627\n",
      "Epoch 466/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8468 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 467/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8464 - val_loss: 0.3229 - val_accuracy: 0.8629\n",
      "Epoch 468/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8462 - val_loss: 0.3227 - val_accuracy: 0.8625\n",
      "Epoch 469/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8468 - val_loss: 0.3227 - val_accuracy: 0.8624\n",
      "Epoch 470/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8461 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 471/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8488 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 472/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8474 - val_loss: 0.3235 - val_accuracy: 0.8621\n",
      "Epoch 473/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8473 - val_loss: 0.3237 - val_accuracy: 0.8624\n",
      "Epoch 474/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8449 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 475/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8463 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 476/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3532 - accuracy: 0.8463 - val_loss: 0.3237 - val_accuracy: 0.8628\n",
      "Epoch 477/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.8497 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 478/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8468 - val_loss: 0.3238 - val_accuracy: 0.8618\n",
      "Epoch 479/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8460 - val_loss: 0.3229 - val_accuracy: 0.8630\n",
      "Epoch 480/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8466 - val_loss: 0.3234 - val_accuracy: 0.8622\n",
      "Epoch 481/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8477 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 482/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8467 - val_loss: 0.3231 - val_accuracy: 0.8626\n",
      "Epoch 483/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8461 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 484/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8476 - val_loss: 0.3231 - val_accuracy: 0.8616\n",
      "Epoch 485/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3509 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8624\n",
      "Epoch 486/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3540 - accuracy: 0.8465 - val_loss: 0.3228 - val_accuracy: 0.8630\n",
      "Epoch 487/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3516 - accuracy: 0.8466 - val_loss: 0.3229 - val_accuracy: 0.8626\n",
      "Epoch 488/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8455 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 489/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8462 - val_loss: 0.3237 - val_accuracy: 0.8625\n",
      "Epoch 490/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3528 - accuracy: 0.8475 - val_loss: 0.3229 - val_accuracy: 0.8628\n",
      "Epoch 491/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8468 - val_loss: 0.3229 - val_accuracy: 0.8627\n",
      "Epoch 492/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8460 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 493/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8460 - val_loss: 0.3227 - val_accuracy: 0.8634\n",
      "Epoch 494/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3512 - accuracy: 0.8477 - val_loss: 0.3225 - val_accuracy: 0.8628\n",
      "Epoch 495/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8467 - val_loss: 0.3229 - val_accuracy: 0.8625\n",
      "Epoch 496/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3532 - accuracy: 0.8479 - val_loss: 0.3234 - val_accuracy: 0.8622\n",
      "Epoch 497/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8481 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 498/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8474 - val_loss: 0.3224 - val_accuracy: 0.8625\n",
      "Epoch 499/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8473 - val_loss: 0.3235 - val_accuracy: 0.8626\n",
      "Epoch 500/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8625\n",
      "Epoch 501/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3527 - accuracy: 0.8458 - val_loss: 0.3223 - val_accuracy: 0.8633\n",
      "Epoch 502/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8478 - val_loss: 0.3225 - val_accuracy: 0.8626\n",
      "Epoch 503/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8625\n",
      "Epoch 504/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8470 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 505/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8471 - val_loss: 0.3224 - val_accuracy: 0.8628\n",
      "Epoch 506/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8475 - val_loss: 0.3226 - val_accuracy: 0.8631\n",
      "Epoch 507/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8470 - val_loss: 0.3228 - val_accuracy: 0.8631\n",
      "Epoch 508/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8465 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 509/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8466 - val_loss: 0.3227 - val_accuracy: 0.8630\n",
      "Epoch 510/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8462 - val_loss: 0.3232 - val_accuracy: 0.8619\n",
      "Epoch 511/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8464 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 512/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8478 - val_loss: 0.3227 - val_accuracy: 0.8629\n",
      "Epoch 513/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8469 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 514/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8462 - val_loss: 0.3241 - val_accuracy: 0.8624\n",
      "Epoch 515/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8482 - val_loss: 0.3237 - val_accuracy: 0.8623\n",
      "Epoch 516/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8464 - val_loss: 0.3239 - val_accuracy: 0.8623\n",
      "Epoch 517/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8480 - val_loss: 0.3235 - val_accuracy: 0.8622\n",
      "Epoch 518/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8468 - val_loss: 0.3232 - val_accuracy: 0.8627\n",
      "Epoch 519/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 520/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8474 - val_loss: 0.3238 - val_accuracy: 0.8625\n",
      "Epoch 521/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3529 - accuracy: 0.8458 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 522/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8483 - val_loss: 0.3230 - val_accuracy: 0.8626\n",
      "Epoch 523/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8490 - val_loss: 0.3238 - val_accuracy: 0.8627\n",
      "Epoch 524/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8461 - val_loss: 0.3233 - val_accuracy: 0.8627\n",
      "Epoch 525/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3522 - accuracy: 0.8469 - val_loss: 0.3226 - val_accuracy: 0.8631\n",
      "Epoch 526/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8469 - val_loss: 0.3233 - val_accuracy: 0.8625\n",
      "Epoch 527/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8460 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 528/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8463 - val_loss: 0.3226 - val_accuracy: 0.8618\n",
      "Epoch 529/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.8461 - val_loss: 0.3237 - val_accuracy: 0.8619\n",
      "Epoch 530/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8475 - val_loss: 0.3227 - val_accuracy: 0.8633\n",
      "Epoch 531/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8464 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 532/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8486 - val_loss: 0.3228 - val_accuracy: 0.8627\n",
      "Epoch 533/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8461 - val_loss: 0.3231 - val_accuracy: 0.8627\n",
      "Epoch 534/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3515 - accuracy: 0.8469 - val_loss: 0.3235 - val_accuracy: 0.8637\n",
      "Epoch 535/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8465 - val_loss: 0.3228 - val_accuracy: 0.8634\n",
      "Epoch 536/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8460 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 537/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8474 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 538/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8464 - val_loss: 0.3225 - val_accuracy: 0.8637\n",
      "Epoch 539/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8479 - val_loss: 0.3227 - val_accuracy: 0.8636\n",
      "Epoch 540/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8465 - val_loss: 0.3237 - val_accuracy: 0.8623\n",
      "Epoch 541/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8465 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 542/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8481 - val_loss: 0.3228 - val_accuracy: 0.8628\n",
      "Epoch 543/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3510 - accuracy: 0.8482 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 544/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3520 - accuracy: 0.8463 - val_loss: 0.3236 - val_accuracy: 0.8626\n",
      "Epoch 545/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3503 - accuracy: 0.8487 - val_loss: 0.3238 - val_accuracy: 0.8617\n",
      "Epoch 546/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8466 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 547/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3516 - accuracy: 0.8478 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 548/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8482 - val_loss: 0.3239 - val_accuracy: 0.8629\n",
      "Epoch 549/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8480 - val_loss: 0.3234 - val_accuracy: 0.8625\n",
      "Epoch 550/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8468 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 551/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8479 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 552/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3529 - accuracy: 0.8472 - val_loss: 0.3230 - val_accuracy: 0.8622\n",
      "Epoch 553/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8455 - val_loss: 0.3235 - val_accuracy: 0.8629\n",
      "Epoch 554/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8469 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 555/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8466 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 556/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8632\n",
      "Epoch 557/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3230 - val_accuracy: 0.8627\n",
      "Epoch 558/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8487 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 559/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 560/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3537 - accuracy: 0.8470 - val_loss: 0.3246 - val_accuracy: 0.8628\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8460 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 562/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3503 - accuracy: 0.8471 - val_loss: 0.3224 - val_accuracy: 0.8637\n",
      "Epoch 563/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8467 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 564/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3534 - accuracy: 0.8476 - val_loss: 0.3236 - val_accuracy: 0.8636\n",
      "Epoch 565/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3522 - accuracy: 0.8470 - val_loss: 0.3235 - val_accuracy: 0.8629\n",
      "Epoch 566/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8465 - val_loss: 0.3229 - val_accuracy: 0.8639\n",
      "Epoch 567/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8459 - val_loss: 0.3229 - val_accuracy: 0.8629\n",
      "Epoch 568/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3539 - accuracy: 0.8457 - val_loss: 0.3238 - val_accuracy: 0.8631\n",
      "Epoch 569/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3540 - accuracy: 0.8470 - val_loss: 0.3238 - val_accuracy: 0.8626\n",
      "Epoch 570/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3527 - accuracy: 0.8479 - val_loss: 0.3232 - val_accuracy: 0.8632\n",
      "Epoch 571/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8470 - val_loss: 0.3228 - val_accuracy: 0.8639\n",
      "Epoch 572/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8476 - val_loss: 0.3228 - val_accuracy: 0.8637\n",
      "Epoch 573/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3541 - accuracy: 0.8453 - val_loss: 0.3237 - val_accuracy: 0.8628\n",
      "Epoch 574/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8462 - val_loss: 0.3229 - val_accuracy: 0.8636\n",
      "Epoch 575/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8483 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 576/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3520 - accuracy: 0.8472 - val_loss: 0.3241 - val_accuracy: 0.8625\n",
      "Epoch 577/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8478 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 578/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8479 - val_loss: 0.3238 - val_accuracy: 0.8628\n",
      "Epoch 579/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3541 - accuracy: 0.8465 - val_loss: 0.3238 - val_accuracy: 0.8629\n",
      "Epoch 580/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8482 - val_loss: 0.3229 - val_accuracy: 0.8626\n",
      "Epoch 581/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3507 - accuracy: 0.8487 - val_loss: 0.3226 - val_accuracy: 0.8639\n",
      "Epoch 582/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8460 - val_loss: 0.3226 - val_accuracy: 0.8634\n",
      "Epoch 583/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8466 - val_loss: 0.3230 - val_accuracy: 0.8625\n",
      "Epoch 584/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8475 - val_loss: 0.3233 - val_accuracy: 0.8628\n",
      "Epoch 585/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3507 - accuracy: 0.8477 - val_loss: 0.3229 - val_accuracy: 0.8623\n",
      "Epoch 586/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3513 - accuracy: 0.8476 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 587/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3545 - accuracy: 0.8458 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 588/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3510 - accuracy: 0.8481 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 589/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8466 - val_loss: 0.3237 - val_accuracy: 0.8630\n",
      "Epoch 590/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8454 - val_loss: 0.3236 - val_accuracy: 0.8634\n",
      "Epoch 591/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3512 - accuracy: 0.8470 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 592/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8461 - val_loss: 0.3225 - val_accuracy: 0.8631\n",
      "Epoch 593/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8463 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 594/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8464 - val_loss: 0.3225 - val_accuracy: 0.8633\n",
      "Epoch 595/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8475 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 596/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3503 - accuracy: 0.8487 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 597/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8484 - val_loss: 0.3236 - val_accuracy: 0.8622\n",
      "Epoch 598/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8454 - val_loss: 0.3242 - val_accuracy: 0.8625\n",
      "Epoch 599/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8462 - val_loss: 0.3235 - val_accuracy: 0.8628\n",
      "Epoch 600/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 601/1000\n",
      "424/424 [==============================] - 3s 8ms/step - loss: 0.3510 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 602/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8483 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 603/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8485 - val_loss: 0.3236 - val_accuracy: 0.8635\n",
      "Epoch 604/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 605/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8484 - val_loss: 0.3238 - val_accuracy: 0.8629\n",
      "Epoch 606/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8471 - val_loss: 0.3229 - val_accuracy: 0.8632\n",
      "Epoch 607/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3510 - accuracy: 0.8476 - val_loss: 0.3232 - val_accuracy: 0.8629\n",
      "Epoch 608/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8478 - val_loss: 0.3238 - val_accuracy: 0.8629\n",
      "Epoch 609/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8483 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 610/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8472 - val_loss: 0.3228 - val_accuracy: 0.8636\n",
      "Epoch 611/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8479 - val_loss: 0.3232 - val_accuracy: 0.8636\n",
      "Epoch 612/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8472 - val_loss: 0.3236 - val_accuracy: 0.8629\n",
      "Epoch 613/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8475 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 614/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8463 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 615/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3539 - accuracy: 0.8470 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 616/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8477 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 617/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.8641\n",
      "Epoch 618/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8459 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 619/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8473 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 620/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8475 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 621/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8475 - val_loss: 0.3233 - val_accuracy: 0.8627\n",
      "Epoch 622/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8464 - val_loss: 0.3234 - val_accuracy: 0.8638\n",
      "Epoch 623/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8482 - val_loss: 0.3233 - val_accuracy: 0.8628\n",
      "Epoch 624/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8455 - val_loss: 0.3232 - val_accuracy: 0.8632\n",
      "Epoch 625/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8478 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 626/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8479 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 627/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3491 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 628/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8464 - val_loss: 0.3236 - val_accuracy: 0.8635\n",
      "Epoch 629/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 630/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8476 - val_loss: 0.3232 - val_accuracy: 0.8629\n",
      "Epoch 631/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8467 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 632/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8470 - val_loss: 0.3234 - val_accuracy: 0.8627\n",
      "Epoch 633/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 634/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3544 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8640\n",
      "Epoch 635/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3500 - accuracy: 0.8471 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 636/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8467 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 637/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8471 - val_loss: 0.3230 - val_accuracy: 0.8635\n",
      "Epoch 638/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8469 - val_loss: 0.3228 - val_accuracy: 0.8638\n",
      "Epoch 639/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8470 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 640/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3503 - accuracy: 0.8482 - val_loss: 0.3225 - val_accuracy: 0.8635\n",
      "Epoch 641/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8479 - val_loss: 0.3230 - val_accuracy: 0.8627\n",
      "Epoch 642/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8457 - val_loss: 0.3230 - val_accuracy: 0.8629\n",
      "Epoch 643/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8479 - val_loss: 0.3230 - val_accuracy: 0.8634\n",
      "Epoch 644/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3514 - accuracy: 0.8472 - val_loss: 0.3226 - val_accuracy: 0.8635\n",
      "Epoch 645/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.8482 - val_loss: 0.3224 - val_accuracy: 0.8634\n",
      "Epoch 646/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8481 - val_loss: 0.3231 - val_accuracy: 0.8627\n",
      "Epoch 647/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8630\n",
      "Epoch 648/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3513 - accuracy: 0.8476 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 649/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8470 - val_loss: 0.3233 - val_accuracy: 0.8630\n",
      "Epoch 650/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8482 - val_loss: 0.3235 - val_accuracy: 0.8627\n",
      "Epoch 651/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3509 - accuracy: 0.8475 - val_loss: 0.3232 - val_accuracy: 0.8626\n",
      "Epoch 652/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8472 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 653/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3536 - accuracy: 0.8466 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 654/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8471 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 655/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3515 - accuracy: 0.8475 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 656/1000\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.3505 - accuracy: 0.8471 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 657/1000\n",
      "424/424 [==============================] - 3s 6ms/step - loss: 0.3526 - accuracy: 0.8477 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 658/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3520 - accuracy: 0.8463 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 659/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3513 - accuracy: 0.8479 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 660/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8467 - val_loss: 0.3234 - val_accuracy: 0.8630\n",
      "Epoch 661/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8468 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 662/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8459 - val_loss: 0.3235 - val_accuracy: 0.8633\n",
      "Epoch 663/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8479 - val_loss: 0.3234 - val_accuracy: 0.8632\n",
      "Epoch 664/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.8460 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 665/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3513 - accuracy: 0.8487 - val_loss: 0.3234 - val_accuracy: 0.8638\n",
      "Epoch 666/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8471 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 667/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8469 - val_loss: 0.3228 - val_accuracy: 0.8637\n",
      "Epoch 668/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3515 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 669/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3498 - accuracy: 0.8484 - val_loss: 0.3227 - val_accuracy: 0.8633\n",
      "Epoch 670/1000\n",
      "424/424 [==============================] - 3s 8ms/step - loss: 0.3518 - accuracy: 0.8478 - val_loss: 0.3225 - val_accuracy: 0.8631\n",
      "Epoch 671/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3501 - accuracy: 0.8493 - val_loss: 0.3230 - val_accuracy: 0.8634\n",
      "Epoch 672/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3533 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8477 - val_loss: 0.3234 - val_accuracy: 0.8629\n",
      "Epoch 674/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8471 - val_loss: 0.3235 - val_accuracy: 0.8628\n",
      "Epoch 675/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3503 - accuracy: 0.8478 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 676/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8464 - val_loss: 0.3228 - val_accuracy: 0.8630\n",
      "Epoch 677/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8478 - val_loss: 0.3234 - val_accuracy: 0.8636\n",
      "Epoch 678/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8472 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 679/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8481 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 680/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8485 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 681/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8472 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 682/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8488 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 683/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3544 - accuracy: 0.8451 - val_loss: 0.3235 - val_accuracy: 0.8629\n",
      "Epoch 684/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8447 - val_loss: 0.3233 - val_accuracy: 0.8636\n",
      "Epoch 685/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3499 - accuracy: 0.8498 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 686/1000\n",
      "424/424 [==============================] - 3s 7ms/step - loss: 0.3504 - accuracy: 0.8485 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 687/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3516 - accuracy: 0.8471 - val_loss: 0.3233 - val_accuracy: 0.8636\n",
      "Epoch 688/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8473 - val_loss: 0.3229 - val_accuracy: 0.8635\n",
      "Epoch 689/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8486 - val_loss: 0.3231 - val_accuracy: 0.8630\n",
      "Epoch 690/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8477 - val_loss: 0.3230 - val_accuracy: 0.8640\n",
      "Epoch 691/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 692/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8625\n",
      "Epoch 693/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8486 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 694/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3499 - accuracy: 0.8479 - val_loss: 0.3236 - val_accuracy: 0.8635\n",
      "Epoch 695/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8455 - val_loss: 0.3236 - val_accuracy: 0.8629\n",
      "Epoch 696/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8479 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 697/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8478 - val_loss: 0.3240 - val_accuracy: 0.8633\n",
      "Epoch 698/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8470 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 699/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8472 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 700/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8448 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 701/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3514 - accuracy: 0.8462 - val_loss: 0.3230 - val_accuracy: 0.8629\n",
      "Epoch 702/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3544 - accuracy: 0.8469 - val_loss: 0.3234 - val_accuracy: 0.8639\n",
      "Epoch 703/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.3237 - val_accuracy: 0.8633\n",
      "Epoch 704/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8456 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 705/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8630\n",
      "Epoch 706/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8479 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 707/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8463 - val_loss: 0.3239 - val_accuracy: 0.8621\n",
      "Epoch 708/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8492 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 709/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8472 - val_loss: 0.3231 - val_accuracy: 0.8638\n",
      "Epoch 710/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8466 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 711/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3543 - accuracy: 0.8462 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 712/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8453 - val_loss: 0.3226 - val_accuracy: 0.8630\n",
      "Epoch 713/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8479 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 714/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8469 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 715/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8481 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 716/1000\n",
      "424/424 [==============================] - 2s 6ms/step - loss: 0.3518 - accuracy: 0.8465 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 717/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3520 - accuracy: 0.8486 - val_loss: 0.3230 - val_accuracy: 0.8635\n",
      "Epoch 718/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8478 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 719/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8469 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 720/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3513 - accuracy: 0.8469 - val_loss: 0.3235 - val_accuracy: 0.8624\n",
      "Epoch 721/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.8482 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 722/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8462 - val_loss: 0.3232 - val_accuracy: 0.8632\n",
      "Epoch 723/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 724/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8477 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 725/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8469 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 726/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8477 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 727/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 728/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3518 - accuracy: 0.8470 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 729/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8464 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 730/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8472 - val_loss: 0.3232 - val_accuracy: 0.8635\n",
      "Epoch 731/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8472 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 732/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3526 - accuracy: 0.8464 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 733/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.8470 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 734/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3536 - accuracy: 0.8458 - val_loss: 0.3234 - val_accuracy: 0.8626\n",
      "Epoch 735/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8474 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 736/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 737/1000\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8463 - val_loss: 0.3234 - val_accuracy: 0.8637\n",
      "Epoch 738/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8480 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 739/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 740/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3496 - accuracy: 0.8476 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 741/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8455 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 742/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8637\n",
      "Epoch 743/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8477 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 744/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8484 - val_loss: 0.3233 - val_accuracy: 0.8628\n",
      "Epoch 745/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8480 - val_loss: 0.3236 - val_accuracy: 0.8629\n",
      "Epoch 746/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8465 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 747/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8456 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 748/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8468 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 749/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 750/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8468 - val_loss: 0.3235 - val_accuracy: 0.8629\n",
      "Epoch 751/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8471 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 752/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8468 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 753/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8473 - val_loss: 0.3228 - val_accuracy: 0.8631\n",
      "Epoch 754/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8473 - val_loss: 0.3239 - val_accuracy: 0.8634\n",
      "Epoch 755/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3503 - accuracy: 0.8487 - val_loss: 0.3230 - val_accuracy: 0.8638\n",
      "Epoch 756/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8465 - val_loss: 0.3235 - val_accuracy: 0.8635\n",
      "Epoch 757/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8478 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 758/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8466 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 759/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8472 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 760/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8640\n",
      "Epoch 761/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8479 - val_loss: 0.3229 - val_accuracy: 0.8635\n",
      "Epoch 762/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8486 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 763/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3501 - accuracy: 0.8484 - val_loss: 0.3228 - val_accuracy: 0.8633\n",
      "Epoch 764/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8487 - val_loss: 0.3227 - val_accuracy: 0.8634\n",
      "Epoch 765/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8474 - val_loss: 0.3228 - val_accuracy: 0.8635\n",
      "Epoch 766/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3507 - accuracy: 0.8483 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 767/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8472 - val_loss: 0.3228 - val_accuracy: 0.8639\n",
      "Epoch 768/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8463 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 769/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8475 - val_loss: 0.3229 - val_accuracy: 0.8638\n",
      "Epoch 770/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8469 - val_loss: 0.3234 - val_accuracy: 0.8633\n",
      "Epoch 771/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8478 - val_loss: 0.3240 - val_accuracy: 0.8632\n",
      "Epoch 772/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8470 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 773/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3504 - accuracy: 0.8473 - val_loss: 0.3232 - val_accuracy: 0.8639\n",
      "Epoch 774/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8483 - val_loss: 0.3233 - val_accuracy: 0.8636\n",
      "Epoch 775/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8466 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 776/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8472 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 777/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8472 - val_loss: 0.3234 - val_accuracy: 0.8627\n",
      "Epoch 778/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8467 - val_loss: 0.3238 - val_accuracy: 0.8631\n",
      "Epoch 779/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8636\n",
      "Epoch 780/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8465 - val_loss: 0.3238 - val_accuracy: 0.8636\n",
      "Epoch 781/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8471 - val_loss: 0.3232 - val_accuracy: 0.8627\n",
      "Epoch 782/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8471 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 783/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8481 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 784/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3502 - accuracy: 0.8479 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8492 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 786/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8466 - val_loss: 0.3239 - val_accuracy: 0.8627\n",
      "Epoch 787/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8496 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 788/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8468 - val_loss: 0.3229 - val_accuracy: 0.8636\n",
      "Epoch 789/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3489 - accuracy: 0.8489 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 790/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3500 - accuracy: 0.8480 - val_loss: 0.3228 - val_accuracy: 0.8646\n",
      "Epoch 791/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8485 - val_loss: 0.3227 - val_accuracy: 0.8637\n",
      "Epoch 792/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8478 - val_loss: 0.3234 - val_accuracy: 0.8629\n",
      "Epoch 793/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3535 - accuracy: 0.8466 - val_loss: 0.3228 - val_accuracy: 0.8637\n",
      "Epoch 794/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8482 - val_loss: 0.3234 - val_accuracy: 0.8629\n",
      "Epoch 795/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8468 - val_loss: 0.3236 - val_accuracy: 0.8637\n",
      "Epoch 796/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8466 - val_loss: 0.3234 - val_accuracy: 0.8641\n",
      "Epoch 797/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8453 - val_loss: 0.3234 - val_accuracy: 0.8640\n",
      "Epoch 798/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8463 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 799/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8639\n",
      "Epoch 800/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8461 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 801/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8473 - val_loss: 0.3239 - val_accuracy: 0.8631\n",
      "Epoch 802/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8467 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 803/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8475 - val_loss: 0.3229 - val_accuracy: 0.8636\n",
      "Epoch 804/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8466 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 805/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 806/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8467 - val_loss: 0.3240 - val_accuracy: 0.8633\n",
      "Epoch 807/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8463 - val_loss: 0.3234 - val_accuracy: 0.8636\n",
      "Epoch 808/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8484 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 809/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 810/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8475 - val_loss: 0.3230 - val_accuracy: 0.8640\n",
      "Epoch 811/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8474 - val_loss: 0.3235 - val_accuracy: 0.8640\n",
      "Epoch 812/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.8480 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 813/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3233 - val_accuracy: 0.8633\n",
      "Epoch 814/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8471 - val_loss: 0.3230 - val_accuracy: 0.8638\n",
      "Epoch 815/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8463 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 816/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8456 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 817/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8463 - val_loss: 0.3237 - val_accuracy: 0.8633\n",
      "Epoch 818/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8471 - val_loss: 0.3233 - val_accuracy: 0.8632\n",
      "Epoch 819/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8489 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 820/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8468 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 821/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8466 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 822/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.3234 - val_accuracy: 0.8630\n",
      "Epoch 823/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8460 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 824/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8476 - val_loss: 0.3237 - val_accuracy: 0.8629\n",
      "Epoch 825/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8482 - val_loss: 0.3236 - val_accuracy: 0.8633\n",
      "Epoch 826/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8487 - val_loss: 0.3240 - val_accuracy: 0.8635\n",
      "Epoch 827/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8474 - val_loss: 0.3230 - val_accuracy: 0.8634\n",
      "Epoch 828/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8488 - val_loss: 0.3240 - val_accuracy: 0.8632\n",
      "Epoch 829/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.8485 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 830/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8466 - val_loss: 0.3230 - val_accuracy: 0.8633\n",
      "Epoch 831/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3494 - accuracy: 0.8479 - val_loss: 0.3235 - val_accuracy: 0.8633\n",
      "Epoch 832/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8467 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 833/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8478 - val_loss: 0.3235 - val_accuracy: 0.8631\n",
      "Epoch 834/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8480 - val_loss: 0.3234 - val_accuracy: 0.8637\n",
      "Epoch 835/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3507 - accuracy: 0.8486 - val_loss: 0.3233 - val_accuracy: 0.8638\n",
      "Epoch 836/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8476 - val_loss: 0.3237 - val_accuracy: 0.8634\n",
      "Epoch 837/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8487 - val_loss: 0.3228 - val_accuracy: 0.8640\n",
      "Epoch 838/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8465 - val_loss: 0.3232 - val_accuracy: 0.8632\n",
      "Epoch 839/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8481 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 840/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8467 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 841/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3496 - accuracy: 0.8483 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 842/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8481 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 843/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8465 - val_loss: 0.3228 - val_accuracy: 0.8635\n",
      "Epoch 844/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.3226 - val_accuracy: 0.8633\n",
      "Epoch 845/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8478 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
      "Epoch 846/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8486 - val_loss: 0.3233 - val_accuracy: 0.8633\n",
      "Epoch 847/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 848/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8466 - val_loss: 0.3228 - val_accuracy: 0.8633\n",
      "Epoch 849/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8635\n",
      "Epoch 850/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8464 - val_loss: 0.3234 - val_accuracy: 0.8626\n",
      "Epoch 851/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8483 - val_loss: 0.3235 - val_accuracy: 0.8636\n",
      "Epoch 852/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8469 - val_loss: 0.3237 - val_accuracy: 0.8632\n",
      "Epoch 853/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8481 - val_loss: 0.3237 - val_accuracy: 0.8633\n",
      "Epoch 854/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8475 - val_loss: 0.3226 - val_accuracy: 0.8633\n",
      "Epoch 855/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8456 - val_loss: 0.3237 - val_accuracy: 0.8630\n",
      "Epoch 856/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8476 - val_loss: 0.3233 - val_accuracy: 0.8637\n",
      "Epoch 857/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8463 - val_loss: 0.3228 - val_accuracy: 0.8636\n",
      "Epoch 858/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8472 - val_loss: 0.3227 - val_accuracy: 0.8634\n",
      "Epoch 859/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8462 - val_loss: 0.3239 - val_accuracy: 0.8631\n",
      "Epoch 860/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8462 - val_loss: 0.3236 - val_accuracy: 0.8634\n",
      "Epoch 861/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8477 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 862/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8489 - val_loss: 0.3229 - val_accuracy: 0.8642\n",
      "Epoch 863/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8462 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 864/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8478 - val_loss: 0.3238 - val_accuracy: 0.8636\n",
      "Epoch 865/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8477 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 866/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8467 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 867/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8471 - val_loss: 0.3237 - val_accuracy: 0.8634\n",
      "Epoch 868/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8461 - val_loss: 0.3234 - val_accuracy: 0.8628\n",
      "Epoch 869/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8480 - val_loss: 0.3236 - val_accuracy: 0.8633\n",
      "Epoch 870/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8478 - val_loss: 0.3235 - val_accuracy: 0.8635\n",
      "Epoch 871/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 872/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8477 - val_loss: 0.3228 - val_accuracy: 0.8632\n",
      "Epoch 873/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8491 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 874/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8480 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 875/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8640\n",
      "Epoch 876/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8450 - val_loss: 0.3229 - val_accuracy: 0.8624\n",
      "Epoch 877/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8470 - val_loss: 0.3227 - val_accuracy: 0.8631\n",
      "Epoch 878/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8456 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 879/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8485 - val_loss: 0.3228 - val_accuracy: 0.8632\n",
      "Epoch 880/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8469 - val_loss: 0.3229 - val_accuracy: 0.8638\n",
      "Epoch 881/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 882/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8493 - val_loss: 0.3235 - val_accuracy: 0.8635\n",
      "Epoch 883/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8479 - val_loss: 0.3233 - val_accuracy: 0.8636\n",
      "Epoch 884/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3549 - accuracy: 0.8466 - val_loss: 0.3232 - val_accuracy: 0.8638\n",
      "Epoch 885/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8475 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 886/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3501 - accuracy: 0.8491 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 887/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8484 - val_loss: 0.3227 - val_accuracy: 0.8631\n",
      "Epoch 888/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3501 - accuracy: 0.8468 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 889/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8454 - val_loss: 0.3233 - val_accuracy: 0.8639\n",
      "Epoch 890/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8466 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 891/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8466 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 892/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8480 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 893/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3494 - accuracy: 0.8481 - val_loss: 0.3230 - val_accuracy: 0.8638\n",
      "Epoch 894/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8467 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 895/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8465 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 896/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8459 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8469 - val_loss: 0.3236 - val_accuracy: 0.8634\n",
      "Epoch 898/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3507 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8633\n",
      "Epoch 899/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8472 - val_loss: 0.3226 - val_accuracy: 0.8634\n",
      "Epoch 900/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8484 - val_loss: 0.3231 - val_accuracy: 0.8627\n",
      "Epoch 901/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8467 - val_loss: 0.3231 - val_accuracy: 0.8632\n",
      "Epoch 902/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8466 - val_loss: 0.3230 - val_accuracy: 0.8635\n",
      "Epoch 903/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8478 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 904/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8465 - val_loss: 0.3233 - val_accuracy: 0.8633\n",
      "Epoch 905/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.8493 - val_loss: 0.3230 - val_accuracy: 0.8630\n",
      "Epoch 906/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8473 - val_loss: 0.3228 - val_accuracy: 0.8634\n",
      "Epoch 907/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8456 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 908/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8479 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 909/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8466 - val_loss: 0.3231 - val_accuracy: 0.8638\n",
      "Epoch 910/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8467 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 911/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8478 - val_loss: 0.3228 - val_accuracy: 0.8637\n",
      "Epoch 912/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8462 - val_loss: 0.3230 - val_accuracy: 0.8634\n",
      "Epoch 913/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8463 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 914/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8466 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 915/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8461 - val_loss: 0.3226 - val_accuracy: 0.8635\n",
      "Epoch 916/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 917/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8468 - val_loss: 0.3235 - val_accuracy: 0.8632\n",
      "Epoch 918/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8455 - val_loss: 0.3236 - val_accuracy: 0.8631\n",
      "Epoch 919/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3502 - accuracy: 0.8469 - val_loss: 0.3234 - val_accuracy: 0.8632\n",
      "Epoch 920/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3540 - accuracy: 0.8471 - val_loss: 0.3227 - val_accuracy: 0.8640\n",
      "Epoch 921/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.3230 - val_accuracy: 0.8638\n",
      "Epoch 922/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3504 - accuracy: 0.8485 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 923/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.8481 - val_loss: 0.3238 - val_accuracy: 0.8633\n",
      "Epoch 924/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3501 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 925/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8479 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 926/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8474 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 927/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8635\n",
      "Epoch 928/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3497 - accuracy: 0.8473 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 929/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8621\n",
      "Epoch 930/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3532 - accuracy: 0.8461 - val_loss: 0.3232 - val_accuracy: 0.8635\n",
      "Epoch 931/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8474 - val_loss: 0.3230 - val_accuracy: 0.8629\n",
      "Epoch 932/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8458 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 933/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8474 - val_loss: 0.3233 - val_accuracy: 0.8629\n",
      "Epoch 934/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 935/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8469 - val_loss: 0.3228 - val_accuracy: 0.8634\n",
      "Epoch 936/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8464 - val_loss: 0.3228 - val_accuracy: 0.8634\n",
      "Epoch 937/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3526 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8634\n",
      "Epoch 938/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8481 - val_loss: 0.3229 - val_accuracy: 0.8637\n",
      "Epoch 939/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8487 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 940/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8476 - val_loss: 0.3230 - val_accuracy: 0.8628\n",
      "Epoch 941/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8472 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 942/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3504 - accuracy: 0.8483 - val_loss: 0.3230 - val_accuracy: 0.8635\n",
      "Epoch 943/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8463 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 944/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8476 - val_loss: 0.3232 - val_accuracy: 0.8631\n",
      "Epoch 945/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 946/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8477 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 947/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8489 - val_loss: 0.3231 - val_accuracy: 0.8629\n",
      "Epoch 948/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8463 - val_loss: 0.3231 - val_accuracy: 0.8628\n",
      "Epoch 949/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3505 - accuracy: 0.8481 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 950/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8469 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 951/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3545 - accuracy: 0.8444 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 952/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3507 - accuracy: 0.8489 - val_loss: 0.3231 - val_accuracy: 0.8631\n",
      "Epoch 953/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8472 - val_loss: 0.3233 - val_accuracy: 0.8637\n",
      "Epoch 954/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3519 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8633\n",
      "Epoch 955/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8453 - val_loss: 0.3231 - val_accuracy: 0.8629\n",
      "Epoch 956/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8480 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 957/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8459 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 958/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8461 - val_loss: 0.3233 - val_accuracy: 0.8633\n",
      "Epoch 959/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8469 - val_loss: 0.3235 - val_accuracy: 0.8633\n",
      "Epoch 960/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8471 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 961/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8469 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 962/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3509 - accuracy: 0.8479 - val_loss: 0.3236 - val_accuracy: 0.8636\n",
      "Epoch 963/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8461 - val_loss: 0.3232 - val_accuracy: 0.8636\n",
      "Epoch 964/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8480 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 965/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 966/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3510 - accuracy: 0.8474 - val_loss: 0.3232 - val_accuracy: 0.8633\n",
      "Epoch 967/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8491 - val_loss: 0.3230 - val_accuracy: 0.8637\n",
      "Epoch 968/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8463 - val_loss: 0.3235 - val_accuracy: 0.8627\n",
      "Epoch 969/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3501 - accuracy: 0.8485 - val_loss: 0.3231 - val_accuracy: 0.8630\n",
      "Epoch 970/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3521 - accuracy: 0.8473 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
      "Epoch 971/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8487 - val_loss: 0.3235 - val_accuracy: 0.8629\n",
      "Epoch 972/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3503 - accuracy: 0.8475 - val_loss: 0.3236 - val_accuracy: 0.8628\n",
      "Epoch 973/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3523 - accuracy: 0.8473 - val_loss: 0.3227 - val_accuracy: 0.8634\n",
      "Epoch 974/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8472 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 975/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3512 - accuracy: 0.8484 - val_loss: 0.3234 - val_accuracy: 0.8636\n",
      "Epoch 976/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8457 - val_loss: 0.3231 - val_accuracy: 0.8634\n",
      "Epoch 977/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8467 - val_loss: 0.3236 - val_accuracy: 0.8625\n",
      "Epoch 978/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8470 - val_loss: 0.3229 - val_accuracy: 0.8635\n",
      "Epoch 979/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8476 - val_loss: 0.3229 - val_accuracy: 0.8641\n",
      "Epoch 980/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3518 - accuracy: 0.8474 - val_loss: 0.3235 - val_accuracy: 0.8634\n",
      "Epoch 981/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8482 - val_loss: 0.3232 - val_accuracy: 0.8637\n",
      "Epoch 982/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8474 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 983/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8476 - val_loss: 0.3228 - val_accuracy: 0.8639\n",
      "Epoch 984/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8472 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 985/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8475 - val_loss: 0.3231 - val_accuracy: 0.8630\n",
      "Epoch 986/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3495 - accuracy: 0.8479 - val_loss: 0.3227 - val_accuracy: 0.8632\n",
      "Epoch 987/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8478 - val_loss: 0.3236 - val_accuracy: 0.8633\n",
      "Epoch 988/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8460 - val_loss: 0.3237 - val_accuracy: 0.8631\n",
      "Epoch 989/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3511 - accuracy: 0.8482 - val_loss: 0.3236 - val_accuracy: 0.8633\n",
      "Epoch 990/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3516 - accuracy: 0.8474 - val_loss: 0.3229 - val_accuracy: 0.8632\n",
      "Epoch 991/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.8483 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 992/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8471 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 993/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8471 - val_loss: 0.3230 - val_accuracy: 0.8635\n",
      "Epoch 994/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3538 - accuracy: 0.8463 - val_loss: 0.3229 - val_accuracy: 0.8632\n",
      "Epoch 995/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3478 - accuracy: 0.8486 - val_loss: 0.3232 - val_accuracy: 0.8635\n",
      "Epoch 996/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.8469 - val_loss: 0.3230 - val_accuracy: 0.8632\n",
      "Epoch 997/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3528 - accuracy: 0.8477 - val_loss: 0.3234 - val_accuracy: 0.8634\n",
      "Epoch 998/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8459 - val_loss: 0.3231 - val_accuracy: 0.8637\n",
      "Epoch 999/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3527 - accuracy: 0.8486 - val_loss: 0.3227 - val_accuracy: 0.8628\n",
      "Epoch 1000/1000\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.8487 - val_loss: 0.3237 - val_accuracy: 0.8631\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "model1m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history2 = model1m.fit(x_train, y_train, epochs = 1000, batch_size = 128, validation_data = (x_val,y_val), callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331147, 28)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train.shape\n",
    "check_agreement1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.optimizer.lr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights('./models/my_model/x.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights('./models/my_model/m_bnorm')\n",
    "model.save_weights('./models/imported_model/i_bnorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agreement test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': '150',\n",
    "         'axes.titlesize':'40',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.xlabel('Epochs',size=40)\n",
    "plt.ylabel(\"Accuracy\",size=40)\n",
    "val = plt.plot(history.epoch, history.history['val_'+'accuracy'],\n",
    "             label='Default variables', linewidth = 4)\n",
    "plt.plot(historym.epoch, historym.history['val_'+'accuracy'],\n",
    "             label='Feature engineering', linewidth = 4)\n",
    "\n",
    "plt.legend(prop={'size':30})\n",
    "plt.xticks(fontsize = 30)\n",
    "plt.xticks(np.arange(0, max(history.epoch)+10, 50.0))\n",
    "plt.yticks(fontsize = 30)\n",
    "#plt.yticks(np.arange(romin(history.history['val_'+'accuracy']), max(history.history['val_'+'accuracy']), 2))\n",
    "plt.xlim([0,max(history.epoch)+1])\n",
    "plt.show()\n",
    "plt.savefig('test.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuned.predict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agr = pandas.read_csv(folder + 'check_agreement.csv.zip')\n",
    "data_agr1 = data_agr[list(f for f in data_agr.columns if f not in filter1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: data_agr\n",
       "  Entities:\n",
       "    df_agr [Rows: 331147, Columns: 47]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_agreement = data_agr\n",
    "es_agr = ft.EntitySet(id='data_agr')\n",
    "es_agr.entity_from_dataframe(entity_id = 'df_agr', dataframe = data_agr1, index = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1081 features\n",
      "EntitySet scattered to 3 workers in 4 seconds                                                                          \n",
      "Elapsed: 00:40 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_matrix_agr, feature_names_agr = ft.dfs(entityset=es_agr, \n",
    "target_entity = 'df_agr', \n",
    "max_depth = 1, \n",
    "verbose = 1, \n",
    "n_jobs = 3,\n",
    "trans_primitives = ['add_numeric'])\n",
    "check_agreement1 = feature_matrix_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_agreement1 = sel_.transform(check_agreement1.fillna(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331147, 461)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_agreement1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23265803]\n",
      " [0.00177309]\n",
      " [0.39068684]\n",
      " ...\n",
      " [0.96447545]\n",
      " [0.988817  ]\n",
      " [0.9879995 ]]\n",
      "KS metric 0.27842199273103607 False\n"
     ]
    }
   ],
   "source": [
    "#check_agreement = pandas.read_csv(folder + 'check_agreement.csv.zip', index_col='id')\n",
    "#check_agreement = add_features(check_agreement)\n",
    "\n",
    "#check_agreement1 = check_agreement[variables_mod].to_numpy()\n",
    "agreement_probs = model1.predict(check_agreement1)\n",
    "print(agreement_probs)\n",
    "ks = evaluation.compute_ks(\n",
    "    agreement_probs[check_agreement['signal'].values == 0],\n",
    "    agreement_probs[check_agreement['signal'].values == 1],\n",
    "    check_agreement[check_agreement['signal'] == 0]['weight'].values,\n",
    "    check_agreement[check_agreement['signal'] == 1]['weight'].values)\n",
    "print('KS metric', ks, ks < 0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: data_cor\n",
       "  Entities:\n",
       "    df_cor [Rows: 5514, Columns: 47]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cor = pandas.read_csv(folder + 'check_correlation.csv.zip')\n",
    "data_cor1 = data_cor[list(f for f in data_cor.columns if f not in filter1)]\n",
    "check_correlation = data_cor\n",
    "es_cor = ft.EntitySet(id='data_cor')\n",
    "es_cor.entity_from_dataframe(entity_id = 'df_cor', dataframe = data_cor1, index = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1081 features\n",
      "EntitySet scattered to 3 workers in 3 seconds                                                                          \n",
      "Elapsed: 00:02 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_cor, feature_names_cor = ft.dfs(entityset=es_cor, \n",
    "target_entity = 'df_cor', \n",
    "max_depth = 1, \n",
    "verbose = 1, \n",
    "n_jobs = 3,\n",
    "trans_primitives = ['add_numeric'])\n",
    "check_correlation1 = feature_matrix_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_correlation1 = sel_.transform(check_correlation1.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CvM metric 0.0010599120449313502 True\n"
     ]
    }
   ],
   "source": [
    "#check_correlation = pandas.read_csv(folder + 'check_correlation.csv.zip', index_col='id')\n",
    "#check_correlation = add_features(check_correlation)\n",
    "#check_correlation1 = check_correlation[variables_mod].to_numpy()\n",
    "correlation_probs = model1.predict(check_correlation1).squeeze()\n",
    "\n",
    "cvm = evaluation.compute_cvm(correlation_probs, check_correlation['mass'])\n",
    "print('CvM metric', cvm, cvm < 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute weighted AUC on the training data with min_ANNmuon > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_21 is incompatible with the layer: expected axis 1 of input shape to have value 2500 but received input with shape [None, 10]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-23a013db7107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_ANNmuon'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_eval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariables_mod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_eval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'signal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3142\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    c:\\users\\emile\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_21 is incompatible with the layer: expected axis 1 of input shape to have value 2500 but received input with shape [None, 10]\n"
     ]
    }
   ],
   "source": [
    "train_eval = data[data['min_ANNmuon'] > 0.4]\n",
    "train_probs = model1m.predict(train_eval[variables_mod].to_numpy()).squeeze()\n",
    "AUC = sklearn.metrics.roc_auc_score(train_eval['signal'], train_probs)\n",
    "print('AUC', AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test, create file for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.DataFrame({'id': test.index})\n",
    "result['prediction'] = model.predict(test[variables].to_numpy()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submission.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
